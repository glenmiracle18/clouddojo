[
  {
    "number": "1",
    "text": "A company is building an ecommer ce web application on A WS. The application sends information about new or ders t o an A maz on API Gatewa y REST API t o pr ocess. The company wants t o ensur e that or ders ar e pr ocessed in the or der that the y ar e r eceiv ed. Which solution will meet these r equir ements?",
    "options": [
      "Use an API Gatewa y integr ation t o send a message t o an Amaz on Simple Queue Ser vice (Amaz on SQS) standar d queue when the application r eceiv es an or der . Conﬁgur e the SQS standar d queue t o inv ok e an A WS Lambda function for pr ocessing.",
      "Use an API Gatewa y integr ation t o send a message t o an Amaz on Simple Queue Ser vice (Amaz on SQS) FIFO queue when the application r eceiv es an or der . Conﬁgur e the SQS FIFO queue t o inv ok e an A WS Lambda function for pr ocessing. Corr ect answer",
      "Use an API Gatewa y integr ation t o publish a message t o an Amaz on Simple Notiﬁcation Ser vice (Amaz on SNS) t opic when the application r eceiv es an or der . Subscribe an A WS Lambda function t o the t opic t o per form pr ocessing. D . Use an API Gatewa y authoriz er t o block any r equests while the application pr ocesses an or der . Ov er all explanation Amaz on SQS FIFO Queue: Using an Amaz on SQS FIFO queue ensur es that messages ar e pr ocessed in the or der the y ar e r eceiv ed. \"FIFO\" stands for First-In-First-Out, and it guar antees the or der of pr ocessing for messages. API Gatewa y Integr ation: Option B utiliz es API Gatewa y for integr ation, which means y ou can seamlessly send or der information t o the SQS FIFO queue as soon as the application r eceiv es an or der . A WS Lambda for Pr ocessing: A WS Lambda is well-suited for pr ocessing messages fr om SQS queues. By conﬁguring the SQS FIFO queue t o inv ok e an A WS Lambda function, y ou can eﬃciently pr ocess or ders as the y arriv e. PAGE3",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "2",
    "text": "A company is de v eloping a new machine learning (ML) model solution on A WS. The models ar e de v eloped as independent micr oser vices that f etch appr o ximately 1 GB of model data fr om A maz on S3 at star tup and load the data int o memor y . Users access the models thr ough an asynchr onous API. Users can send a r equest or a batch of r equests and specify wher e the r esults should be sent. The company pr o vides models t o hundr eds of users. The usage patterns for the models ar e irr egular . Some models could be unused for da ys or weeks. Other models could r eceiv e batches of thousands of r equests at a time. Which design should a solutions ar chitect r ecommend t o meet these r equir ements?",
    "options": [
      "Dir ect the r equests fr om the API int o an Amaz on Simple Queue Ser vice (Amaz on SQS) queue. Deplo y the models as A WS Lambda functions that ar e inv ok ed b y SQS e v ents. Use A WS A ut o Scaling t o incr ease the number of v CPUs for the Lambda functions based on the SQS queue siz e.",
      "Dir ect the r equests fr om the API t o a Network Load Balancer (NLB). Deplo y the models as A WS Lambda functions that ar e inv ok ed b y the NL",
      "C. Dir ect the r equests fr om the API t o an Application Load Balancer (ALB). Deplo y the models as Amaz on Elastic Container Ser vice (Amaz on ECS) ser vices that r ead fr om an Amaz on Simple Queue Ser vice (Amaz on SQS) queue. Use A WS App Mesh t o scale the instances of the ECS cluster based on the SQS queue siz e. D . Dir ect the r equests fr om the API int o an Amaz on Simple Queue Ser vice (Amaz on SQS) queue. Deplo y the models as Amaz on Elastic Container Ser vice (Amaz on ECS) ser vices that r ead fr om the queue. Enable A WS A ut o Scaling on Amaz on ECS for both the cluster and copies of the ser vice based on the queue siz e. Corr ect answer Ov er all explanation Dir ect the r equests fr om the API int o an Amaz on Simple Queue Ser vice (Amaz on SQS) queue. Deplo y the models as Amaz on Elastic Container Ser vice (Amaz on ECS) ser vices that r ead fr om the queue. Enable A WS A ut o Scaling on Amaz on ECS for both the cluster and copies of the ser vice based on the queue siz e. PAGE4",
      ""
    ],
    "correct_answer": null,
    "explanation": "Scalability with SQS: Using SQS as a message queue allows for decoupling between components, pr o viding scalability and asynchr onous pr ocessing. ECS for Micr oser vices: Deplo ying the models as ECS ser vices enables eﬃcient containeriz ed ex ecution of micr oser vices, ensuring r esour ce isolation and ﬂexibility . A ut o Scaling Based on Queue Siz e: Enabling A WS A ut o Scaling on ECS allows for dynamic scaling of both the ECS cluster and ser vice instances based on the siz e of the SQS queue. Eﬃcient Resour ce Utilization: A ut o Scaling ensur es that r esour ces ar e scaled up or down based on demand, optimizing r esour ce utilization. Irr egular Usage P atterns: This solution accommodates irr egular usage patterns and eﬃciently handles v ar ying workloads without continuous running of back end nodes."
  },
  {
    "number": "3",
    "text": "A company has a web application with spor adic usage patterns. Ther e is hea vy usage at the beginning of each month, moder ate usage at the star t of each week, and unpr edictable usage during the week. The application consists of a web ser v er and a My SQL database ser v er running inside the data center . The company would lik e t o mo v e the application t o the A WS Cloud, and needs t o select a cost-eff ectiv e database platform that will not r equir e database modiﬁcations. Which solution will meet these r equir ements?",
    "options": [
      "My SQL deplo y ed on Amaz on EC2 in an A ut o Scaling gr oup",
      "Amaz on RDS for My SQL",
      "Amaz on Dynamo DB D . My SQL-compatible Amaz on A ur or a Ser v erless Corr ect answer PAGE5 Ov er all explanation My SQL-compatible Amaz on A ur or a Ser v erless",
      ""
    ],
    "correct_answer": null,
    "explanation": "Spor adic Usage P atterns: A ur or a Ser v erless aut omatically adjusts capacity based on actual usage, making it suitable for applications with unpr edictable usage patterns. Cost-E ff ectiv e: A ur or a Ser v erless off ers aut omatic scaling, and y ou pa y for the database capacity (measur ed in A ur or a Capacity Units, A CUs) only when the capacity is in use. No Database Modiﬁcations: A ur or a is My SQL-compatible, allowing for a seamless migr ation without the need for database modiﬁcations. High A v ailability: A ur or a Ser v erless pr o vides high a v ailability with aut omatic failo v er , ensuring that the database r emains a v ailable e v en in the e v ent of a failur e. Ser v erless Model: With A ur or a Ser v erless, ther e is no need t o pr o vision or manage database instances continuously , r educing oper ational o v erhead."
  },
  {
    "number": "4",
    "text": "A company has a data ingestion workﬂow that consists of the following: • A n A maz on Simple Notiﬁcation Ser vice (A maz on SNS) t opic for notiﬁcations about new data deliv eries • A n A WS Lambda function t o pr ocess the data and r ecor d metadata The company obser v es that the ingestion workﬂow fails occasionally because of network connectivity issues. When such a failur e occurs, the Lambda function does not ingest the corr esponding data unless the company manually r eruns the job. Which combination of actions should a solutions ar chitect tak e t o ensur e that the Lambda function ingests all data in the futur e? (Choose two.)",
    "options": [
      "Incr ease pr o visioned thr oughput for the Lambda function. PAGE6",
      "Incr ease the CPU and memor y that ar e allocated t o the Lambda function.",
      "Cr eate an Amaz on Simple Queue Ser vice (Amaz on SQS) queue, and subscribe it t o the SNS t opic. Corr ect answer D . Modify the Lambda function t o r ead fr om an Amaz on Simple Queue Ser vice (Amaz on SQS) queue. Corr ect answer E. Deplo y the Lambda function in multiple A v ailability Z ones. Ov er all explanation Cr eate an Amaz on Simple Queue Ser vice (Amaz on SQS) queue, and subscribe it t o the SNS t opic: By cr eating an SQS queue and subscribing it t o the SNS t opic, y ou decouple the pr ocessing of messages fr om the publisher (SNS). This means that e v en if network connectivity issues or tempor ar y failur es occur , messages published t o the SNS t opic ar e st or ed in the SQS queue, and the Lambda function can r etrie v e and pr ocess them when it' s able t o do so. This ensur es that no data is lost. Modify the Lambda function t o r ead fr om an Amaz on Simple Queue Ser vice (Amaz on SQS) queue: By ha ving the Lambda function r ead fr om an SQS queue, y ou can ensur e that the Lambda function pr ocesses all messages, e v en if ther e ar e network issues or occasional failur es. The SQS queue acts as a buff er , allowing the Lambda function t o pr ocess messages at its own pace without data loss.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "5",
    "text": "PAGE7 A company hosts mor e than 300 global websites and applications. The company r equir es a platform t o analyz e mor e than 30 TB of clickstr eam data each da y . What should a solutions ar chitect do t o tr ansmit and pr ocess the clickstr eam data?",
    "options": [
      "Cache the data t o Amaz on Cloud F r ont. St or e the data in an Amaz on S3 buck et. When an object is added t o the S3 buck et. run an A WS Lambda function t o pr ocess the data for analysis.",
      "Design an A WS Data Pipeline t o ar chiv e the data t o an Amaz on S3 buck et and run an Amaz on EMR cluster with the data t o gener ate analytics.",
      "Cr eate an A ut o Scaling gr oup of Amaz on EC2 instances t o pr ocess the data and send it t o an Amaz on S3 data lak e for Amaz on Redshift t o use for analysis. D . Collect the data fr om Amaz on Kinesis Data Str eams. Use Amaz on Kinesis Data Fir ehose t o tr ansmit the data t o an Amaz on S3 data lak e. Load the data in Amaz on Redshift for analysis. Corr ect answer Ov er all explanation Collect the data fr om Amaz on Kinesis Data Str eams. Use Amaz on Kinesis Data Fir ehose t o tr ansmit the data t o an Amaz on S3 data lak e. Load the data in Amaz on Redshift for analysis.",
      ""
    ],
    "correct_answer": null,
    "explanation": "Amaz on Kinesis is designed for r eal-time data str eaming and is suitable for collecting, pr ocessing, and analyzing lar ge v olumes of str eaming data such as clickstr eam data. Amaz on Kinesis Data Fir ehose can be used t o easily captur e and load data int o an Amaz on S3 data lak e. In this scenario, y ou can collect the clickstr eam data fr om Amaz on Kinesis Data Str eams, use Amaz on Kinesis Data Fir ehose t o eﬃciently tr ansmit and load the data int o an Amaz on S3 data lak e. This data can then be pr ocessed and analyz ed using Amaz on Redshift for y our analytics needs. PAGE8 This ar chitectur e is well-suited for pr ocessing lar ge v olumes of str eaming data eﬃciently and allows y ou t o per form analytics on the st or ed data."
  },
  {
    "number": "6",
    "text": "A company runs an online mark etplace web application on A WS. The application ser v es hundr eds of thousands of users during peak hours. The company needs a scalable, near-r eal-time solution t o shar e the details of millions of ﬁnancial tr ansactions with se v er al other internal applications. T r ansactions also need t o be pr ocessed t o r emo v e sensitiv e data befor e being st or ed in a document database for low-latency r etrie v al. What should a solutions ar chitect r ecommend t o meet these r equir ements?",
    "options": [
      "St or e the batched tr ansactions data in Amaz on S3 as ﬁles. Use A WS Lambda t o pr ocess e v er y ﬁle and r emo v e sensitiv e data befor e updating the ﬁles in Amaz on S3. The Lambda function then st or es the data in Amaz on Dynamo D",
      "Other applications can consume tr ansaction ﬁles st or ed in Amaz on S3.",
      "Str eam the tr ansactions data int o Amaz on Kinesis Data Fir ehose t o st or e data in Amaz on Dynamo DB and Amaz on S3. Use A WS Lambda integr ation with Kinesis Data Fir ehose t o r emo v e sensitiv e data. Other applications can consume the data st or ed in Amaz on S3.",
      "Str eam the tr ansactions data int o Amaz on Kinesis Data Str eams. Use A WS Lambda integr ation t o r emo v e sensitiv e data fr om e v er y tr ansaction and then st or e the tr ansactions data in Amaz on Dynamo D",
      "Other applications can consume the tr ansactions data off the Kinesis data str eam. Corr ect answer D . St or e the tr ansactions data int o Amaz on Dynamo D",
      "Set up a rule in Dynamo DB t o r emo v e sensitiv e data fr om e v er y tr ansaction upon write. Use Dynamo DB Str eams t o shar e the tr ansactions data with other applications. Ov er all explanation PAGE9 This solution le v er ages the r eal-time capabilities of Amaz on Kinesis Data Str eams and A WS Lambda t o pr ocess and st or e the tr ansactions data while ensuring that sensitiv e information is r emo v ed. Kinesis Data Str eams allows y ou t o ingest and pr ocess high v olumes of str eaming data, and y ou can use A WS Lambda t o per form data tr ansformation and cleaning oper ations as data ﬂows thr ough the str eam. After r emo ving sensitiv e data, the cleaned tr ansactions can be st or ed in Amaz on Dynamo DB for low-latency r etrie v al, and other applications can consume the pr ocessed data fr om the Kinesis data str eam. This ar chitectur e is scalable, near-r eal-time, and well-suited for high-thr oughput and sensitiv e data pr ocessing."
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "7",
    "text": "A company needs t o tr ansf er 600 TB of data fr om its on-pr emises network-attached st or age (N AS) system t o the A WS Cloud. The data tr ansf er must be complete within 2 weeks. The data is sensitiv e and must be encr ypted in tr ansit. The company ’ s internet connection can suppor t an upload speed of 100 Mbps. Which solution meets these r equir ements MOST cost-eff ectiv ely?",
    "options": [
      "Cr eate a VPN connection between the on-pr emises N AS system and the near est A WS Region. T r ansf er the data o v er the VPN connection.",
      "Set up a 10 Gbps A WS Dir ect Connect connection between the company location and the near est A WS Region. T r ansf er the data o v er a VPN connection int o the Region t o st or e the data in Amaz on S3.",
      "Use the A WS Snow F amily console t o or der se v er al A WS Snowball E dge St or age Optimiz ed de vices. Use the de vices t o tr ansf er the data t o Amaz on S3. Corr ect answer D . Use Amaz on S3 multi-par t upload functionality t o tr ansf er the ﬁles o v er H T TPS. PAGE10 Ov er all explanation A WS Snowball E dge is a physical data tr ansf er appliance that can be used t o tr ansf er lar ge amounts of data fr om on-pr emises t o A WS. It is suitable for situations wher e the data tr ansf er o v er the network is not f easible. The best option is t o use the A WS Snow F amily console t o or der se v er al A WS Snowball E dge St or age Optimiz ed de vices and use the de vices t o tr ansf er the data t o Amaz on S3. Snowball E dge is a petab yte-scale data tr ansf er de vice that can help tr ansf er lar ge amounts of data secur ely and quickly . Using Snowball E dge can be the most cost-eff ectiv e solution for tr ansf erring lar ge amounts of data o v er long distances and can help meet the r equir ement of tr ansf erring 600 TB of data within two weeks.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "9",
    "text": "A company runs a highly a v ailable image-pr ocessing application on A maz on EC2 instances in a single VP",
    "options": [
      "The EC2 instances run inside se v er al subnets acr oss multiple A v ailability Z ones. The EC2 instances do not communicate with each other . Howe v er , the EC2 instances download images fr om A maz on S3 and upload images t o A maz on S3 thr ough a single N A T gatewa y . The company is concerned about data tr ansf er char ges. What is the MOST cost-eff ectiv e wa y for the company t o a v oid Regional data tr ansf er char ges?",
      "Deplo y a gatewa y VPC endpoint for Amaz on S3. Corr ect answer",
      "Replace the N A T gatewa y with a N A T instance.",
      "Pr o vision an EC2 Dedicated Host t o run the EC2 instances. D . Launch the N A T gatewa y in each A v ailability Z one. Ov er all explanation A VPC endpoint for Amaz on S3 allows the EC2 instances t o access Amaz on S3 within the same r egion without incurring data tr ansf er char ges. It r outes tr aﬃc t o Amaz on S3 dir ectly fr om the VPC, a v oiding the need t o go thr ough the N A T gatewa y . Launching a N A T gatewa y in each A v ailability Z one (option A) or r eplacing the N A T gatewa y with a N A T instance (option B) would not eliminate data tr ansf er char ges, as the data would still ha v e t o pass thr ough the N A T de vice t o r each Amaz on S3. Pr o visioning an EC2 Dedicated Host (option D) does not addr ess the data tr ansf er char ges and is not r elated t o r educing data tr ansf er costs between the EC2 instances and Amaz on S3."
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "10",
    "text": "A meteor ological star tup company has a cust om web application t o sell weather data t o its users online. The company uses A maz on Dynamo DB t o st or e its data and wants t o build a new ser vice that sends an aler t t o the managers of four internal teams e v er y PAGE13 time a new weather e v ent is r ecor ded. The company does not want this new ser vice t o aff ect the per formance of the curr ent application. What should a solutions ar chitect do t o meet these r equir ements with the LEAST amount of oper ational o v erhead?",
    "options": [
      "Enable Amaz on Dynamo DB Str eams on the table. Use triggers t o write t o a single Amaz on Simple Notiﬁcation Ser vice (Amaz on SNS) t opic t o which the teams can subscribe. Corr ect answer",
      "Ha v e the curr ent application publish a message t o four Amaz on Simple Notiﬁcation Ser vice (Amaz on SNS) t opics. Ha v e each team subscribe t o one t opic.",
      "Use Dynamo DB tr ansactions t o write new e v ent data t o the table. Conﬁgur e the tr ansactions t o notify internal teams. D . Add a cust om attribute t o each r ecor d t o ﬂag new items. W rite a cr on job that scans the table e v er y minute for items that ar e new and notiﬁes an Amaz on Simple Queue Ser vice (Amaz on SQS) queue t o which the teams can subscribe. Ov er all explanation Enabling Dynamo DB Str eams allows y ou t o captur e changes t o the Dynamo DB table, and y ou can use triggers t o write t o an Amaz on SNS t opic. This allows teams t o subscribe t o a single t opic for notiﬁcations with minimal oper ational o v erhead. The best solution t o meet these r equir ements with the least amount of oper ational o v erhead is t o enable Amaz on Dynamo DB Str eams on the table and use triggers t o write t o a single Amaz on Simple Notiﬁcation Ser vice (Amaz on SNS) t opic t o which the teams can subscribe. This solution r equir es minimal conﬁgur ation and infr astructur e setup, and Amaz on Dynamo DB Str eams pr o vide a low-latency wa y t o captur e changes t o the Dynamo DB table. The triggers aut omatically captur e the changes and publish them t o the SNS t opic, which notiﬁes the internal teams. PAGE14",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "11",
    "text": "A company has implemented a self-managed DNS ser vice on A WS. The solution consists of the following: • A maz on EC2 instances in diff er ent A WS Regions • Endpoints of a standar d acceler at or in A WS Global Acceler at or The company wants t o pr otect the solution against DDo S attacks. What should a solutions ar chitect do t o meet this r equir ement?",
    "options": [
      "Subscribe t o A WS Shield Adv anced. Add the acceler at or as a r esour ce t o pr otect. Corr ect answer",
      "Cr eate an A WS W AF web A CL that includes a r ate-based rule. Associate the web A CL with the acceler at or .",
      "Subscribe t o A WS Shield Adv anced. Add the EC2 instances as r esour ces t o pr otect. D . Cr eate an A WS W AF web A CL that includes a r ate-based rule. Associate the web A CL with the EC2 instances. Ov er all explanation A WS Shield Adv anced pr o vides adv anced DDo S pr otection. Adding the acceler at or as a r esour ce allows it t o be pr otected against DDo S attacks.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "12",
    "text": "A n I AM user made se v er al conﬁgur ation changes t o A WS r esour ces in their company ' s account during a pr oduction deplo yment last week. A solutions ar chitect learned that a couple of security gr oup rules ar e not conﬁgur ed as desir ed. The solutions ar chitect wants t o conﬁrm which I AM user was r esponsible for making changes. Which ser vice should the solutions ar chitect use t o ﬁnd the desir ed information? PAGE15",
    "options": [
      "Amaz on Guar d Duty",
      "Amaz on Inspect or",
      "A WS Conﬁg D . A WS Cloud T r ail Corr ect answer Ov er all explanation A WS Cloud T r ail is the ser vice used t o monit or and log A WS API call activity . It r ecor ds API actions tak en on A WS r esour ces, including who per formed the actions.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "13",
    "text": "A company runs multiple Windows workloads on A WS. The company ' s emplo y ees use Windows ﬁle shar es that ar e hosted on two A maz on EC2 instances. The ﬁle shar es synchr oniz e data between themselv es and maintain duplicate copies. The company wants a highly a v ailable and dur able st or age solution that pr eser v es how users curr ently access the ﬁles. What should a solutions ar chitect do t o meet these r equir ements?",
    "options": [
      "Migr ate all the data t o Amaz on S3. Set up I AM authentication for users t o access ﬁles.",
      "Set up an Amaz on S3 File Gatewa y . Mount the S3 File Gatewa y on the existing EC2 instances.",
      "Extend the ﬁle shar e envir onment t o Amaz on FSx for Windows File Ser v er with a Multi-AZ conﬁgur ation. Migr ate all the data t o FSx for Windows File Ser v er . Corr ect answer D . Extend the ﬁle shar e envir onment t o Amaz on Elastic File System (Amaz on EFS) with a Multi-AZ conﬁgur ation. Migr ate all the data t o Amaz on EFS. Ov er all explanation PAGE16 Extend the ﬁle shar e envir onment t o Amaz on FSx for Windows File Ser v er with a Multi-AZ conﬁgur ation. Migr ate all the data t o FSx for Windows File Ser v er . Her e ' s why this option is the most suitable: Amaz on FSx for Windows File Ser v er: FSx for Windows File Ser v er is a managed ﬁle st or age ser vice that is fully compatible with Windows ﬁle shar es. It' s designed t o work with Windows-based applications and envir onments. Multi-AZ Conﬁgur ation : Amaz on FSx suppor ts Multi-AZ conﬁgur ations, which means that it r eplicates y our data acr oss multiple A v ailability Z ones for high a v ailability and dur ability . Data Migr ation: Y ou can migr ate the existing data fr om y our EC2 instances t o FSx for Windows File Ser v er . This solution pr o vides a highly a v ailable and dur able st or age envir onment while pr eser ving the wa y users curr ently access the ﬁles using Windows ﬁle shar es. It' s a good ﬁt for Windows workloads and off ers nativ e Windows compatibility .",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "14",
    "text": "A company obser v es an incr ease in A maz on EC2 costs in its most r ecent bill. The billing team notices unwanted v er tical scaling of instance types for a couple of EC2 instances. A solutions ar chitect needs t o cr eate a gr aph comparing the last 2 months of EC2 costs and per form an in-depth analysis t o identify the r oot cause of the v er tical scaling. How should the solutions ar chitect gener ate the information with the LEAST oper ational o v erhead?",
    "options": [
      "Use gr aphs fr om the A WS Billing and Cost Management dashboar d t o compar e EC2 costs based on instance types for the last 2 months. Corr ect answer PAGE17",
      "Use A WS Cost and Usage Repor ts t o cr eate a r epor t and send it t o an Amaz on S3 buck et. Use Amaz on Quick Sight with Amaz on S3 as a sour ce t o gener ate an inter activ e gr aph based on instance types.",
      "Use A WS Budgets t o cr eate a budget r epor t and compar e EC2 costs based on instance types. D . Use Cost Explor er ' s gr anular ﬁltering f eatur e t o per form an in-depth analysis of EC2 costs based on instance types. Ov er all explanation A WS Billing and Cost Management dashboar d pr o vides a built-in inter face for gener ating cost and usage r epor ts without the need t o cr eate cust om r epor ts or set up additional t ools. Y ou can easily cr eate gr aphs and visualiz e cost data, including EC2 costs based on instance types, dir ectly fr om the A WS Management Console. This appr oach is user-friendly and does not r equir e setting up additional ser vices or per forming complex conﬁgur ations.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "15",
    "text": "A company needs t o st or e its accounting r ecor ds in A maz on S3. The r ecor ds must be immediately accessible for 1 y ear and then must be ar chiv ed for an additional 9 y ears. No one at the company , including administr ativ e users and r oot users, can be able t o delete the r ecor ds during the entir e 10-y ear period. The r ecor ds must be st or ed with maximum r esiliency . Which solution will meet these r equir ements?",
    "options": [
      "St or e the r ecor ds in S3 Glacier for the entir e 10-y ear period. Use an access contr ol policy t o deny deletion of the r ecor ds for a period of 10 y ears. PAGE18",
      "Use an S3 Lif ecy cle policy t o tr ansition the r ecor ds fr om S3 Standar d t o S3 Glacier Deep Ar chiv e after 1 y ear . Use S3 Object Lock in compliance mode for a period of 10 y ears. Corr ect answer",
      "St or e the r ecor ds b y using S3 Intelligent-Tiering. Use an I AM policy t o deny deletion of the r ecor ds. After 10 y ears, change the I AM policy t o allow deletion. D . Use an S3 Lif ecy cle policy t o tr ansition the r ecor ds fr om S3 Standar d t o S3 One Z one-Infr equent Access (S3 One Z one-I A) after 1 y ear . Use S3 Object Lock in go v ernance mode for a period of 10 y ears. Ov er all explanation Use an S3 Lif ecy cle policy t o tr ansition the r ecor ds fr om S3 Standar d t o S3 Glacier Deep Ar chiv e after 1 y ear . Use S3 Object Lock in compliance mode for a period of 10 y ears. Her e ' s why this option is the most appr opriate: S3 Object Lock : S3 Object Lock ensur es that objects r emain unalter ed for the dur ation y ou specify . In this case, y ou want t o r etain the r ecor ds without deletion for 10 y ears, which is pr ecisely what S3 Object Lock in compliance mode is designed for . S3 Lif ecy cle P olicy : Using an S3 Lif ecy cle policy t o tr ansition the r ecor ds fr om S3 Standar d t o S3 Glacier Deep Ar chiv e after 1 y ear helps t o r educe st or age costs. It' s a cost-eff ectiv e wa y t o manage data r etention while k eeping the r ecor ds accessible for the r equir ed period. S3 Glacier Deep Ar chiv e : S3 Glacier Deep Ar chiv e pr o vides dur able, secur e, and cost-eff ectiv e ar chiv al st or age for long-term data r etention. This solution ensur es that the r ecor ds ar e immediately accessible for 1 y ear in S3 Standar d, followed b y secur e and dur able ar chiv al st or age in S3 Glacier Deep Ar chiv e for the additional 9 y ears. Additionally , it enfor ces the r estriction on deletion, making it suitable for the company ' s needs. PAGE19",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "16",
    "text": "A company needs t o ingest and handle lar ge amounts of str eaming data that its application gener ates. The application runs on A maz on EC2 instances and sends data t o A maz on Kinesis Data Str eams, which is conﬁgur ed with default settings. E v er y other da y , the application consumes the data and writes the data t o an A maz on S3 buck et for business intelligence (BI) pr ocessing. The company obser v es that A maz on S3 is not r eceiving all the data that the application sends t o Kinesis Data Str eams. What should a solutions ar chitect do t o r esolv e this issue?",
    "options": [
      "T urn on S3 V ersioning within the S3 buck et t o pr eser v e e v er y v ersion of e v er y object that is ingested in the S3 buck et.",
      "Update the Kinesis Data Str eams default settings b y modifying the data r etention period.",
      "Update the number of Kinesis shar ds t o handle the thr oughput of the data that is sent t o Kinesis Data Str eams. Corr ect answer D . Update the application t o use the Kinesis Pr oducer Libr ar y (KPL) t o send the data t o Kinesis Data Str eams. Ov er all explanation Update the number of Kinesis shar ds t o handle the thr oughput of the data that is sent t o Kinesis Data Str eams.",
      ""
    ],
    "correct_answer": null,
    "explanation": "Kinesis Data Str eams use shar ds t o scale thr oughput. If data is not r eaching Amaz on S3, it ma y be because the number of shar ds is insuﬃcient. Incr easing the number of Kinesis shar ds allows for gr eater par allel pr ocessing and can handle higher data thr oughput. PAGE20 Updating the Kinesis Data Str eams conﬁgur ation t o match the r equir ed thr oughput is essential t o ensur e that all data is ingested."
  },
  {
    "number": "17",
    "text": "A company has a website hosted on A WS. The website is behind an A pplication Load Balancer (ALB) that is conﬁgur ed t o handle H T TP and H T TPS separ ately . The company wants t o for war d all r equests t o the website so that the r equests will use H T TPS. What should a solutions ar chitect do t o meet this r equir ement?",
    "options": [
      "Update the ALB' s network A CL t o accept only H T TPS tr aﬃc.",
      "Replace the ALB with a Network Load Balancer conﬁgur ed t o use Ser v er Name Indication (SNI).",
      "Cr eate a listener rule on the ALB t o r edir ect H T TP tr aﬃc t o H T TPS. Corr ect answer D . Cr eate a rule that r eplaces the H T TP in the URL with H T TPS. Ov er all explanation Cr eate a listener rule on the ALB t o r edir ect H T TP tr aﬃc t o H T TPS.",
      ""
    ],
    "correct_answer": null,
    "explanation": "T o ensur e that all H T TP r equests ar e r edir ected t o H T TPS, y ou should cr eate a listener rule on the Application Load Balancer (ALB) that per forms the r edir ection. This rule can be conﬁgur ed t o inspect incoming r equests and r edir ect them t o H T TPS if the y ar e r eceiv ed o v er H T TP . By conﬁguring this rule, y ou can ensur e that all r equests t o y our website ar e secur ely handled o v er H T TPS. PAGE21"
  },
  {
    "number": "18",
    "text": "A company needs t o r e view its A WS Cloud deplo yment t o ensur e that its A maz on S3 buck ets do not ha v e unauthoriz ed conﬁgur ation changes. What should a solutions ar chitect do t o accomplish this goal?",
    "options": [
      "T urn on Amaz on S3 ser v er access logging. Conﬁgur e Amaz on E v ent Bridge (Amaz on Cloud W atch E v ents).",
      "T urn on A WS Conﬁg with the appr opriate rules. Corr ect answer",
      "T urn on Amaz on Inspect or with the appr opriate assessment template. D . T urn on A WS T rusted Advisor with the appr opriate checks. Ov er all explanation A WS Conﬁg is a ser vice that enables y ou t o assess, audit, and e v aluate the conﬁgur ations of y our A WS r esour ces. Y ou can use A WS Conﬁg t o monit or and r ecor d changes t o the conﬁgur ation of y our Amaz on S3 buck ets. By turning on A WS Conﬁg and enabling the appr opriate rules, y ou can ensur e that y our S3 buck ets do not ha v e unauthoriz ed conﬁgur ation changes.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "19",
    "text": "A company is running a popular social media website. The website giv es users the ability t o upload images t o shar e with other users. The company wants t o mak e sur e that the images do not contain inappr opriate content. The company needs a solution that minimiz es de v elopment effor t. What should a solutions ar chitect do t o meet these r equir ements?",
    "options": [
      "Use Amaz on Rekognition t o detect inappr opriate content. Use human r e view for low-conﬁdence pr edictions. Corr ect answer PAGE22",
      "Use Amaz on Sage Mak er t o detect inappr opriate content. Use gr ound truth t o label low-conﬁdence pr edictions.",
      "Use Amaz on Compr ehend t o detect inappr opriate content. Use human r e view for low-conﬁdence pr edictions. D . Use A WS F ar gate t o deplo y a cust om machine learning model t o detect inappr opriate content. Use gr ound truth t o label low-conﬁdence pr edictions. Ov er all explanation Use Amaz on Rekognition t o detect inappr opriate content. Use human r e view for low-conﬁdence pr edictions.",
      ""
    ],
    "correct_answer": null,
    "explanation": "Amaz on Rekognition is a ser vice that off ers pr e-tr ained machine learning models for image and video analysis, including detecting inappr opriate content. It can quickly and accur ately detect explicit or suggestiv e content within images. F or low-conﬁdence pr edictions, y ou can set up a human r e view workﬂow thr ough Amaz on Rekognition Cust om Labels. This allows human r e viewers t o r e view and conﬁrm the inappr opriate content, thus r educing the chances of false positiv es or negativ es. Using Amaz on Rekognition for inappr opriate content detection minimiz es the de v elopment effor t compar ed t o building a cust om machine learning model and is a cost-eff ectiv e wa y t o ensur e content moder ation on y our social media website."
  },
  {
    "number": "20",
    "text": "A global company hosts its web application on A maz on EC2 instances behind an A pplication Load Balancer (ALB). The web application has static data and dynamic data. The company st or es its static data in an A maz on S3 buck et. The company wants t o impr o v e per formance and r educe latency for the static data and dynamic data. The company is using its own domain name r egister ed with A maz on Route 53. What should a solutions ar chitect do t o meet these r equir ements? PAGE23",
    "options": [
      "Cr eate an Amaz on Cloud F r ont distribution that has the ALB as an origin. Cr eate an A WS Global Acceler at or standar d acceler at or that has the S3 buck et as an endpoint. Cr eate two domain names. P oint one domain name t o the Cloud F r ont DNS name for dynamic content. P oint the other domain name t o the acceler at or DNS name for static content. Use the domain names as endpoints for the web application.",
      "Cr eate an Amaz on Cloud F r ont distribution that has the S3 buck et as an origin. Cr eate an A WS Global Acceler at or standar d acceler at or that has the ALB and the Cloud F r ont distribution as endpoints. Cr eate a cust om domain name that points t o the acceler at or DNS name. Use the cust om domain name as an endpoint for the web application. Corr ect answer",
      "Cr eate an Amaz on Cloud F r ont distribution that has the S3 buck et and the ALB as origins. Conﬁgur e Route 53 t o r oute tr aﬃc t o the Cloud F r ont distribution. D . Cr eate an Amaz on Cloud F r ont distribution that has the ALB as an origin. Cr eate an A WS Global Acceler at or standar d acceler at or that has the S3 buck et as an endpoint Conﬁgur e Route 53 t o r oute tr aﬃc t o the Cloud F r ont distribution. Ov er all explanation Cr eate an Amaz on Cloud F r ont distribution that has the S3 buck et as an origin t o acceler ate the static content. Cr eate an A WS Global Acceler at or standar d acceler at or that has the ALB and the Cloud F r ont distribution as endpoints. Cr eate a cust om domain name that points t o the acceler at or DNS name. Use the cust om domain name as an endpoint for the web application.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "21",
    "text": "A n ecommer ce company needs t o run a scheduled daily job t o aggr egate and ﬁlter sales r ecor ds for analytics. The company st or es the sales r ecor ds in an A maz on S3 PAGE24 buck et. Each object can be up t o 10 GB in siz e. Based on the number of sales e v ents, the job can tak e up t o an hour t o complete. The CPU and memor y usage of the job ar e constant and ar e known in adv ance. A solutions ar chitect needs t o minimiz e the amount of oper ational effor t that is needed for the job t o run. Which solution meets these r equir ements?",
    "options": [
      "Cr eate an Amaz on Elastic Container Ser vice (Amaz on ECS) cluster with an A WS F ar gate launch type. Cr eate an Amaz on E v ent Bridge scheduled e v ent that launches an ECS task on the cluster t o run the job. Corr ect answer",
      "Cr eate an Amaz on Elastic Container Ser vice (Amaz on ECS) cluster with an Amaz on EC2 launch type and an A ut o Scaling gr oup with at least one EC2 instance. Cr eate an Amaz on E v ent Bridge scheduled e v ent that launches an ECS task on the cluster t o run the job.",
      "Cr eate an A WS Lambda function that has an Amaz on E v ent Bridge notiﬁcation. Schedule the E v ent Bridge e v ent t o run once a da y . D . Cr eate an A WS Lambda function. Cr eate an Amaz on API Gatewa y H T TP API, and integr ate the API with the function. Cr eate an Amaz on E v ent Bridge scheduled e v ent that calls the API and inv ok es the function. Ov er all explanation Using A WS F ar gate allows y ou t o run containers without managing the underlying infr astructur e. Using ECS with F ar gate for the scheduled task minimiz es oper ational o v erhead.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "22",
    "text": "A company hosts its multi-tier applications on A WS. F or compliance, go v ernance, auditing, and security , the company must tr ack conﬁgur ation changes on its A WS r esour ces and r ecor d a hist or y of API calls made t o these r esour ces. What should a solutions ar chitect do t o meet these r equir ements? PAGE25",
    "options": [
      "Use A WS Conﬁg t o tr ack conﬁgur ation changes and A WS Cloud T r ail t o r ecor d API calls. Corr ect answer",
      "Use A WS Cloud T r ail t o tr ack conﬁgur ation changes and A WS Conﬁg t o r ecor d API calls.",
      "Use A WS Cloud T r ail t o tr ack conﬁgur ation changes and Amaz on Cloud W atch t o r ecor d API calls. D . Use A WS Conﬁg t o tr ack conﬁgur ation changes and Amaz on Cloud W atch t o r ecor d API calls. Ov er all explanation A WS Conﬁg is speciﬁcally designed t o tr ack and r ecor d conﬁgur ation changes on A WS r esour ces. It pr o vides hist orical data on the state of y our r esour ces and allows y ou t o e v aluate changes o v er time. On the other hand, A WS Cloud T r ail is designed t o r ecor d API calls made on y our A WS account, pr o viding an audit tr ail for actions tak en via the A WS Management Console, A WS CLI, SDKs, etc. This combination allows y ou t o meet compliance, go v ernance, auditing, and security r equir ements eff ectiv ely .",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "23",
    "text": "A company wants t o migr ate its on-pr emises application t o A WS. The application pr oduces output ﬁles that v ar y in siz e fr om tens of gigab ytes t o hundr eds of ter ab ytes. The application data must be st or ed in a standar d ﬁle system structur e. The company wants a solution that scales aut omatically . is highly a v ailable, and r equir es minimum oper ational o v erhead. Which solution will meet these r equir ements? PAGE26",
    "options": [
      "Migr ate the application t o Amaz on EC2 instances in a Multi-AZ A ut o Scaling gr oup. Use Amaz on Elastic File System (Amaz on EFS) for st or age. Corr ect answer",
      "Migr ate the application t o run as containers on Amaz on Elastic Container Ser vice (Amaz on ECS). Use Amaz on S3 for st or age.",
      "Migr ate the application t o Amaz on EC2 instances in a Multi-AZ A ut o Scaling gr oup. Use Amaz on Elastic Block St or e (Amaz on EBS) for st or age. D . Migr ate the application t o run as containers on Amaz on Elastic K ubernetes Ser vice (Amaz on EKS). Use Amaz on Elastic Block St or e (Amaz on EBS) for st or age. Ov er all explanation Migr ate the application t o Amaz on EC2 instances in a Multi-AZ A ut o Scaling gr oup and use Amaz on Elastic File System (Amaz on EFS) for st or age. Her e ' s why this is a suitable choice: Scalability: Amaz on EFS can scale aut omatically as y our st or age needs gr ow , and it can handle v ar ying ﬁle siz es eﬃciently . High A v ailability: Multi-AZ deplo yment ensur es high a v ailability b y r eplicating data acr oss multiple A v ailability Z ones, making it r esilient t o failur es. Standar d File System Structur e: Amaz on EFS pr o vides an NFS-based ﬁle system, which off ers a standar d ﬁle system structur e that can be easily used b y applications. Minimum Oper ational Ov erhead: As a managed ser vice, Amaz on EFS abstr acts much of the oper ational o v erhead, lik e har dwar e pr o visioning and maintenance, fr om y ou. Ease of Integr ation: Amaz on EFS is easily integr ated with Amaz on EC2 instances, making it a seamless choice for migr ating y our application. While running containers with Amaz on ECS or Amaz on EKS could be an option, using Amaz on EFS simpliﬁes the st or age aspect and meets the r equir ement of a standar d ﬁle PAGE27 system structur e. Running on EC2 instances with Amaz on EFS pr o vides a simple and highly a v ailable solution with minimal oper ational o v erhead for ﬁle st or age.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "24",
    "text": "A company st or es call tr anscript ﬁles on a monthly basis. Users access the ﬁles r andomly within 1 y ear of the call, but users access the ﬁles infr equently after 1 y ear . The company wants t o optimiz e its solution b y giving users the ability t o quer y and r etrie v e ﬁles that ar e less than 1-y ear-old as quickly as possible. A dela y in r etrie ving older ﬁles is acceptable. Which solution will meet these r equir ements MOST cost-eff ectiv ely?",
    "options": [
      "St or e individual ﬁles in Amaz on S3 Standar d st or age. Use S3 Lif ecy cle policies t o mo v e the ﬁles t o S3 Glacier Deep Ar chiv e after 1 y ear . St or e sear ch metadata in Amaz on RDS. Quer y the ﬁles fr om Amaz on RDS. Retrie v e the ﬁles fr om S3 Glacier Deep Ar chiv e.",
      "St or e individual ﬁles with tags in Amaz on S3 Glacier Instant Retrie v al. Quer y the tags t o r etrie v e the ﬁles fr om S3 Glacier Instant Retrie v al.",
      "St or e individual ﬁles with tags in Amaz on S3 Standar d st or age. St or e sear ch metadata for each ar chiv e in Amaz on S3 Standar d st or age. Use S3 Lif ecy cle policies t o mo v e the ﬁles t o S3 Glacier Instant Retrie v al after 1 y ear . Quer y and r etrie v e the ﬁles b y sear ching for metadata fr om Amaz on S3. D . St or e individual ﬁles in Amaz on S3 Intelligent-Tiering. Use S3 Lif ecy cle policies t o mo v e the ﬁles t o S3 Glacier Flexible Retrie v al after 1 y ear . Quer y and r etrie v e the ﬁles that ar e in Amaz on S3 b y using Amaz on A thena. Quer y and r etrie v e the ﬁles that ar e in S3 Glacier b y using S3 Glacier Select. Corr ect answer Ov er all explanation A maz on S3 Intelligent-Tiering: This st or age class is designed t o optimiz e costs for data with unknown or changing access patterns. It aut omatically mo v es objects between two access tiers: fr equent and infr equent access. In y our case, this is suitable PAGE28 for the ﬁles that ar e accessed within the ﬁrst y ear (fr equent access) and the ones accessed less fr equently after 1 y ear (infr equent access). A maz on A thena for Quer ying: Y ou can use Amaz on A thena, an inter activ e quer y ser vice, t o quer y and r etrie v e the ﬁles that ar e still st or ed in the S3 Intelligent-Tiering access tiers. This allows y ou t o quickly access ﬁles that ar e less than 1 y ear old. S3 Glacier Select for Retrie v al: F or the ﬁles that ha v e tr ansitioned t o S3 Glacier (after 1 y ear), y ou can use S3 Glacier Select t o r etrie v e speciﬁc data fr om the ar chiv es without ha ving t o r est or e the entir e object. This pr o vides a cost-eff ectiv e r etrie v al mechanism for older ﬁles.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "25",
    "text": "A n ecommer ce company wants t o launch a one-deal-a-da y website on A WS. Each da y will f eatur e exactly one pr oduct on sale for a period of 24 hours. The company wants t o be able t o handle millions of r equests each hour with millisecond latency during peak hours. Which solution will meet these r equir ements with the LEAST oper ational o v erhead?",
    "options": [
      "Deplo y the full website on Amaz on EC2 instances that run in A ut o Scaling gr oups acr oss multiple A v ailability Z ones. Add an Application Load Balancer (ALB) t o distribute the website tr aﬃc. Add another ALB for the back end APIs. St or e the data in Amaz on RDS for My SQL.",
      "Use Amaz on S3 t o host the full website in diff er ent S3 buck ets. Add Amaz on Cloud F r ont distributions. Set the S3 buck ets as origins for the distributions. St or e the or der data in Amaz on S3.",
      "Use an Amaz on S3 buck et t o host the website ' s static content. Deplo y an Amaz on Cloud F r ont distribution. Set the S3 buck et as the origin. Use Amaz on API Gatewa y and A WS Lambda functions for the back end APIs. St or e the data in Amaz on Dynamo D",
      "Corr ect answer PAGE29 D . Migr ate the full application t o run in containers. Host the containers on Amaz on Elastic K ubernetes Ser vice (Amaz on EKS). Use the K ubernetes Cluster A ut oscaler t o incr ease and decr ease the number of pods t o pr ocess bursts in tr aﬃc. St or e the data in Amaz on RDS for My SQL. Ov er all explanation Scalability: Amaz on S3 and Amaz on Cloud F r ont ar e highly scalable and can handle millions of r equests with low latency . Amaz on S3 is gr eat for hosting static content, and Cloud F r ont pr o vides a content deliv er y network (CDN) t o cache content close t o end-users. Ser v erless Back end: Using Amaz on API Gatewa y and A WS Lambda for the back end APIs pr o vides ser v erless ar chitectur e, eliminating the oper ational o v erhead of managing ser v ers. A WS Lambda can aut omatically scale based on the incoming tr aﬃc, making it cost-eff ectiv e and eﬃcient. Database: Amaz on Dynamo DB is a highly scalable No SQL database that can handle the r equir ed thr oughput. It' s designed for low-latency , high-per formance applications and can scale as needed."
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "26",
    "text": "A solutions ar chitect is implementing a complex Ja v a application with a My SQL database. The Ja v a application must be deplo y ed on A pache T omcat and must be highly a v ailable. What should the solutions ar chitect do t o meet these r equir ements?",
    "options": [
      "Migr ate the database t o Amaz on Elasti Cache. Conﬁgur e the Elasti Cache security gr oup t o allow access fr om the application.",
      "Deplo y the application in A WS Lambda. Conﬁgur e an Amaz on API Gatewa y API t o connect with the Lambda functions.",
      "Launch an Amaz on EC2 instance. Install a My SQL ser v er on the EC2 instance. Conﬁgur e the application on the ser v er . Cr eate an AMI. Use the AMI t o cr eate a launch template with an A ut o Scaling gr oup. PAGE30 D . Deplo y the application b y using A WS Elastic Beanstalk. Conﬁgur e a load-balanced envir onment and a r olling deplo yment policy . Corr ect answer Ov er all explanation Deplo y the application b y using A WS Elastic Beanstalk. Conﬁgur e a load-balanced envir onment and a r olling deplo yment policy .",
      ""
    ],
    "correct_answer": null,
    "explanation": "Elastic Beanstalk: Elastic Beanstalk simpliﬁes the deplo yment and management of applications, including Ja v a applications running on Apache T omcat. Load-Balanced Envir onment: Conﬁguring a load-balanced envir onment ensur es high a v ailability and distribution of incoming tr aﬃc among multiple instances. Rolling Deplo yment P olicy: Elastic Beanstalk suppor ts r olling deplo yments, minimizing downtime during application updates b y gr adually r eplacing instances. Managed Envir onment: Elastic Beanstalk pr o vides a managed envir onment, handling capacity pr o visioning, load balancing, and aut omatic scaling. Eﬃcient Deplo yment: Rolling deplo yments ensur e eﬃcient and r eliable application updates without disrupting the a v ailability of the application."
  },
  {
    "number": "27",
    "text": "A company is migr ating a distributed application t o A WS. The application ser v es v ariable workloads. The legacy platform consists of a primar y ser v er that coor dinates jobs acr oss multiple compute nodes. The company wants t o moderniz e the application with a solution that maximiz es r esiliency and scalability . How should a solutions ar chitect design the ar chitectur e t o meet these r equir ements?",
    "options": [
      "Conﬁgur e an Amaz on Simple Queue Ser vice (Amaz on SQS) queue as a destination for the jobs. Implement the compute nodes with Amaz on EC2 instances that ar e managed in an A ut o Scaling gr oup. Conﬁgur e EC2 A ut o Scaling t o use scheduled scaling. PAGE31",
      "Implement the primar y ser v er and the compute nodes with Amaz on EC2 instances that ar e managed in an A ut o Scaling gr oup. Conﬁgur e Amaz on E v ent Bridge (Amaz on Cloud W atch E v ents) as a destination for the jobs. Conﬁgur e EC2 A ut o Scaling based on the load on the compute nodes.",
      "Conﬁgur e an Amaz on Simple Queue Ser vice (Amaz on SQS) queue as a destination for the jobs. Implement the compute nodes with Amaz on EC2 instances that ar e managed in an A ut o Scaling gr oup. Conﬁgur e EC2 A ut o Scaling based on the siz e of the queue. Corr ect answer D . Implement the primar y ser v er and the compute nodes with Amaz on EC2 instances that ar e managed in an A ut o Scaling gr oup. Conﬁgur e A WS Cloud T r ail as a destination for the jobs. Conﬁgur e EC2 A ut o Scaling based on the load on the primar y ser v er . Ov er all explanation A maz on SQS for Decoupling: Using Amaz on SQS t o queue jobs is a common and eff ectiv e appr oach for decoupling components in a distributed application. It ensur es that the primar y ser v er doesn 't ha v e t o be dir ectly connected t o the compute nodes, which allows for better scalability and fault t oler ance. A ut o Scaling based on Queue Siz e: By conﬁguring EC2 A ut o Scaling based on the siz e of the SQS queue, y ou can aut omatically adjust the number of compute nodes accor ding t o the incoming workload. This appr oach ensur es that y ou scale y our compute nodes dynamically in r esponse t o the workload, which aligns with the r equir ements for r esiliency and scalability .",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "28",
    "text": "A company is launching a new application and will displa y application metrics on an A maz on Cloud W atch dashboar d. The company ' s pr oduct manager needs t o access this dashboar d periodically . The pr oduct manager does not ha v e an A WS account. A solutions ar chitect must pr o vide access t o the pr oduct manager b y following the principle of least privilege. Which solution will meet these r equir ements? PAGE32",
    "options": [
      "Deplo y a bastion ser v er in a public subnet. When the pr oduct manager r equir es access t o the dashboar d, star t the ser v er and shar e the RDP cr edentials. On the bastion ser v er , ensur e that the br owser is conﬁgur ed t o open the dashboar d URL with cached A WS cr edentials that ha v e appr opriate permissions t o view the dashboar d.",
      "Cr eate an I AM user for the company ' s emplo y ees. A ttach the View Only Access A WS managed policy t o the I AM user . Shar e the new login cr edentials with the pr oduct manager . Ask the pr oduct manager t o na vigate t o the Cloud W atch console and locate the dashboar d b y name in the Dashboar ds section.",
      "Cr eate an I AM user speciﬁcally for the pr oduct manager . A ttach the Cloud W atch Read Only Access A WS managed policy t o the user . Shar e the new login cr edentials with the pr oduct manager . Shar e the br owser URL of the corr ect dashboar d with the pr oduct manager . Corr ect answer D . Shar e the dashboar d fr om the Cloud W atch console. Enter the pr oduct manager ' s email addr ess, and complete the sharing steps. Pr o vide a shar eable link for the dashboar d t o the pr oduct manager . Ov er all explanation I AM User: By cr eating an I AM user , y ou can gr ant the pr oduct manager speciﬁc and limited permissions for accessing Cloud W atch, in this case, r ead-only access. Least Privilege: A ttaching the Cloud W atch Read Only Access A WS managed policy ensur es that the pr oduct manager has the minimum r equir ed permissions t o view the dashboar d, aligning with the principle of least privilege. Login Cr edentials: Pr o viding the pr oduct manager with their own login cr edentials ensur es accountability and auditability . Dashboar d URL: Sharing the URL of the speciﬁc dashboar d allows the pr oduct manager t o access it dir ectly without na vigating thr ough the A WS Management Console, making it mor e user-friendly . PAGE33",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "29",
    "text": "A company is migr ating applications t o A WS. The applications ar e deplo y ed in diff er ent accounts. The company manages the accounts centr ally b y using A WS Or ganizations. The company ' s security team needs a single sign-on (SSO) solution acr oss all the company ' s accounts. The company must continue managing the users and gr oups in its on-pr emises self-managed Micr osoft Activ e Dir ect or y . Which solution will meet these r equir ements?",
    "options": [
      "Deplo y an identity pr o vider (Id P) on pr emises. Enable A WS Single Sign-On (A WS SSO) fr om the A WS SSO console.",
      "Use A WS Dir ect or y Ser vice. Cr eate a two-wa y trust r elationship with the company ' s self-managed Micr osoft Activ e Dir ect or y .",
      "Enable A WS Single Sign-On (A WS SSO) fr om the A WS SSO console. Cr eate a two-wa y for est trust t o connect the company ' s self-managed Micr osoft Activ e Dir ect or y with A WS SSO b y using A WS Dir ect or y Ser vice for Micr osoft Activ e Dir ect or y . Corr ect answer D . Enable A WS Single Sign-On (A WS SSO) fr om the A WS SSO console. Cr eate a one-wa y for est trust or a one-wa y domain trust t o connect the company ' s self-managed Micr osoft Activ e Dir ect or y with A WS SSO b y using A WS Dir ect or y Ser vice for Micr osoft Activ e Dir ect or y . Ov er all explanation A WS Single Sign-On (A WS SSO): A WS SSO is an identity management ser vice pr o vided b y Amaz on W eb Ser vices. It allows y ou t o centr ally manage SSO access t o multiple A WS accounts and applications. With A WS SSO , y ou can cr eate and manage users, gr ant permissions t o A WS accounts, and conﬁgur e SSO settings. T wo-W a y F or est T rust: In this context, a \"for est\" r ef ers t o a collection of one or mor e Activ e Dir ect or y domains that shar e a common schema. A trust is a r elationship established between domains or for ests t o allow users in one domain t o access r esour ces in another . PAGE34 Connecting with A WS SSO: T o enable SSO access t o A WS accounts fr om y our company ' s self-managed Micr osoft Activ e Dir ect or y , y ou cr eate a two-wa y trust between the on-pr emises AD for est and A WS SSO . Her e ' s a mor e detailed explanation of the steps inv olv ed: Enable A WS SSO: F r om the A WS SSO console, y ou enable A WS SSO . This sets up the SSO ser vice within y our A WS envir onment. Cr eate a T wo-W a y F or est T rust: Y ou establish a two-wa y trust r elationship between y our on-pr emises Activ e Dir ect or y for est and A WS SSO . This trust r elationship allows user authentication and authorization between y our on-pr emises AD and A WS SSO . Sync Users and Gr oups: A WS SSO allows y ou t o synchr oniz e users and gr oups fr om y our on-pr emises AD int o A WS SSO . This means that y our existing users and gr oups in y our self-managed AD can be used for access t o A WS r esour ces. Gr ant Access t o A WS Accounts: Once y our users and gr oups ar e synchr oniz ed, y ou can gr ant them access t o y our A WS accounts and applications, pr o viding the necessar y permissions. Single Sign-On: Users can then log in t o their A WS accounts and applications using their on-pr emises AD cr edentials without the need for separ ate A WS-speciﬁc usernames and passwor ds. The two-wa y trust allows users t o authenticate and access A WS ser vices using their existing on-pr emises cr edentials. This appr oach simpliﬁes user management and access contr ol acr oss both y our on-pr emises envir onment and A WS, making it a suitable solution for or ganizations that want t o maintain a single sour ce of user identity and cr edentials while using A WS ser vices.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "30",
    "text": "A company wants t o use the A WS Cloud t o mak e an existing application highly a v ailable and r esilient. The curr ent v ersion of the application r esides in the company ' s data center . The application r ecently experienced data loss after a database ser v er cr ashed because of an unexpected power outage. PAGE35 The company needs a solution that a v oids any single points of failur e. The solution must giv e the application the ability t o scale t o meet user demand. Which solution will meet these r equir ements?",
    "options": [
      "Deplo y the application ser v ers b y using Amaz on EC2 instances in an A ut o Scaling gr oup acr oss multiple A v ailability Z ones. Use an Amaz on RDS DB instance in a Multi-AZ conﬁgur ation. Corr ect answer",
      "Deplo y the application ser v ers b y using Amaz on EC2 instances in an A ut o Scaling gr oup in a single A v ailability Z one. Deplo y the database on an EC2 instance. Enable EC2 A ut o Reco v er y .",
      "Deplo y the application ser v ers b y using Amaz on EC2 instances in an A ut o Scaling gr oup acr oss multiple A v ailability Z ones. Deplo y the primar y and secondar y database ser v ers on EC2 instances acr oss multiple A v ailability Z ones. Use Amaz on Elastic Block St or e (Amaz on EBS) Multi-A ttach t o cr eate shar ed st or age between the instances. D . Deplo y the application ser v ers b y using Amaz on EC2 instances in an A ut o Scaling gr oup acr oss multiple A v ailability Z ones. Use an Amaz on RDS DB instance with a r ead r eplica in a single A v ailability Z one. Pr omote the r ead r eplica t o r eplace the primar y DB instance if the primar y DB instance fails. Ov er all explanation Deplo y the application ser v ers b y using Amaz on EC2 instances in an A ut o Scaling gr oup acr oss multiple A v ailability Z ones. Use an Amaz on RDS DB instance in a Multi-AZ conﬁgur ation.",
      ""
    ],
    "correct_answer": null,
    "explanation": "Deplo ying the application ser v ers acr oss multiple A v ailability Z ones (AZs) in an A ut o Scaling gr oup ensur es high a v ailability and a v oids single points of failur e. Using Amaz on RDS with Multi-AZ conﬁgur ation for the database pr o vides aut omatic failo v er in the e v ent of a failur e in the primar y database instance, enhancing r esilience. This ar chitectur e suppor ts scalability b y utilizing A ut o Scaling for the application ser v ers, allowing them t o scale based on demand. PAGE36 The Multi-AZ conﬁgur ation for RDS also enhances data dur ability b y maintaining synchr onous copies of the database in diff er ent AZs. Ov er all, this solution meets the r equir ements of high a v ailability , r esilience, and scalability ."
  },
  {
    "number": "31",
    "text": "A company is implementing a shar ed st or age solution for a gaming application that is hosted in the A WS Cloud. The company needs the ability t o use L ustr e clients t o access data. The solution must be fully managed. Which solution meets these r equir ements?",
    "options": [
      "Cr eate an A WS Data Sync task that shar es the data as a mountable ﬁle system. Mount the ﬁle system t o the application ser v er .",
      "Cr eate an Amaz on Elastic File System (Amaz on EFS) ﬁle system, and conﬁgur e it t o suppor t L ustr e. A ttach the ﬁle system t o the origin ser v er . Connect the application ser v er t o the ﬁle system.",
      "Cr eate an A WS St or age Gatewa y ﬁle gatewa y . Cr eate a ﬁle shar e that uses the r equir ed client pr ot ocol. Connect the application ser v er t o the ﬁle shar e. D . Cr eate an Amaz on FSx for L ustr e ﬁle system. A ttach the ﬁle system t o the origin ser v er . Connect the application ser v er t o the ﬁle system. Corr ect answer Ov er all explanation Cr eate an Amaz on FSx for L ustr e ﬁle system. A ttach the ﬁle system t o the origin ser v er . Connect the application ser v er t o the ﬁle system.",
      ""
    ],
    "correct_answer": null,
    "explanation": "Amaz on FSx for L ustr e is a fully managed, high-per formance ﬁle system that can be used t o suppor t L ustr e clients. It pr o vides dur ability , high thr oughput, and low latency for applications that r equir e fast access t o shar ed data. PAGE37 Using FSx for L ustr e is the r ecommended solution for fully managed shar ed st or age with L ustr e client suppor t."
  },
  {
    "number": "32",
    "text": "A company is running a cust om application on A maz on EC2 On-Demand Instances. The application has fr ontend nodes that need t o run 24 hours a da y , 7 da ys a week and back end nodes that need t o run only for a shor t time based on workload. The number of back end nodes v aries during the da y . The company needs t o scale out and scale in mor e instances based on workload. Which solution will meet these r equir ements MOST cost-eff ectiv ely?",
    "options": [
      "Use Spot Instances for the fr ontend nodes. Use A WS F ar gate for the back end nodes.",
      "Use Spot Instances for the fr ontend nodes. Use Reser v ed Instances for the back end nodes.",
      "Use Reser v ed Instances for the fr ontend nodes. Use Spot Instances for the back end nodes. Corr ect answer D . Use Reser v ed Instances for the fr ontend nodes. Use A WS F ar gate for the back end nodes. Ov er all explanation Use Reser v ed Instances for the fr ontend nodes. Use Spot Instances for the back end nodes.",
      ""
    ],
    "correct_answer": null,
    "explanation": "Reser v ed Instances (RIs): RIs pr o vide signiﬁcant cost sa vings for pr edictable workloads with fr ontend nodes running 24/7. PAGE38 Spot Instances: Spot Instances ar e cost-eff ectiv e for v ariable and shor t-liv ed workloads, making them suitable for back end nodes with v ar ying demand. F r ontend Nodes Stability: Using RIs for fr ontend nodes ensur es stable, continuous a v ailability without interruption. Back end Nodes Cost-E ff ectiv e Scaling: Spot Instances allow cost-eff ectiv e scaling for back end nodes, meeting the v ar ying workload r equir ements. Cost Optimization: This combination pr o vides a cost-eff ectiv e solution b y le v er aging RIs for stability and Spot Instances for scalability ."
  },
  {
    "number": "33",
    "text": "A n image-hosting company st or es its objects in A maz on S3 buck ets. The company wants t o a v oid accidental exposur e of the objects in the S3 buck ets t o the public. All S3 objects in the entir e A WS account need t o r emain priv ate. Which solution will meet these r equir ements?",
    "options": [
      "Use Amaz on Guar d Duty t o monit or S3 buck et policies. Cr eate an aut omatic r emediation action rule that uses an A WS Lambda function t o r emediate any change that mak es the objects public.",
      "Use A WS T rusted Advisor t o ﬁnd publicly accessible S3 buck ets. Conﬁgur e email notiﬁcations in T rusted Advisor when a change is detected. Manually change the S3 buck et policy if it allows public access.",
      "Use the S3 Block Public Access f eatur e on the account le v el. Use A WS Or ganizations t o cr eate a ser vice contr ol policy (SCP) that pr e v ents I AM users fr om changing the setting. Apply the SCP t o the account. Corr ect answer D . Use A WS Resour ce Access Manager t o ﬁnd publicly accessible S3 buck ets. Use Amaz on Simple Notiﬁcation Ser vice (Amaz on SNS) t o inv ok e an A WS Lambda function when a change is detected. Deplo y a Lambda function that pr ogr ammatically r emediates the change. PAGE39 Ov er all explanation Use the S3 Block Public Access f eatur e on the account le v el. Use A WS Or ganizations t o cr eate a ser vice contr ol policy (SCP) that pr e v ents I AM users fr om changing the setting. Apply the SCP t o the account.",
      ""
    ],
    "correct_answer": null,
    "explanation": "S3 Block Public Access: Enabling this f eatur e on the account le v el ensur es that no S3 objects in any buck et can be made public. A WS Or ganizations SCP: A ser vice contr ol policy (SCP) in A WS Or ganizations allows y ou t o set ﬁne-gr ained permissions and r estrictions acr oss accounts. Pr e v enting Changes: By cr eating an SCP that r estricts the modiﬁcation of S3 Block Public Access settings, y ou enfor ce the least privilege principle. A ut omation: Using SCPs helps aut omate and centr ally manage access policies acr oss multiple accounts. Compliance with Security P olicy: This solution aligns with the security policy of k eeping all S3 objects priv ate."
  },
  {
    "number": "34",
    "text": "A de v eloper has an application that uses an A WS Lambda function t o upload ﬁles t o A maz on S3 and needs the r equir ed permissions t o per form the task. The de v eloper alr eady has an I AM user with v alid I AM cr edentials r equir ed for A maz on S3. What should a solutions ar chitect do t o gr ant the permissions?",
    "options": [
      "Cr eate a signed r equest using the existing I AM cr edentials in the Lambda function.",
      "Cr eate a new I AM user and use the existing I AM cr edentials in the Lambda function.",
      "Cr eate an I AM ex ecution r ole with the r equir ed permissions and attach the I AM r ole t o the Lambda function. Corr ect answer PAGE40 D . Add r equir ed I AM permissions in the r esour ce policy of the Lambda function. Ov er all explanation Cr eate an I AM ex ecution r ole with the r equir ed permissions and attach the I AM r ole t o the Lambda function.",
      ""
    ],
    "correct_answer": null,
    "explanation": "Lambda functions r equir e ex ecution r oles t o gr ant permissions t o access A WS ser vices. Cr eating an I AM ex ecution r ole with the necessar y permissions for S3 access and attaching it t o the Lambda function ensur es that the function has the r equir ed permissions t o upload ﬁles t o S3. The I AM user cr edentials ar e not used dir ectly within the Lambda function; instead, an I AM r ole is assumed."
  },
  {
    "number": "35",
    "text": "A de v elopment team runs monthly r esour ce-intensiv e tests on its gener al purpose A maz on RDS for My SQL DB instance with P er formance Insights enabled. The testing lasts for 48 hours once a month and is the only pr ocess that uses the database. The team wants t o r educe the cost of running the tests without r educing the compute and memor y attributes of the DB instance. Which solution meets these r equir ements MOST cost-eff ectiv ely?",
    "options": [
      "Modify the DB instance t o a low-capacity instance when tests ar e completed. Modify the DB instance again when r equir ed.",
      "St op the DB instance when tests ar e completed. Restar t the DB instance when r equir ed.",
      "Use an A ut o Scaling policy with the DB instance t o aut omatically scale when tests ar e completed. PAGE41 D . Cr eate a snapshot when tests ar e completed. T erminate the DB instance and r est or e the snapshot when r equir ed. Corr ect answer Ov er all explanation Cost Eﬃciency: By terminating the DB instance when not in use, y ou eliminate the ongoing costs associated with running the RDS instance. Y ou only incur costs for the st or age of the snapshot, which is typically less expensiv e than running a full RDS instance. Isolation: T erminating the instance pr o vides isolation between the r esour ce-intensiv e testing period and r egular oper ation. This ensur es that the tests don 't impact the per formance or r esour ce a v ailability of the database during normal oper ations. Quick Reco v er y: Rest oring the database fr om a snapshot is a r elativ ely quick pr ocess. It allows y ou t o quickly pr epar e and set up the RDS instance in the desir ed state for testing when needed.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "36",
    "text": "A company has an application that ingests incoming messages. Do z ens of other applications and micr oser vices then quickly consume these messages. The number of messages v aries dr astically and sometimes incr eases suddenly t o 100,000 each second. The company wants t o decouple the solution and incr ease scalability . Which solution meets these r equir ements?",
    "options": [
      "P ersist the messages t o Amaz on Kinesis Data Analytics. Conﬁgur e the consumer applications t o r ead and pr ocess the messages.",
      "Publish the messages t o an Amaz on Simple Notiﬁcation Ser vice (Amaz on SNS) t opic with multiple Amaz on Simple Queue Ser vice (Amaz on SOS) subscriptions. Conﬁgur e the consumer applications t o pr ocess the messages fr om the queues. Corr ect answer",
      "Deplo y the ingestion application on Amaz on EC2 instances in an A ut o Scaling gr oup t o scale the number of EC2 instances based on CPU metrics. PAGE42 D . W rite the messages t o Amaz on Kinesis Data Str eams with a single shar d. Use an A WS Lambda function t o pr epr ocess messages and st or e them in Amaz on Dynamo D",
      "Conﬁgur e the consumer applications t o r ead fr om Dynamo DB t o pr ocess the messages. Ov er all explanation Decoupling and Scalability: Amaz on SNS and Amaz on SQS ar e designed for decoupling and scaling applications. SNS allows y ou t o publish messages t o t opics, and subscribers can r eceiv e those messages asynchr onously . By using multiple SQS subscriptions t o an SNS t opic, y ou can ensur e that multiple consumer applications can independently pr ocess the messages at their own r ates. Handling V ar ying Message Rates: SNS and SQS can eﬃciently handle v ar ying message r ates. As the number of incoming messages ﬂuctuates, A WS aut omatically scales SQS and the consumer applications as needed. This ensur es that the system can handle sudden incr eases in the message r ate, such as 100,000 messages per second. Reliability and Dur ability: Amaz on SQS pr o vides message dur ability and r eliability . Messages ar e st or ed r edundantly , and the system is designed t o ensur e that messages ar e not lost in tr ansit. This is crucial for handling a high v olume of messages."
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "37",
    "text": "A company is building an application in the A WS Cloud. The application will st or e data in A maz on S3 buck ets in two A WS Regions. The company must use an A WS K e y Management Ser vice (A WS KMS) cust omer managed k e y t o encr ypt all data that is st or ed in the S3 buck ets. The data in both S3 buck ets must be encr ypted and decr ypted with the same KMS k e y . The data and the k e y must be st or ed in each of the two Regions. Which solution will meet these r equir ements with the LEAST oper ational o v erhead?",
    "options": [
      "Cr eate a cust omer managed multi-Region KMS k e y . Cr eate an S3 buck et in each Region. Conﬁgur e r eplication between the S3 buck ets. Conﬁgur e the application t o use the KMS k e y with client-side encr yption. Corr ect answer PAGE43",
      "Cr eate an S3 buck et in each Region. Conﬁgur e the S3 buck ets t o use ser v er-side encr yption with Amaz on S3 managed encr yption k e ys (SSE-S3). Conﬁgur e r eplication between the S3 buck ets.",
      "Cr eate a cust omer managed KMS k e y and an S3 buck et in each Region. Conﬁgur e the S3 buck ets t o use ser v er-side encr yption with A WS KMS k e ys (SSE-KMS). Conﬁgur e r eplication between the S3 buck ets. D . Cr eate a cust omer managed KMS k e y and an S3 buck et in each Region. Conﬁgur e the S3 buck ets t o use ser v er-side encr yption with Amaz on S3 managed encr yption k e ys (SSE-S3). Conﬁgur e r eplication between the S3 buck ets. Ov er all explanation Cr eate a cust omer managed multi-Region KMS k e y . Cr eate an S3 buck et in each Region. Conﬁgur e r eplication between the S3 buck ets. Conﬁgur e the application t o use the KMS k e y with client-side encr yption. With this appr oach, y ou cr eate a single cust omer managed KMS k e y that' s a v ailable in multiple A WS Regions. This k e y can be used t o encr ypt and decr ypt data in both Regions consistently . Y ou then conﬁgur e S3 buck ets in each Region t o use ser v er-side encr yption with A WS KMS k e ys (SSE-KMS) and associate them with this multi-Region KMS k e y . Conﬁguring r eplication between the S3 buck ets ensur es that data is synchr oniz ed between the two Regions. Client-side encr yption would inv olv e the application itself handling encr yption, which ma y r equir e mor e oper ational o v erhead compar ed t o using ser v er-side encr yption with KMS k e ys. This appr oach also aligns with the r equir ement of using the same KMS k e y for encr yption and decr yption in both Regions.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "38",
    "text": "A company needs a backup str ategy for its thr ee-tier stateless web application. The web application runs on A maz on EC2 instances in an A ut o Scaling gr oup with a dynamic scaling policy that is conﬁgur ed t o r espond t o scaling e v ents. The database tier runs on A maz on RDS for P ostgr e SQL. The web application does not r equir e tempor ar y local st or age on the EC2 instances. The company ’ s r eco v er y point objectiv e (RPO) is 2 hours. PAGE44 The backup str ategy must maximiz e scalability and optimiz e r esour ce utilization for this envir onment. Which solution will meet these r equir ements?",
    "options": [
      "T ak e snapshots of Amaz on Elastic Block St or e (Amaz on EBS) v olumes of the EC2 instances and database e v er y 2 hours t o meet the RPO .",
      "Retain the latest Amaz on Machine Images (AMIs) of the web and application tiers. Enable aut omated backups in Amaz on RDS and use point-in-time r eco v er y t o meet the RPO . Corr ect answer",
      "Conﬁgur e a snapshot lif ecy cle policy t o tak e Amaz on Elastic Block St or e (Amaz on EBS) snapshots. Enable aut omated backups in Amaz on RDS t o meet the RPO . D . T ak e snapshots of Amaz on Elastic Block St or e (Amaz on EBS) v olumes of the EC2 instances e v er y 2 hours. Enable aut omated backups in Amaz on RDS and use point-in-time r eco v er y t o meet the RPO . Ov er all explanation Since the application has no local data on instances, AMIs alone can meet the RPO b y r est oring instances fr om the most r ecent AMI backup. When combined with aut omated RDS backups for the database, this pr o vides a complete backup solution for this envir onment. The other options inv olving EBS snapshots would be unnecessar y giv en the stateless natur e of the instances. AMIs pr o vide all the backup needed for the app tier . This uses nativ e, aut omated A WS backup f eatur es that r equir e minimal ongoing management: - AMI aut omated backups pr o vide point-in-time r eco v er y for the stateless app tier . - RDS aut omated backups pr o vide point-in-time r eco v er y for the database.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "39",
    "text": "A company has a thr ee-tier web application that is deplo y ed on A WS. The web ser v ers ar e deplo y ed in a public subnet in a VP",
    "options": [
      "The application ser v ers and database ser v ers ar e deplo y ed in priv ate subnets in the same VP",
      "The company has deplo y ed a PAGE45 thir d-par ty vir tual ﬁr ewall appliance fr om A WS Mark etplace in an inspection VP",
      "The appliance is conﬁgur ed with an IP inter face that can accept IP pack ets. A solutions ar chitect needs t o integr ate the web application with the appliance t o inspect all tr aﬃc t o the application befor e the tr aﬃc r eaches the web ser v er . Which solution will meet these r equir ements with the LEAST oper ational o v erhead?",
      "Deplo y a Gatewa y Load Balancer in the inspection VP",
      "Cr eate a Gatewa y Load Balancer endpoint t o r eceiv e the incoming pack ets and for war d the pack ets t o the appliance.",
      "Cr eate a Network Load Balancer in the public subnet of the application ' s VPC t o r oute the tr aﬃc t o the appliance for pack et inspection. Corr ect answer",
      "Cr eate an Application Load Balancer in the public subnet of the application ' s VPC t o r oute the tr aﬃc t o the appliance for pack et inspection. D . Deplo y a tr ansit gatewa y in the inspection VPConﬁgur e r oute tables t o r oute the incoming pack ets thr ough the tr ansit gatewa y . Ov er all explanation Network Load Balancer (NLB): NLB is designed for high a v ailability and ultr a-low latency at the tr anspor t la y er (La y er 4). It' s a suitable choice for r outing tr aﬃc t o the appliance for pack et inspection without much o v erhead. Least Oper ational Ov erhead: NLB is a simple and str aightfor war d solution for r outing tr aﬃc t o the appliance. It doesn 't intr oduce additional complexity compar ed t o some of the other options."
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "40",
    "text": "A company is deplo ying a new application on A maz on EC2 instances. The application writes data t o A maz on Elastic Block St or e (A maz on EBS) v olumes. The company needs t o ensur e that all data that is written t o the EBS v olumes is encr ypted at r est. Which solution will meet this r equir ement? PAGE46",
    "options": [
      "Cr eate an A WS K e y Management Ser vice (A WS KMS) k e y policy that enfor ces EBS encr yption in the account. Ensur e that the k e y policy is activ e.",
      "Cr eate an EC2 instance tag that has a k e y of Encr ypt and a v alue of T rue. T ag all instances that r equir e encr yption at the EBS le v el.",
      "Cr eate an I AM r ole that speciﬁes EBS encr yption. A ttach the r ole t o the EC2 instances. D . Cr eate the EBS v olumes as encr ypted v olumes. A ttach the EBS v olumes t o the EC2 instances. Corr ect answer Ov er all explanation Cr eate the EBS v olumes as encr ypted v olumes. A ttach the EBS v olumes t o the EC2 instances.",
      ""
    ],
    "correct_answer": null,
    "explanation": "Cr eating EBS v olumes as encr ypted v olumes ensur es that all data written t o those v olumes is encr ypted at r est. This pr o vides data security for the application running on EC2 instances."
  },
  {
    "number": "41",
    "text": "A de v elopment team needs t o host a website that will be accessed b y other teams. The website contents consist of H TML, CSS, client-side Ja v a Script, and images. Which method is the MOST cost-eff ectiv e for hosting the website?",
    "options": [
      "Cr eate an Amaz on S3 buck et and host the website ther e. Corr ect answer",
      "Containeriz e the website and host it in A WS F ar gate.",
      "Conﬁgur e an Application Load Balancer with an A WS Lambda tar get that uses the Expr ess.js fr amework. PAGE47 D . Deplo y a web ser v er on an Amaz on EC2 instance t o host the website. Ov er all explanation This is the most cost-eff ectiv e option for hosting a simple static website consisting of H TML, CSS, client-side Ja v a Script, and images. Amaz on S3 is designed for scalable and cost-eff ectiv e st or age of objects, making it ideal for ser ving static content lik e a website. Y ou can conﬁgur e the S3 buck et t o act as a static website host, and it can ser v e y our website content dir ectly t o users without the need for additional ser v ers or containers. It' s a simple and eﬃcient wa y t o host static content while k eeping costs low .",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "42",
    "text": "A r apidly gr owing global ecommer ce company is hosting its web application on A WS. The web application includes static content and dynamic content. The website st or es online tr ansaction pr ocessing (OL TP) data in an A maz on RDS database The website ’ s users ar e experiencing slow page loads. Which combination of actions should a solutions ar chitect tak e t o r esolv e this issue? (Choose two.)",
    "options": [
      "Conﬁgur e an Amaz on Redshift cluster .",
      "Cr eate a r ead r eplica for the RDS DB instance. Corr ect answer",
      "Conﬁgur e a Multi-AZ deplo yment for the RDS DB instance. D . Set up an Amaz on Cloud F r ont distribution. Corr ect answer E. Host the dynamic web content in Amaz on S3. Ov er all explanation Set up an Amaz on Cloud F r ont distribution. Cr eate a r ead r eplica for the RDS DB instance.",
      ""
    ],
    "correct_answer": null,
    "explanation": "PAGE48 A maz on Cloud F r ont: Distributing static content thr ough Cloud F r ont acceler ates page loads b y caching content at edge locations globally , r educing latency . Read Replicas: Cr eating r ead r eplicas for the RDS DB instance oﬄoads r ead oper ations, impr o ving o v er all database per formance. Global Content Deliv er y: Cloud F r ont' s global network ensur es faster content deliv er y t o users ar ound the world, enhancing the user experience. Optimizing Database Load: Read r eplicas distribute r ead tr aﬃc, pr e v enting the primar y database fr om being o v erloaded, especially during peak times. Scalability: Both Cloud F r ont and RDS r ead r eplicas contribute t o impr o v ed scalability and per formance of the web application."
  },
  {
    "number": "43",
    "text": "A company runs its infr astructur e on A WS and has a r egister ed base of 700,000 users for its document management application. The company intends t o cr eate a pr oduct that conv er ts lar ge .pdf ﬁles t o .jpg image ﬁles. The .pdf ﬁles a v er age 5 MB in siz e. The company needs t o st or e the original ﬁles and the conv er ted ﬁles. A solutions ar chitect must design a scalable solution t o accommodate demand that will gr ow r apidly o v er time. Which solution meets these r equir ements MOST cost-eff ectiv ely?",
    "options": [
      "Upload the .pdf ﬁles t o an A WS Elastic Beanstalk application that includes Amaz on EC2 instances, Amaz on Elastic Block St or e (Amaz on EBS) st or age, and an A ut o Scaling gr oup. Use a pr ogr am in the EC2 instances t o conv er t the ﬁles t o .jpg format. Sa v e the .pdf ﬁles and the .jpg ﬁles in the EBS st or e.",
      "Upload the .pdf ﬁles t o an A WS Elastic Beanstalk application that includes Amaz on EC2 instances, Amaz on Elastic File System (Amaz on EFS) st or age, and PAGE49 an A ut o Scaling gr oup. Use a pr ogr am in the EC2 instances t o conv er t the ﬁle t o .jpg format. Sa v e the .pdf ﬁles and the .jpg ﬁles in the EBS st or e.",
      "Sa v e the .pdf ﬁles t o Amaz on Dynamo DUse the Dynamo DB Str eams f eatur e t o inv ok e an A WS Lambda function t o conv er t the ﬁles t o .jpg format and st or e them back in Dynamo D",
      "D . Sa v e the .pdf ﬁles t o Amaz on S3. Conﬁgur e an S3 PUT e v ent t o inv ok e an A WS Lambda function t o conv er t the ﬁles t o .jpg format and st or e them back in Amaz on S3. Corr ect answer Ov er all explanation Sa v e the .pdf ﬁles t o Amaz on S3. Conﬁgur e an S3 PUT e v ent t o inv ok e an A WS Lambda function t o conv er t the ﬁles t o .jpg format and st or e them back in Amaz on S3."
    ],
    "correct_answer": null,
    "explanation": "This solution is the most cost-eff ectiv e and scalable among the pr o vided options. It le v er ages Amaz on S3 for st or age, which is highly scalable, dur able, and designed for object st or age. Using S3 PUT e v ents t o trigger an A WS Lambda function for conv ersion allows for a ser v erless, e v ent-driv en ar chitectur e that can aut omatically scale based on demand. A WS Lambda scales aut omatically , and y ou only pa y for the compute r esour ces used during ex ecution."
  },
  {
    "number": "44",
    "text": "A company needs the ability t o analyz e the log ﬁles of its pr oprietar y application. The logs ar e st or ed in JSON format in an A maz on S3 buck et. Queries will be simple and will run on-demand. A solutions ar chitect needs t o per form the analysis with minimal changes t o the existing ar chitectur e. What should the solutions ar chitect do t o meet these r equir ements with the LEAST amount of oper ational o v erhead? PAGE50",
    "options": [
      "Use Amaz on Redshift t o load all the content int o one place and run the SQL queries as needed.",
      "Use Amaz on Cloud W atch Logs t o st or e the logs. Run SQL queries as needed fr om the Amaz on Cloud W atch console.",
      "Use A WS Glue t o catalog the logs. Use a tr ansient Apache Spark cluster on Amaz on EMR t o run the SQL queries as needed. D . Use Amaz on A thena dir ectly with Amaz on S3 t o run the queries as needed. Corr ect answer Ov er all explanation Minimal Oper ational Ov erhead: Amaz on A thena is a ser v erless quer y ser vice that allows y ou t o run SQL queries dir ectly on data st or ed in Amaz on S3. Ther e is no need t o pr o vision or manage ser v ers, clusters, or infr astructur e. This signiﬁcantly r educes oper ational o v erhead, as y ou only need t o focus on running y our queries. Simple Integr ation: Amaz on A thena seamlessly integr ates with data st or ed in Amaz on S3, including JSON-formatted data. Ther e ' s no need t o mo v e or tr ansform the data, making it the most str aightfor war d solution for analyzing log ﬁles with minimal ar chitectur al changes. On-Demand Queries: Amaz on A thena allows y ou t o run queries on-demand. Y ou only pa y for the queries y ou ex ecute, which is cost-eff ectiv e and aligns well with y our simple, on-demand quer y r equir ements. Suppor t for SQL Queries: Amaz on A thena suppor ts standar d SQL queries, making it easy t o write and ex ecute the queries needed for log ﬁle analysis.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "45",
    "text": "A company is hosting a web application on A WS using a single A maz on EC2 instance that st or es user-uploaded documents in an A maz on EBS v olume. F or better scalability and a v ailability , the company duplicated the ar chitectur e and cr eated a second EC2 instance and EBS v olume in another A v ailability Z one, placing both behind an PAGE51 A pplication Load Balancer . After completing this change, users r epor ted that, each time the y r efr eshed the website, the y could see one subset of their documents or the other , but ne v er all of the documents at the same time. What should a solutions ar chitect pr opose t o ensur e users see all of their documents at once?",
    "options": [
      "Conﬁgur e the Application Load Balancer t o dir ect a user t o the ser v er with the documents",
      "Cop y the data so both EBS v olumes contain all the documents",
      "Conﬁgur e the Application Load Balancer t o send the r equest t o both ser v ers. Return each document fr om the corr ect ser v er D . Cop y the data fr om both EBS v olumes t o Amaz on EFS. Modify the application t o sa v e new documents t o Amaz on EFS. Corr ect answer Ov er all explanation Data Consistency: Amaz on EFS is a managed ﬁle st or age ser vice that pr o vides a shar ed, scalable ﬁle system accessible fr om multiple EC2 instances. By cop ying the data fr om both EBS v olumes t o Amaz on EFS, y ou ensur e that both EC2 instances ha v e access t o the same set of documents. This eliminates the issue of users seeing diff er ent subsets of their documents. Scalability and A v ailability: Amaz on EFS is designed for high a v ailability and can be mounted b y multiple EC2 instances acr oss diff er ent A v ailability Z ones. This aligns with y our goal of better scalability and a v ailability . Real-Time Data Access: By sa ving new documents t o Amaz on EFS, y ou ensur e that any newly uploaded documents ar e immediately accessible t o both EC2 instances. This is crucial for maintaining data consistency and ensuring users can see all their documents at once.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "46",
    "text": "A company has an on-pr emises application that gener ates a lar ge amount of time-sensitiv e data that is back ed up t o A maz on S3. The application has gr own and PAGE52 ther e ar e user complaints about internet bandwidth limitations. A solutions ar chitect needs t o design a long-term solution that allows for both timely backups t o A maz on S3 and with minimal impact on internet connectivity for internal users. Which solution meets these r equir ements?",
    "options": [
      "Submit a suppor t tick et thr ough the A WS Management Console. Request the r emo v al of S3 ser vice limits fr om the account.",
      "Establish A WS VPN connections and pr o xy all tr aﬃc thr ough a VPC gatewa y endpoint.",
      "Establish a new A WS Dir ect Connect connection and dir ect backup tr aﬃc thr ough this new connection. Corr ect answer D . Or der daily A WS Snowball de vices. Load the data ont o the Snowball de vices and r eturn the de vices t o A WS each da y . Ov er all explanation A WS Dir ect Connect pr o vides a dedicated network connection fr om y our on-pr emises data center t o A WS. It off ers a mor e r eliable and higher bandwidth connection compar ed t o typical internet connections. By establishing a new A WS Dir ect Connect connection speciﬁcally for the backup tr aﬃc, y ou can ensur e that backups ar e sent t o Amaz on S3 with minimal impact on y our internet connectivity for internal users. This allows y ou t o tak e adv antage of the dedicated network connection for y our backup needs. A WS Snowball (option D) is not ideal for time-sensitiv e data since it inv olv es manual data tr ansf er and shipping, which ma y not pr o vide the r equir ed speed for timely backups. Submitting a suppor t tick et (option A) is not a solution t o addr ess bandwidth limitations, and A WS ser vice limits do not apply t o this scenario.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "47",
    "text": "A company that hosts its web application on A WS wants t o ensur e all A maz on EC2 instances. A maz on RDS DB instances. and A maz on Redshift clusters ar e conﬁgur ed PAGE53 with tags. The company wants t o minimiz e the effor t of conﬁguring and oper ating this check. What should a solutions ar chitect do t o accomplish this?",
    "options": [
      "Use A WS Conﬁg rules t o deﬁne and detect r esour ces that ar e not pr operly tagged. Corr ect answer",
      "W rite API calls t o check all r esour ces for pr oper tag allocation. P eriodically run the code on an EC2 instance.",
      "W rite API calls t o check all r esour ces for pr oper tag allocation. Schedule an A WS Lambda function thr ough Amaz on Cloud W atch t o periodically run the code. D . Use Cost Explor er t o displa y r esour ces that ar e not pr operly tagged. T ag those r esour ces manually . Ov er all explanation A WS Conﬁg rules ar e designed t o help assess and monit or the conﬁgur ation of A WS r esour ces, including their tag compliance. By cr eating a cust om A WS Conﬁg rule, y ou can deﬁne the tagging r equir ements for y our Amaz on EC2 instances, RDS DB instances, and Redshift clusters. This rule can check whether the necessar y tags ar e pr esent and pr operly allocated t o these r esour ces. If a r esour ce is found t o be non-compliant with the tagging r equir ements, A WS Conﬁg can aut omatically ﬂag it, allowing y ou t o tak e corr ectiv e actions. This appr oach is mor e aut omated and r equir es less manual effor t compar ed t o options B, C, and D . With A WS Conﬁg, y ou can continuously monit or and enfor ce tagging standar ds without the need for manual checks or cust om code. Additionally , A WS Conﬁg off ers r eal-time visibility int o y our r esour ce compliance status.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "48",
    "text": "A company is designing an application. The application uses an A WS Lambda function t o r eceiv e information thr ough A maz on API Gatewa y and t o st or e the information in an A maz on A ur or a P ostgr e SQL database. PAGE54 During the pr oof-of-concept stage, the company has t o incr ease the Lambda quotas signiﬁcantly t o handle the high v olumes of data that the company needs t o load int o the database. A solutions ar chitect must r ecommend a new design t o impr o v e scalability and minimiz e the conﬁgur ation effor t. Which solution will meet these r equir ements?",
    "options": [
      "Set up two Lambda functions. Conﬁgur e one function t o r eceiv e the information. Conﬁgur e the other function t o load the information int o the database. Integr ate the Lambda functions b y using an Amaz on Simple Queue Ser vice (Amaz on SQS) queue.",
      "Set up two Lambda functions. Conﬁgur e one function t o r eceiv e the information. Conﬁgur e the other function t o load the information int o the database. Integr ate the Lambda functions b y using Amaz on Simple Notiﬁcation Ser vice (Amaz on SNS).",
      "Refact or the Lambda function code t o Apache T omcat code that runs on Amaz on EC2 instances. Connect the database b y using nativ e Ja v a Database Connectivity (JDBC ) driv ers. D . Change the platform fr om A ur or a t o Amaz on Dynamo D",
      "Pr o vision a Dynamo DB Acceler at or (D AX) cluster . Use the D AX client SDK t o point the existing Dynamo DB API calls at the D AX cluster . Corr ect answer Ov er all explanation Scalability: Amaz on Dynamo DB is a fully managed No SQL database ser vice designed for high scalability and per formance. Dynamo DB can easily handle high v olumes of data and aut omatically scales t o accommodate incr eased workloads. Dynamo DB Acceler at or (D AX): D AX is an in-memor y caching ser vice that can signiﬁcantly impr o v e the r ead per formance of Dynamo DB tables. It helps r educe the database load and latency , making it a suitable choice for handling high v olumes of data. Minimiz ed Conﬁgur ation E ffor t: By choosing Dynamo DB with D AX, y ou can continue using the existing Dynamo DB API calls without signiﬁcant changes t o y our application. This minimiz es conﬁgur ation effor t and simpliﬁes the migr ation pr ocess. PAGE55"
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "49",
    "text": "A n application runs on an A maz on EC2 instance in a VP",
    "options": [
      "The application pr ocesses logs that ar e st or ed in an A maz on S3 buck et. The EC2 instance needs t o access the S3 buck et without connectivity t o the internet. Which solution will pr o vide priv ate network connectivity t o A maz on S3?",
      "Cr eate a gatewa y VPC endpoint t o the S3 buck et. Corr ect answer",
      "Str eam the logs t o Amaz on Cloud W atch Logs. Expor t the logs t o the S3 buck et.",
      "Cr eate an Amaz on API Gatewa y API with a priv ate link t o access the S3 endpoint. D . Cr eate an instance pr oﬁle on Amaz on EC2 t o allow S3 access. Ov er all explanation VPC Endpoint for S3: Amaz on VPC Endpoints enable y ou t o priv ately connect y our VPC t o suppor ted A WS ser vices, including Amaz on S3, without r equiring internet access. This means y our EC2 instance can secur ely access S3 r esour ces within the same VP",
      "Isolation fr om the Internet: With a VPC endpoint, y ou ensur e that y our application running on the EC2 instance can access S3 without being exposed t o the public internet. This enhances security and r educes the risk of potential security thr eats."
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "50",
    "text": "A solutions ar chitect needs t o allow team members t o access A maz on S3 buck ets in two diff er ent A WS accounts: a de v elopment account and a pr oduction account. The team curr ently has access t o S3 buck ets in the de v elopment account b y using unique I AM users that ar e assigned t o an I AM gr oup that has appr opriate permissions in the account. The solutions ar chitect has cr eated an I AM r ole in the pr oduction account. The r ole has a policy that gr ants access t o an S3 buck et in the pr oduction account. Which solution will meet these r equir ements while complying with the principle of least privilege? PAGE56",
    "options": [
      "T urn off the S3 Block Public Access f eatur e on the S3 buck et in the pr oduction account.",
      "Cr eate a user in the pr oduction account with unique cr edentials for each team member .",
      "Add the de v elopment account as a principal in the trust policy of the r ole in the pr oduction account. Corr ect answer D . A ttach the Administr at or Access policy t o the de v elopment account users. Ov er all explanation Add the de v elopment account as a principal in the trust policy of the r ole in the pr oduction account.",
      ""
    ],
    "correct_answer": null,
    "explanation": "Cr oss-Account Access: Adding the de v elopment account as a principal in the trust policy enables cr oss-account access t o the I AM r ole in the pr oduction account. I AM Role T rust P olicy: This appr oach adher es t o the principle of least privilege b y explicitly specifying the trusted account for access. A v oiding Unique Cr edentials: Rather than cr eating additional I AM users in the pr oduction account, le v er aging I AM r oles pr omotes better security pr actices. Scalability: This solution scales eﬃciently as team members fr om the de v elopment account can assume the r ole without r equiring individual I AM users. Centr aliz ed Management: I AM r oles pr o vide centr aliz ed management of permissions, making it easier t o contr ol access acr oss multiple A WS accounts."
  },
  {
    "number": "51",
    "text": "A solutions ar chitect wants t o use the following JSON text as an identity-based policy t o gr ant speciﬁc permissions: Which I AM principals can the solutions ar chitect attach this policy t o? (Choose two.) PAGE57",
    "options": [
      "Or ganization",
      "Amaz on Elastic Container Ser vice (Amaz on ECS) r esour ce",
      "Role Corr ect answer D . Amaz on EC2 r esour ce E. Gr oup Corr ect answer Ov er all explanation Identity-based policy used for r ole and gr oup",
      ""
    ],
    "correct_answer": null,
    "explanation": "Role: I AM r oles ar e entities with policies that determine what actions can be per formed on what r esour ces. Roles can be assumed b y I AM users, A WS ser vices, or A WS r esour ces. Gr oup: I AM gr oups ar e containers for I AM users. P olicies attached t o gr oups apply t o all users in the gr oup, simplifying permission management. I AM P olicy: The pr o vided policy can be attached t o both I AM r oles and I AM gr oups, allowing for ﬂexible and r eusable permission management. Resour ce-Speciﬁc P ermissions: The policy gr ants speciﬁc permissions r elated t o EC2 actions within the us-east-1 Region. P olicy Conditions: The policy includes a condition that r equir es multi-fact or authentication (MF A) for cer tain EC2 actions, enhancing security ."
  },
  {
    "number": "52",
    "text": "A company needs guar anteed A maz on EC2 capacity in thr ee speciﬁc A v ailability Z ones in a speciﬁc A WS Region for an upcoming e v ent that will last 1 week. What should the company do t o guar antee the EC2 capacity? PAGE58",
    "options": [
      "Pur chase Reser v ed Instances that specify the Region needed.",
      "Cr eate an On-Demand Capacity Reser v ation that speciﬁes the Region needed.",
      "Cr eate an On-Demand Capacity Reser v ation that speciﬁes the Region and thr ee A v ailability Z ones needed. Corr ect answer D . Pur chase Reser v ed Instances that specify the Region and thr ee A v ailability Z ones needed. Ov er all explanation Cr eate an On-Demand Capacity Reser v ation that speciﬁes the Region and thr ee A v ailability Z ones needed. This ensur es that the company has r eser v ed capacity in the desir ed Region and A v ailability Z ones for the speciﬁed dur ation without ha ving t o mak e an upfr ont pa yment as is the case with Reser v ed Instances. On-Demand Capacity Reser v ations pr o vide gr eater ﬂexibility for shor t-term capacity r equir ements, such as e v ents or peak workloads.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "53",
    "text": "A company is st oring backup ﬁles b y using A maz on S3 Standar d st or age. The ﬁles ar e accessed fr equently for 1 month. Howe v er , the ﬁles ar e not accessed after 1 month. The company must k eep the ﬁles indeﬁnitely . Which st or age solution will meet these r equir ements MOST cost-eff ectiv ely?",
    "options": [
      "Cr eate an S3 Lif ecy cle conﬁgur ation t o tr ansition objects fr om S3 Standar d t o S3 Standar d-Infr equent Access (S3 Standar d-I A) after 1 month.",
      "Cr eate an S3 Lif ecy cle conﬁgur ation t o tr ansition objects fr om S3 Standar d t o S3 One Z one-Infr equent Access (S3 One Z one-I A) after 1 month.",
      "Conﬁgur e S3 Intelligent-Tiering t o aut omatically migr ate objects. PAGE59 D . Cr eate an S3 Lif ecy cle conﬁgur ation t o tr ansition objects fr om S3 Standar d t o S3 Glacier Deep Ar chiv e after 1 month. Corr ect answer Ov er all explanation Amaz on S3 Glacier Deep Ar chiv e is a secur e, dur able, and extr emely low-cost Amaz on S3 st or age class for long-term r etention of data that is r ar ely accessed and for which r etrie v al times of se v er al hours ar e acceptable. It is the lowest-cost st or age option in Amaz on S3, making it a cost-eff ectiv e choice for st oring backup ﬁles that ar e not accessed after 1 month.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "54",
    "text": "A n ecommer ce company is experiencing an incr ease in user tr aﬃc. The company ’ s st or e is deplo y ed on A maz on EC2 instances as a two-tier web application consisting of a web tier and a separ ate database tier . As tr aﬃc incr eases, the company notices that the ar chitectur e is causing signiﬁcant dela ys in sending timely mark eting and or der conﬁrmation email t o users. The company wants t o r educe the time it spends r esolving complex email deliv er y issues and minimiz e oper ational o v erhead. What should a solutions ar chitect do t o meet these r equir ements?",
    "options": [
      "Conﬁgur e the web instance t o send email thr ough Amaz on Simple Email Ser vice (Amaz on SES). Corr ect answer",
      "Cr eate a separ ate application tier using EC2 instances dedicated t o email pr ocessing.",
      "Cr eate a separ ate application tier using EC2 instances dedicated t o email pr ocessing. Place the instances in an A ut o Scaling gr oup. D . Conﬁgur e the web instance t o send email thr ough Amaz on Simple Notiﬁcation Ser vice (Amaz on SNS). Ov er all explanation Conﬁgur e the web instance t o send email thr ough Amaz on Simple Email Ser vice (Amaz on SES). PAGE60",
      ""
    ],
    "correct_answer": null,
    "explanation": "Oﬄoad Email Pr ocessing: Conﬁguring the web instance t o send emails thr ough Amaz on SES oﬄoads the email pr ocessing workload fr om the application ser v ers, r educing latency . A maz on SES Beneﬁts: SES is a fully managed email ser vice that ensur es high deliv er ability , scalability , and r eliability of email communication. Minimiz e Oper ational Ov erhead: Utilizing Amaz on SES r educes the oper ational o v erhead associated with managing a dedicated email pr ocessing tier . Cost-E ff ectiv e: Amaz on SES pr o vides a cost-eff ectiv e solution for sending emails, especially when compar ed t o managing a separ ate EC2-based email pr ocessing tier . Scalability: Amaz on SES can easily handle the incr easing v olume of emails as the application ' s user tr aﬃc gr ows."
  },
  {
    "number": "55",
    "text": "A solutions ar chitect is designing the ar chitectur e for a softwar e demonstr ation envir onment. The envir onment will run on A maz on EC2 instances in an A ut o Scaling gr oup behind an A pplication Load Balancer (ALB). The system will experience signiﬁcant incr eases in tr aﬃc during working hours but is not r equir ed t o oper ate on week ends. Which combination of actions should the solutions ar chitect tak e t o ensur e that the system can scale t o meet demand? (Choose two.)",
    "options": [
      "Use a tar get tr acking scaling policy t o scale the A ut o Scaling gr oup based on instance CPU utilization.",
      "Launch the EC2 instances in multiple A WS Regions t o distribute the load acr oss Regions.",
      "Use A WS A ut o Scaling t o adjust the ALB capacity based on r equest r ate. Corr ect answer D . Use A WS A ut o Scaling t o scale the capacity of the VPC internet gatewa y . PAGE61 E. Use scheduled scaling t o change the A ut o Scaling gr oup minimum, maximum, and desir ed capacity t o z er o for week ends. Re v er t t o the default v alues at the star t of the week. Corr ect answer Ov er all explanation A WS A ut o Scaling can dynamically adjust the capacity of the Application Load Balancer (ALB) based on the r equest r ate, ensuring that the system can scale t o meet demand during working hours. Using scheduled scaling t o set A ut o Scaling gr oup capacity t o z er o during week ends helps sa v e costs b y minimizing r esour ces when the system doesn 't r equir e high a v ailability .",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "56",
    "text": "A hospital r ecently deplo y ed a RESTful API with A maz on API Gatewa y and A WS Lambda. The hospital uses API Gatewa y and Lambda t o upload r epor ts that ar e in PDF format and JPEG format. The hospital needs t o modify the Lambda code t o identify pr otected health information (PHI) in the r epor ts. Which solution will meet these r equir ements with the LEAST oper ational o v erhead?",
    "options": [
      "Use Amaz on Rekognition t o extr act the text fr om the r epor ts. Use Amaz on Compr ehend Medical t o identify the PHI fr om the extr acted text.",
      "Use Amaz on T extr act t o extr act the text fr om the r epor ts. Use Amaz on Sage Mak er t o identify the PHI fr om the extr acted text.",
      "Use Amaz on T extr act t o extr act the text fr om the r epor ts. Use Amaz on Compr ehend Medical t o identify the PHI fr om the extr acted text. Corr ect answer D . Use existing P ython libr aries t o extr act the text fr om the r epor ts and t o identify the PHI fr om the extr acted text. Ov er all explanation Use Amaz on T extr act t o extr act the text fr om the r epor ts. Use Amaz on Compr ehend Medical t o identify the PHI fr om the extr acted text. PAGE62",
      ""
    ],
    "correct_answer": null,
    "explanation": "Amaz on T extr act is a ser vice designed for extr acting text and data fr om documents, which includes PDF and JPEG ﬁles. It can accur ately extr act text and helps identify k e y information. Amaz on Compr ehend Medical is speciﬁcally designed for identifying pr otected health information (PHI) within text, making it a suitable choice for healthcar e-r elated applications. Using these two ser vices, y ou can oﬄoad the hea vy lifting of text extr action and PHI identiﬁcation t o A WS-managed ser vices, r educing oper ational o v erhead and ensuring accur ate r esults for healthcar e data analysis."
  },
  {
    "number": "57",
    "text": "A company uses NFS t o st or e lar ge video ﬁles in on-pr emises network attached st or age. Each video ﬁle r anges in siz e fr om 1 MB t o 500 G",
    "options": [
      "The t otal st or age is 70 TB and is no longer gr owing. The company decides t o migr ate the video ﬁles t o A maz on S3. The company must migr ate the video ﬁles as soon as possible while using the least possible network bandwidth. Which solution will meet these r equir ements?",
      "Cr eate an S3 buck et. Cr eate an I AM r ole that has permissions t o write t o the S3 buck et. Use the A WS CLI t o cop y all ﬁles locally t o the S3 buck et.",
      "Deplo y an S3 File Gatewa y on pr emises. Cr eate a public ser vice endpoint t o connect t o the S3 File Gatewa y . Cr eate an S3 buck et. Cr eate a new NFS ﬁle shar e on the S3 File Gatewa y . P oint the new ﬁle shar e t o the S3 buck et. T r ansf er the data fr om the existing NFS ﬁle shar e t o the S3 File Gatewa y .",
      "Set up an A WS Dir ect Connect connection between the on-pr emises network and A WS. Deplo y an S3 File Gatewa y on pr emises. Cr eate a public vir tual inter face ( VIF) t o connect t o the S3 File Gatewa y . Cr eate an S3 buck et. Cr eate a new NFS ﬁle shar e on the S3 File Gatewa y . P oint the new ﬁle shar e t o the S3 buck et. T r ansf er the data fr om the existing NFS ﬁle shar e t o the S3 File Gatewa y . PAGE63 D . Cr eate an A WS Snowball E dge job. Receiv e a Snowball E dge de vice on pr emises. Use the Snowball E dge client t o tr ansf er data t o the de vice. Return the de vice so that A WS can impor t the data int o Amaz on S3. Corr ect answer Ov er all explanation Minimizing Network Bandwidth: A WS Snowball E dge is designed for high-v olume data migr ation and is an ideal solution for situations wher e minimizing network bandwidth is a primar y concern. Y ou can tr ansf er the data t o the Snowball E dge de vice on pr emises, which does not consume y our internet bandwidth. Lar ge Data V olumes: Snowball E dge is built for lar ge data sets, and it suppor ts a wide r ange of data siz es, including the video ﬁles r anging fr om 1 MB t o 500 G",
      "It can handle the 70 TB of data eﬃciently . Conv enient Data T r ansf er: With Snowball E dge, y ou don 't need t o r ely on internet speed or face data tr ansf er challenges, which is often the case when cop ying data dir ectly t o S3 o v er the internet. Security: Snowball E dge de vices ar e highly secur e and tamper-e vident, ensuring the saf ety of y our data during tr ansit."
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "58",
    "text": "A pa yment pr ocessing company r ecor ds all v oice communication with its cust omers and st or es the audio ﬁles in an A maz on S3 buck et. The company needs t o captur e the text fr om the audio ﬁles. The company must r emo v e fr om the text any personally identiﬁable information (PII) that belongs t o cust omers. What should a solutions ar chitect do t o meet these r equir ements?",
    "options": [
      "Pr ocess the audio ﬁles b y using Amaz on Kinesis Video Str eams. Use an A WS Lambda function t o scan for known PII patterns.",
      "Cr eate an Amaz on Connect contact ﬂow that ingests the audio ﬁles with tr anscription turned on. Embed an A WS Lambda function t o scan for known PII patterns. Use Amaz on E v ent Bridge t o star t the contact ﬂow when an audio ﬁle is uploaded t o the S3 buck et. PAGE64",
      "When an audio ﬁle is uploaded t o the S3 buck et, inv ok e an A WS Lambda function t o star t an Amaz on T extr act task t o analyz e the call r ecor dings. D . Conﬁgur e an Amaz on T r anscribe tr anscription job with PII r edaction turned on. When an audio ﬁle is uploaded t o the S3 buck et, inv ok e an A WS Lambda function t o star t the tr anscription job. St or e the output in a separ ate S3 buck et. Corr ect answer Ov er all explanation Amaz on T r anscribe suppor ts PII r edaction, and y ou can conﬁgur e tr anscription jobs with r edaction f eatur es. Using Amaz on T r anscribe, combined with Lambda for aut omation, allows for the extr action of text fr om audio ﬁles with PII r edaction.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "59",
    "text": "A n application de v elopment team is designing a micr oser vice that will conv er t lar ge images t o smaller , compr essed images. When a user uploads an image thr ough the web inter face, the micr oser vice should st or e the image in an A maz on S3 buck et, pr ocess and compr ess the image with an A WS Lambda function, and st or e the image in its compr essed form in a diff er ent S3 buck et. A solutions ar chitect needs t o design a solution that uses dur able, stateless components t o pr ocess the images aut omatically . Which combination of actions will meet these r equir ements? (Choose two.)",
    "options": [
      "Cr eate an Amaz on Simple Queue Ser vice (Amaz on SQS) queue. Conﬁgur e the S3 buck et t o send a notiﬁcation t o the SQS queue when an image is uploaded t o the S3 buck et. Corr ect answer",
      "Conﬁgur e the Lambda function t o use the Amaz on Simple Queue Ser vice (Amaz on SQS) queue as the inv ocation sour ce. When the SQS message is successfully pr ocessed, delete the message in the queue. Corr ect answer",
      "Launch an Amaz on EC2 instance t o monit or an Amaz on Simple Queue Ser vice (Amaz on SQS) queue. When items ar e added t o the queue, log the ﬁle name in a text ﬁle on the EC2 instance and inv ok e the Lambda function. PAGE65 D . Conﬁgur e an Amaz on E v ent Bridge (Amaz on Cloud W atch E v ents) e v ent t o monit or the S3 buck et. When an image is uploaded, send an aler t t o an Amaz on ample Notiﬁcation Ser vice (Amaz on SNS) t opic with the application owner ' s email addr ess for fur ther pr ocessing. E. Conﬁgur e the Lambda function t o monit or the S3 buck et for new uploads. When an uploaded image is detected, write the ﬁle name t o a text ﬁle in memor y and use the text ﬁle t o k eep tr ack of the images that wer e pr ocessed. Ov er all explanation Cr eate an Amaz on Simple Queue Ser vice (Amaz on SQS) queue. Conﬁgur e the S3 buck et t o send a notiﬁcation t o the SQS queue when an image is uploaded t o the S3 buck et. This sets up an SQS queue t o r eceiv e notiﬁcations when an image is uploaded t o the S3 buck et, allowing for e v ent-driv en pr ocessing. Conﬁgur e the Lambda function t o use the Amaz on Simple Queue Ser vice (Amaz on SQS) queue as the inv ocation sour ce. When the SQS message is successfully pr ocessed, delete the message in the queue. This conﬁgur es A WS Lambda t o be trigger ed b y messages in the SQS queue, ensuring that each image upload triggers the Lambda function for pr ocessing. Deleting the message after successful pr ocessing helps ensur e that messages ar e not pr ocessed mor e than once.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "60",
    "text": "A company has an A maz on S3 buck et that contains critical data. The company must pr otect the data fr om accidental deletion. Which combination of steps should a solutions ar chitect tak e t o meet these r equir ements? (Choose two.)",
    "options": [
      "Enable v ersioning on the S3 buck et. Corr ect answer",
      "Enable MF A Delete on the S3 buck et. Corr ect answer PAGE66",
      "Enable default encr yption on the S3 buck et. D . Cr eate a buck et policy on the S3 buck et. E. Cr eate a lif ecy cle policy for the objects in the S3 buck et. Ov er all explanation Enable v ersioning on the S3 buck et. V ersioning k eeps multiple v ersions of an object in the same S3 buck et. If an object is deleted, the pr e vious v ersions can still be accessed, pr e v enting accidental data loss. Enable MF A Delete on the S3 buck et. Multi-F act or A uthentication (MF A) Delete r equir es additional authentication (in the form of an MF A de vice) for the deletion of objects. This pr o vides an extr a la y er of pr otection against accidental deletions.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "61",
    "text": "A company is de v eloping a two-tier web application on A WS. The company ' s de v elopers ha v e deplo y ed the application on an A maz on EC2 instance that connects dir ectly t o a back end A maz on RDS database. The company must not har dcode database cr edentials in the application. The company must also implement a solution t o aut omatically r otate the database cr edentials on a r egular basis. Which solution will meet these r equir ements with the LEAST oper ational o v erhead?",
    "options": [
      "St or e the database cr edentials in the instance metadata. Use Amaz on E v ent Bridge (Amaz on Cloud W atch E v ents) rules t o run a scheduled A WS Lambda function that updates the RDS cr edentials and instance metadata at the same time.",
      "St or e the database cr edentials as a secr et in A WS Secr ets Manager . T urn on aut omatic r otation for the secr et. A ttach the r equir ed permission t o the EC2 r ole t o gr ant access t o the secr et. Corr ect answer",
      "St or e the database cr edentials in a conﬁgur ation ﬁle in an encr ypted Amaz on S3 buck et. Use Amaz on E v ent Bridge (Amaz on Cloud W atch E v ents) rules t o run a scheduled A WS Lambda function that updates the RDS cr edentials and the PAGE67 cr edentials in the conﬁgur ation ﬁle at the same time. Use S3 V ersioning t o ensur e the ability t o fall back t o pr e vious v alues. D . St or e the database cr edentials as encr ypted par ameters in A WS Systems Manager P ar ameter St or e. T urn on aut omatic r otation for the encr ypted par ameters. A ttach the r equir ed permission t o the EC2 r ole t o gr ant access t o the encr ypted par ameters. Ov er all explanation St or e the database cr edentials as a secr et in A WS Secr ets Manager . T urn on aut omatic r otation for the secr et. A ttach the r equir ed permission t o the EC2 r ole t o gr ant access t o the secr et.",
      ""
    ],
    "correct_answer": null,
    "explanation": "A WS Secr ets Manager is designed for st oring, managing, and r otating sensitiv e information lik e database cr edentials. When y ou use A WS Secr ets Manager , y ou can enable aut omatic r otation of the cr edentials, which is a best pr actice for security . This r otation can be managed seamlessly without the need for manual inter v ention. By attaching the necessar y permissions t o the EC2 instance ' s r ole, y our application can secur ely r etrie v e the cr edentials fr om A WS Secr ets Manager , ensuring that the cr edentials ar e not har dcoded in the application and that the y ar e aut omatically r otated. This appr oach minimiz es oper ational o v erhead and pr o vides a highly secur e and aut omated solution."
  },
  {
    "number": "62",
    "text": "A company collects data for temper atur e, humidity , and atmospheric pr essur e in cities acr oss multiple continents. The a v er age v olume of data that the company collects fr om each site daily is 500 G",
    "options": [
      "Each site has a high-speed Internet connection. The company wants t o aggr egate the data fr om all these global sites as quickly as possible in a single A maz on S3 buck et. The solution must minimiz e oper ational complexity . Which solution meets these r equir ements?",
      "T urn on S3 T r ansf er Acceler ation on the destination S3 buck et. Use multipar t uploads t o dir ectly upload site data t o the destination S3 buck et. Corr ect answer PAGE68",
      "Upload the data fr om each site t o an S3 buck et in the closest Region. Use S3 Cr oss-Region Replication t o cop y objects t o the destination S3 buck et. Then r emo v e the data fr om the origin S3 buck et.",
      "Schedule A WS Snowball E dge St or age Optimiz ed de vice jobs daily t o tr ansf er data fr om each site t o the closest Region. Use S3 Cr oss-Region Replication t o cop y objects t o the destination S3 buck et. D . Upload the data fr om each site t o an Amaz on EC2 instance in the closest Region. St or e the data in an Amaz on Elastic Block St or e (Amaz on EBS) v olume. A t r egular inter v als, tak e an EBS snapshot and cop y it t o the Region that contains the destination S3 buck et. Rest or e the EBS v olume in that Region. Ov er all explanation 1. S3 T r ansf er Acceler ation Beneﬁt: Enabling S3 T r ansf er Acceler ation pr o vides an eﬃcient method t o acceler ate data uploads t o y our S3 buck et. This is achie v ed b y utilizing Amaz on ' s Content Deliv er y Network (CDN) t o optimiz e the tr ansf er path. 2. High-Speed Internet Connections: Giv en that each site has a high-speed Internet connection, this choice aligns well with the capability t o tr ansf er data quickly . The combination of T r ansf er Acceler ation and high-speed connections can signiﬁcantly enhance the upload per formance. 3. Reduced Latency: T r ansf er Acceler ation minimiz es the eff ects of network latency , allowing data t o be uploaded mor e r apidly . It' s par ticularly adv antageous when dealing with distant or geogr aphically dispersed sites. 4. Minimiz ed Oper ational Complexity: This appr oach k eeps things simple. It dir ectly uploads data t o the destination S3 buck et, which means ther e ' s no need for additional ser vices or conﬁgur ations that might intr oduce complexity . 5. Dir ect P ath t o Destination: Data is sent dir ectly t o the destination buck et, eliminating the need for intermediate steps, such as cop ying data between S3 buck ets, that can slow down the pr ocess. 6. Cost-Eﬃcient: While ther e might be some additional costs associated with using T r ansf er Acceler ation, this appr oach can be cost-eff ectiv e compar ed t o other methods that inv olv e data r eplication or specializ ed har dwar e de vices. PAGE69 7. Real-Time Data A v ailability: Data is a v ailable in near r eal-time in the destination buck et, as ther e ' s no need t o wait for r eplication or data tr ansf er jobs t o complete. This is crucial for applications or pr ocesses that r equir e immediate access t o the latest data. 8. Simpliﬁed Maintenance: With a str aightfor war d data tr ansf er pr ocess, y ou can minimiz e the need for ongoing maintenance and monit oring. This helps k eep the solution easy t o manage. It' s impor tant t o consider potential costs, security measur es, and data r edundancy r equir ements in y our decision-making pr ocess. While Option A can pr o vide a fast and str aightfor war d data tr ansf er , mak e sur e it aligns with y our speciﬁc needs and constr aints befor e implementing it."
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "63",
    "text": "A company has an application that pr o vides mark eting ser vices t o st or es. The ser vices ar e based on pr e vious pur chases b y st or e cust omers. The st or es upload tr ansaction data t o the company thr ough SF TP , and the data is pr ocessed and analyz ed t o gener ate new mark eting off ers. Some of the ﬁles can ex ceed 200 GB in siz e. Recently , the company disco v er ed that some of the st or es ha v e uploaded ﬁles that contain personally identiﬁable information (PII) that should not ha v e been included. The company wants administr at ors t o be aler ted if PII is shar ed again. The company also wants t o aut omate r emediation. What should a solutions ar chitect do t o meet these r equir ements with the LEAST de v elopment effor t?",
    "options": [
      "Implement cust om scanning algorithms in an A WS Lambda function. T rigger the function when objects ar e loaded int o the buck et. If objects contain PII, use Amaz on Simple Notiﬁcation Ser vice (Amaz on SNS) t o trigger a notiﬁcation t o the administr at ors t o r emo v e the objects that contain PII.",
      "Use an Amaz on S3 buck et as a secur e tr ansf er point. Use Amaz on Macie t o scan the objects in the buck et. If objects contain PII, use Amaz on Simple Notiﬁcation Ser vice (Amaz on SNS) t o trigger a notiﬁcation t o the administr at ors t o r emo v e the objects that contain PII. Corr ect answer PAGE70",
      "Use an Amaz on S3 buck et as a secur e tr ansf er point. Use Amaz on Inspect or t o scan the objects in the buck et. If objects contain PII, trigger an S3 Lif ecy cle policy t o r emo v e the objects that contain PII. D . Implement cust om scanning algorithms in an A WS Lambda function. T rigger the function when objects ar e loaded int o the buck et. If objects contain PII, use Amaz on Simple Email Ser vice (Amaz on SES) t o trigger a notiﬁcation t o the administr at ors and trigger an S3 Lif ecy cle policy t o r emo v e the meats that contain PII. Ov er all explanation A maz on Macie : Amaz on Macie is a machine learning ser vice that helps disco v er , classify , and pr otect sensitiv e data, including PII, in Amaz on S3 buck ets. By using Macie, y ou can aut omatically scan the objects for PII without ha ving t o de v elop cust om scanning algorithms. It simpliﬁes the detection pr ocess. A maz on SNS: Amaz on SNS can be used t o send notiﬁcations t o administr at ors when PII is detected in the objects. This is an eﬃcient wa y t o aler t administr at ors about the issue. Manual r emediation: This appr oach inv olv es administr at ors manually r emo ving the objects that contain PII. This is usually pr ef err ed in situations wher e y ou want human inter v ention t o ensur e the accur acy of the decision t o r emo v e such data.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "64",
    "text": "A company has a pr oduction workload that runs on 1,000 A maz on EC2 Linux instances. The workload is power ed b y thir d-par ty softwar e. The company needs t o patch the thir d-par ty softwar e on all EC2 instances as quickly as possible t o r emediate a critical security vulner ability . What should a solutions ar chitect do t o meet these r equir ements?",
    "options": [
      "Cr eate an A WS Lambda function t o apply the patch t o all EC2 instances.",
      "Conﬁgur e A WS Systems Manager P atch Manager t o apply the patch t o all EC2 instances. Corr ect answer",
      "Use A WS Systems Manager Run Command t o run a cust om command that applies the patch t o all EC2 instances. PAGE71 D . Schedule an A WS Systems Manager maintenance window t o apply the patch t o all EC2 instances. Ov er all explanation A WS Systems Manager P atch Manager is a fully managed ser vice that aut omates the pr ocess of patching and managing softwar e acr oss y our Amaz on EC2 instances. It is speciﬁcally designed for tasks lik e this wher e y ou need t o apply patches t o a lar ge number of instances. With A WS Systems Manager P atch Manager , y ou can deﬁne patch baselines, schedule maintenance windows, and quickly apply patches t o EC2 instances. It pr o vides y ou with a centr aliz ed and eﬃcient wa y t o k eep y our instances up-t o-date with security patches. Running cust om scripts (option D) or using A WS Lambda functions (option A) t o patch instances can be mor e complex and less eﬃcient for handling lar ge-scale patching, especially in a time-critical security scenario. Systems Manager P atch Manager simpliﬁes and aut omates the pr ocess.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "65",
    "text": "A ser v erless application uses A maz on API Gatewa y , A WS Lambda, and A maz on Dynamo D",
    "options": [
      "The Lambda function needs permissions t o r ead and write t o the Dynamo DB table. Which solution will giv e the Lambda function access t o the Dynamo DB table MOST secur ely?",
      "Cr eate an I AM r ole that includes Dynamo DB as a trusted ser vice. A ttach a policy t o the r ole that allows r ead and write access fr om the Lambda function. Update the code of the Lambda function t o attach t o the new r ole as an ex ecution r ole.",
      "Cr eate an I AM user with pr ogr ammatic access t o the Lambda function. A ttach a policy t o the user that allows r ead and write access t o the Dynamo DB table. St or e the access_k e y_id and secr et_access_k e y par ameters in A WS Systems Manager P ar ameter St or e as secur e string par ameters. Update the Lambda function code t o r etrie v e the secur e string par ameters befor e connecting t o the Dynamo DB table. PAGE72",
      "Cr eate an I AM user with pr ogr ammatic access t o the Lambda function. A ttach a policy t o the user that allows r ead and write access t o the Dynamo DB table. St or e the access_k e y_id and secr et_access_k e y par ameters as par t of the Lambda envir onment v ariables. Ensur e that other A WS users do not ha v e r ead and write access t o the Lambda function conﬁgur ation. D . Cr eate an I AM r ole that includes Lambda as a trusted ser vice. A ttach a policy t o the r ole that allows r ead and write access t o the Dynamo DB table. Update the conﬁgur ation of the Lambda function t o use the new r ole as the ex ecution r ole. Corr ect answer Ov er all explanation Cr eate an I AM r ole that includes Lambda as a trusted ser vice. A ttach a policy t o the r ole that allows r ead and write access t o the Dynamo DB table. Update the conﬁgur ation of the Lambda function t o use the new r ole as the ex ecution r ole."
    ],
    "correct_answer": null,
    "explanation": "I AM Role: Cr eating an I AM r ole allows ﬁne-gr ained contr ol o v er permissions, and Lambda functions can assume r oles for access t o A WS r esour ces. P olicy for Dynamo DB Access: A ttaching a policy t o the r ole that gr ants r ead and write access t o the Dynamo DB table ensur es the Lambda function has the necessar y permissions. T rusted Ser vice: Including Lambda as a trusted ser vice in the I AM r ole allows the Lambda function t o assume the r ole. Dynamic P ermissions: The I AM r ole appr oach ensur es that permissions ar e dynamically assigned t o the Lambda function, enhancing security . Least Privilege: This solution adher es t o the principle of least privilege b y gr anting only the necessar y permissions for Dynamo DB access."
  },
  {
    "number": "66",
    "text": "A manufacturing company has machine sensors that upload .csv ﬁles t o an A maz on S3 buck et. These .csv ﬁles must be conv er ted int o images and must be made a v ailable as soon as possible for the aut omatic gener ation of gr aphical r epor ts. PAGE73 The images become irr ele v ant after 1 month, but the .csv ﬁles must be k ept t o tr ain machine learning (ML) models twice a y ear . The ML tr ainings and audits ar e planned weeks in adv ance. Which combination of steps will meet these r equir ements MOST cost-eff ectiv ely? (Choose two.)",
    "options": [
      "Cr eate S3 Lif ecy cle rules for .csv ﬁles and image ﬁles in the S3 buck et. T r ansition the .csv ﬁles fr om S3 Standar d t o S3 Glacier 1 da y after the y ar e uploaded. Expir e the image ﬁles after 30 da ys. Corr ect answer",
      "Cr eate S3 Lif ecy cle rules for .csv ﬁles and image ﬁles in the S3 buck et. T r ansition the .csv ﬁles fr om S3 Standar d t o S3 Standar d-Infr equent Access (S3 Standar d-I A) 1 da y after the y ar e uploaded. K eep the image ﬁles in Reduced Redundancy St or age (RRS).",
      "Launch an Amaz on EC2 Spot Instance that downloads the .csv ﬁles e v er y hour , gener ates the image ﬁles, and uploads the images t o the S3 buck et. D . Design an A WS Lambda function that conv er ts the .csv ﬁles int o images and st or es the images in the S3 buck et. Inv ok e the Lambda function when a .csv ﬁle is uploaded. Corr ect answer E. Cr eate S3 Lif ecy cle rules for .csv ﬁles and image ﬁles in the S3 buck et. T r ansition the .csv ﬁles fr om S3 Standar d t o S3 One Z one-Infr equent Access (S3 One Z one-I A) 1 da y after the y ar e uploaded. Expir e the image ﬁles after 30 da ys. Ov er all explanation Design an A WS Lambda function that conv er ts the .csv ﬁles int o images and st or es the images in the S3 buck et. Inv ok e the Lambda function when a .csv ﬁle is uploaded. Cr eate S3 Lif ecy cle rules for .csv ﬁles and image ﬁles in the S3 buck et. T r ansition the .csv ﬁles fr om S3 Standar d t o S3 Standar d-Infr equent Access (S3 Standar d-I A) 1 da y after the y ar e uploaded. K eep the image ﬁles in Reduced Redundancy St or age (RRS).",
      ""
    ],
    "correct_answer": null,
    "explanation": "A WS Lambda for File Conv ersion: Using Lambda for conv er ting .csv ﬁles int o images ensur es a ser v erless, scalable, and cost-eff ectiv e solution. PAGE74 E v ent-Driv en Ex ecution: Lambda can be trigger ed b y S3 e v ents, ensuring aut omatic ex ecution when a .csv ﬁle is uploaded. S3 Lif ecy cle Rules: Lif ecy cle rules ar e applied t o both .csv ﬁles and image ﬁles, allowing for eﬃcient management of st or age costs. T r ansition t o S3 Standar d-I A: T r ansitioning .csv ﬁles t o S3 Standar d-I A after 1 da y optimiz es st or age costs based on access patterns. Reduced Redundancy St or age (RRS): St oring image ﬁles in RRS ma y be cost-eff ectiv e, considering the images become irr ele v ant after 30 da ys. This combination pr o vides a cost-eff ectiv e, scalable, and well-ar chitected solution for the giv en r equir ements."
  },
  {
    "number": "67",
    "text": "A company is implementing a new business application. The application runs on two A maz on EC2 instances and uses an A maz on S3 buck et for document st or age. A solutions ar chitect needs t o ensur e that the EC2 instances can access the S3 buck et. What should the solutions ar chitect do t o meet this r equir ement?",
    "options": [
      "Cr eate an I AM user that gr ants access t o the S3 buck et. A ttach the user account t o the EC2 instances",
      "Cr eate an I AM policy that gr ants access t o the S3 buck et. A ttach the policy t o the EC2 instances.",
      "Cr eate an I AM gr oup that gr ants access t o the S3 buck et. A ttach the gr oup t o the EC2 instances. D . Cr eate an I AM r ole that gr ants access t o the S3 buck et. A ttach the r ole t o the EC2 instances. Corr ect answer Ov er all explanation I AM Roles: I AM r oles ar e designed for gr anting tempor ar y permissions t o A WS ser vices, such as EC2 instances. Roles pr o vide secur e and eﬃcient access t o A WS r esour ces without the need for long-term cr edentials lik e access k e ys. PAGE75 Least Privilege: I AM r oles can be set up with the principle of least privilege, meaning y ou can deﬁne speciﬁc permissions for the r ole t o access the S3 buck et without gr anting unnecessar y or o v erly permissiv e permissions.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "68",
    "text": "A company runs an ecommer ce application on A maz on EC2 instances behind an A pplication Load Balancer . The instances run in an A maz on EC2 A ut o Scaling gr oup acr oss multiple A v ailability Z ones. The A ut o Scaling gr oup scales based on CPU utilization metrics. The ecommer ce application st or es the tr ansaction data in a My SQL 8.0 database that is hosted on a lar ge EC2 instance. The database ' s per formance degr ades quickly as application load incr eases. The application handles mor e r ead r equests than write tr ansactions. The company wants a solution that will aut omatically scale the database t o meet the demand of unpr edictable r ead workloads while maintaining high a v ailability . Which solution will meet these r equir ements?",
    "options": [
      "Use Amaz on Elasti Cache for Memcached with EC2 Spot Instances.",
      "Use Amaz on A ur or a with a Multi-AZ deplo yment. Conﬁgur e A ur or a A ut o Scaling with A ur or a Replicas. Corr ect answer",
      "Use Amaz on RDS with a Single-AZ deplo yment Conﬁgur e Amaz on RDS t o add r eader instances in a diff er ent A v ailability Z one. D . Use Amaz on Redshift with a single node for leader and compute functionality . Ov er all explanation A maz on A ur or a: Amaz on A ur or a is a high-per formance, fully managed database ser vice that is compatible with My SQL and pr o vides ex cellent r ead scaling capabilities. Multi-AZ Deplo yment: A ur or a suppor ts a Multi-AZ deplo yment, which ensur es high a v ailability and aut omatic failo v er in case of an issue with the primar y instance. This is impor tant for maintaining high a v ailability . A ur or a A ut o Scaling: A ur or a allows y ou t o conﬁgur e A ut o Scaling with A ur or a Replicas. With A ur or a A ut o Scaling, y ou can aut omatically add r ead r eplicas in r esponse t o incr eased r ead demand, and these r eplicas can help distribute the r ead workload, impr o ving per formance. PAGE76",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "69",
    "text": "A company is pr eparing t o launch a public-facing web application in the A WS Cloud. The ar chitectur e consists of A maz on EC2 instances within a VPC behind an Elastic Load Balancer (ELB). A thir d-par ty ser vice is used for the DNS. The company ' s solutions ar chitect must r ecommend a solution t o detect and pr otect against lar ge-scale DDo S attacks. Which solution meets these r equir ements?",
    "options": [
      "Enable Amaz on Inspect or on the EC2 instances.",
      "Enable A WS Shield Adv anced and assign the ELB t o it. Corr ect answer",
      "Enable A WS Shield and assign Amaz on Route 53 t o it. D . Enable Amaz on Guar d Duty on the account. Ov er all explanation A WS Shield Adv anced is a managed Distributed Denial of Ser vice (DDo S) pr otection ser vice that pr o vides additional pr otection be y ond what is pr o vided b y A WS Shield Standar d. It' s designed t o pr otect against lar ger and mor e sophisticated DDo S attacks. By assigning the Elastic Load Balancer (ELB) t o A WS Shield Adv anced, y ou can le v er age its pr otection capabilities and guar d against lar ge-scale DDo S attacks. This is an eff ectiv e solution for public-facing web applications wher e DDo S pr otection is essential.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "70",
    "text": "A company wants t o impr o v e its ability t o clone lar ge amounts of pr oduction data int o a test envir onment in the same A WS Region. The data is st or ed in A maz on EC2 instances on A maz on Elastic Block St or e (A maz on EBS) v olumes. Modiﬁcations t o the cloned data must not aff ect the pr oduction envir onment. The softwar e that accesses this data r equir es consistently high I/O per formance. A solutions ar chitect needs t o minimiz e the time that is r equir ed t o clone the pr oduction data int o the test envir onment. PAGE77 Which solution will meet these r equir ements?",
    "options": [
      "Conﬁgur e the pr oduction EBS v olumes t o use the EBS Multi-A ttach f eatur e. T ak e EBS snapshots of the pr oduction EBS v olumes. A ttach the pr oduction EBS v olumes t o the EC2 instances in the test envir onment.",
      "T ak e EBS snapshots of the pr oduction EBS v olumes. T urn on the EBS fast snapshot r est or e f eatur e on the EBS snapshots. Rest or e the snapshots int o new EBS v olumes. A ttach the new EBS v olumes t o EC2 instances in the test envir onment. Corr ect answer",
      "T ak e EBS snapshots of the pr oduction EBS v olumes. Cr eate and initializ e new EBS v olumes. A ttach the new EBS v olumes t o EC2 instances in the test envir onment befor e r est oring the v olumes fr om the pr oduction EBS snapshots. D . T ak e EBS snapshots of the pr oduction EBS v olumes. Rest or e the snapshots ont o EC2 instance st or e v olumes in the test envir onment. Ov er all explanation Amaz on EBS fast snapshot r est or e (FSR) enables y ou t o cr eate a v olume fr om a snapshot that is fully initializ ed at cr eation. This eliminates the latency of I/O oper ations on a block when it is accessed for the ﬁrst time. V olumes that ar e cr eated using fast snapshot r est or e instantly deliv er all of their pr o visioned per formance.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "71",
    "text": "A company hosts a data lak e on A WS. The data lak e consists of data in A maz on S3 and A maz on RDS for P ostgr e SQL. The company needs a r epor ting solution that pr o vides data visualization and includes all the data sour ces within the data lak e. Only the company ' s management team should ha v e full access t o all the visualizations. The r est of the company should ha v e only limited access. Which solution will meet these r equir ements?",
    "options": [
      "Cr eate an A WS Glue table and cr awler for the data in Amaz on S3. Use Amaz on A thena F eder ated Quer y t o access data within Amaz on RDS for P ostgr e SQL. Gener ate r epor ts b y using Amaz on A thena. Publish the r epor ts t o Amaz on S3. Use S3 buck et policies t o limit access t o the r epor ts. PAGE78",
      "Cr eate an analysis in Amaz on Quick Sight. Connect all the data sour ces and cr eate new datasets. Publish dashboar ds t o visualiz e the data. Shar e the dashboar ds with the appr opriate I AM r oles.",
      "Cr eate an analysis in Amaz on Quick Sight. Connect all the data sour ces and cr eate new datasets. Publish dashboar ds t o visualiz e the data. Shar e the dashboar ds with the appr opriate users and gr oups. Corr ect answer D . Cr eate an A WS Glue table and cr awler for the data in Amaz on S3. Cr eate an A WS Glue extr act, tr ansform, and load (E TL) job t o pr oduce r epor ts. Publish the r epor ts t o Amaz on S3. Use S3 buck et policies t o limit access t o the r epor ts. Ov er all explanation A maz on Quick Sight: Amaz on Quick Sight is a fully managed, ser v erless business intelligence ser vice that mak es it easy t o cr eate inter activ e visualizations and r epor ts. It is designed for data visualization and r epor ting. Fine-Gr ained Access Contr ol: Amaz on Quick Sight allows y ou t o cr eate ﬁne-gr ained access contr ols, allowing y ou t o shar e dashboar ds and visualizations with speciﬁc users and gr oups, gr anting them access t o only the data and insights the y need.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "72",
    "text": "A company wants t o run its critical applications in containers t o meet r equir ements for scalability and a v ailability . The company pr ef ers t o focus on maintenance of the critical applications. The company does not want t o be r esponsible for pr o visioning and managing the underlying infr astructur e that runs the containeriz ed workload. What should a solutions ar chitect do t o meet these r equir ements?",
    "options": [
      "Use Amaz on EC2 instances, and install Dock er on the instances.",
      "Use Amaz on Elastic Container Ser vice (Amaz on ECS) on Amaz on EC2 work er nodes.",
      "Use Amaz on EC2 instances fr om an Amaz on Elastic Container Ser vice (Amaz on ECS)-optimiz ed Amaz on Machine Image (AMI). PAGE79 D . Use Amaz on Elastic Container Ser vice (Amaz on ECS) on A WS F ar gate. Corr ect answer Ov er all explanation Use Amaz on Elastic Container Ser vice (Amaz on ECS) on A WS F ar gate.",
      ""
    ],
    "correct_answer": null,
    "explanation": "Amaz on ECS on A WS F ar gate is a ser v erless container management ser vice. With F ar gate, y ou don 't need t o pr o vision or manage the underlying infr astructur e (Amaz on EC2 instances). It allows y ou t o focus on running y our containeriz ed applications while A WS tak es car e of the infr astructur e management. This is an ideal choice when y ou want t o run containeriz ed workloads without the oper ational o v erhead of managing the underlying EC2 instances, making it a suitable option for companies that pr ef er t o focus on maintaining their critical applications."
  },
  {
    "number": "73",
    "text": "A company uses A WS Or ganizations with all f eatur es enabled and runs multiple A maz on EC2 workloads in the ap-southeast-2 Region. The company has a ser vice contr ol policy (SCP) that pr e v ents any r esour ces fr om being cr eated in any other Region. A security policy r equir es the company t o encr ypt all data at r est. A n audit disco v ers that emplo y ees ha v e cr eated A maz on Elastic Block St or e (A maz on EBS) v olumes for EC2 instances without encr ypting the v olumes. The company wants any new EC2 instances that any I AM user or r oot user launches in ap-southeast-2 t o use encr ypted EBS v olumes. The company wants a solution that will ha v e minimal eff ect on emplo y ees who cr eate EBS v olumes. Which combination of steps will meet these r equir ements? (Choose two.)",
    "options": [
      "In the Or ganizations management account, specify the Default EBS v olume encr yption setting. Corr ect answer PAGE80",
      "Cr eate an SCP . A ttach the SCP t o the r oot or ganizational unit (OU). Deﬁne the SCP t o deny the ec2:Cr eate V olume action whenthe ec2:Encr ypted condition equals false. Corr ect answer",
      "Update the I AM policies for each account t o deny the ec2:Cr eate V olume action when the ec2:Encr ypted condition equals false. D . In the Amaz on EC2 console, select the EBS encr yption account attribute and deﬁne a default encr yption k e y . E. Cr eate an I AM permission boundar y . A ttach the permission boundar y t o the r oot or ganizational unit (OU). Deﬁne the boundar y t o deny the ec2:Cr eate V olume action when the ec2:Encr ypted condition equals false. Ov er all explanation Cr eating an SCP and attaching it t o the r oot or ganizational unit (OU) will deny the ec2:Cr eate V olume action when the ec2:Encr ypted condition equals false. This means that any I AM user or r oot user in any account in the or ganization will not be able t o cr eate an EBS v olume without encr ypting it. Specifying the Default EBS v olume encr yption setting in the Or ganizations management account will ensur e that all new EBS v olumes cr eated in any account in the or ganization ar e encr ypted b y default.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "74",
    "text": "A company is running a multi-tier ecommer ce web application in the A WS Cloud. The application runs on A maz on EC2 instances with an A maz on RDS for My SQL Multi-AZ DB instance. A maz on RDS is conﬁgur ed with the latest gener ation DB instance with 2,000 GB of st or age in a Gener al Purpose SSD (gp3) A maz on Elastic Block St or e (A maz on EBS) v olume. The database per formance aff ects the application during periods of high demand. A database administr at or analyz es the logs in A maz on Cloud W atch Logs and disco v ers that the application per formance alwa ys degr ades when the number of r ead and write IOPS is higher than 20,000. What should a solutions ar chitect do t o impr o v e the application per formance? PAGE81",
    "options": [
      "Incr ease the number of IOPS on the gp3 v olume.",
      "Replace the 2,000 GB gp3 v olume with two 1,000 GB gp3 v olumes.",
      "Replace the v olume with a magnetic v olume. D . Replace the v olume with a Pr o visioned IOPS SSD (io2) v olume. Corr ect answer Ov er all explanation The per formance issue with the gp3 v olume suggests a need for higher IOPS. The io2 v olume type is designed for critical database workloads that r equir e sustained high IOPS per formance.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "75",
    "text": "A company uses A WS Or ganizations t o manage multiple A WS accounts for diff er ent depar tments. The management account has an A maz on S3 buck et that contains pr oject r epor ts. The company wants t o limit access t o this S3 buck et t o only users of accounts within the or ganization in A WS Or ganizations. Which solution meets these r equir ements with the LEAST amount of oper ational o v erhead?",
    "options": [
      "T ag each user that needs access t o the S3 buck et. Add the aws:Principal T ag global condition k e y t o the S3 buck et policy .",
      "Cr eate an or ganizational unit (OU) for each depar tment. Add the aws:Principal Or g P aths global condition k e y t o the S3 buck et policy .",
      "Use A WS Cloud T r ail t o monit or the Cr eate Account, Invite Account T o Or ganization, Lea v e Or ganization, and Remo v e Account F r om Or ganization e v ents. Update the S3 buck et policy accor dingly . D . Add the aws Principal Or g ID global condition k e y with a r ef er ence t o the or ganization ID t o the S3 buck et policy . Corr ect answer Ov er all explanation Simple and Dir ect A ppr oach: Adding the aws Principal Or g ID condition k e y dir ectly in the S3 buck et policy is a str aightfor war d wa y t o r estrict access t o users fr om accounts PAGE82 within the A WS Or ganization. It r equir es minimal conﬁgur ation and ongoing management. Or ganization-Wide Restriction: By specifying the or ganization ' s ID as the condition, y ou ensur e that only users fr om accounts within the or ganization can access the S3 buck et. This dir ectly aligns with the r equir ement of limiting access t o the or ganization ' s users.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "76",
    "text": "A solutions ar chitect is de v eloping a VPC ar chitectur e that includes multiple subnets. The ar chitectur e will host applications that use A maz on EC2 instances and A maz on RDS DB instances. The ar chitectur e consists of six subnets in two A v ailability Z ones. Each A v ailability Z one includes a public subnet, a priv ate subnet, and a dedicated subnet for databases. Only EC2 instances that run in the priv ate subnets can ha v e access t o the RDS databases. Which solution will meet these r equir ements?",
    "options": [
      "Cr eate a security gr oup that allows inbound tr aﬃc fr om the security gr oup that is assigned t o instances in the priv ate subnets. A ttach the security gr oup t o the DB instances. Corr ect answer",
      "Cr eate a security gr oup that denies inbound tr aﬃc fr om the security gr oup that is assigned t o instances in the public subnets. A ttach the security gr oup t o the DB instances.",
      "Cr eate a new peering connection between the public subnets and the priv ate subnets. Cr eate a diff er ent peering connection between the priv ate subnets and the database subnets. D . Cr eate a new r oute table that ex cludes the r oute t o the public subnets' CIDR blocks. Associate the r oute table with the database subnets. Ov er all explanation Cr eate a security gr oup that allows inbound tr aﬃc fr om the security gr oup that is assigned t o instances in the priv ate subnets. A ttach the security gr oup t o the DB instances.",
      ""
    ],
    "correct_answer": null,
    "explanation": "PAGE83 By cr eating a security gr oup (SG) for the RDS instances and allowing inbound tr aﬃc fr om the security gr oup assigned t o the EC2 instances in the priv ate subnets, y ou contr ol and r estrict access t o the RDS instances. EC2 instances that use the security gr oup assigned t o them in the priv ate subnets will be able t o communicate with the RDS instances because the security gr oup rules ar e set t o allow this speciﬁc tr aﬃc. This appr oach ensur es that only instances in the priv ate subnets, which ha v e the appr opriate security gr oup assigned t o them, can access the RDS databases while isolating them fr om instances in the public subnets. It' s a common pr actice for security and access contr ol in A WS VPC ar chitectur es."
  },
  {
    "number": "77",
    "text": "A company maintains a sear chable r eposit or y of items on its website. The data is st or ed in an A maz on RDS for My SQL database table that contains mor e than 10 million r ows. The database has 2 TB of Gener al Purpose SSD st or age. Ther e ar e millions of updates against this data e v er y da y thr ough the company ' s website. The company has noticed that some inser t oper ations ar e taking 10 seconds or longer . The company has determined that the database st or age per formance is the pr oblem. Which solution addr esses this per formance issue?",
    "options": [
      "Change the DB instance t o a memor y optimiz ed instance class.",
      "Enable Multi-AZ RDS r ead r eplicas with My SQL nativ e asynchr onous r eplication.",
      "Change the DB instance t o a burstable per formance instance class. D . Change the st or age type t o Pr o visioned IOPS SSD . Corr ect answer Ov er all explanation Gener al Purpose (SSD) st or age pr o vides a balance of price and per formance, but it might not be suitable for workloads with high write-intensiv e oper ations. Pr o visioned IOPS SSD (io1) st or age allows y ou t o allocate a speciﬁc number of IOPS (Input/Output Oper ations P er Second) and pr o vides consistent and pr edictable PAGE84 per formance. This can signiﬁcantly impr o v e write per formance, especially for workloads with fr equent updates. Changing the instance type or enabling Multi-AZ RDS r ead r eplicas won 't dir ectly addr ess the st or age per formance issue r elated t o high write-intensiv e oper ations.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "78",
    "text": "A solutions ar chitect must migr ate a Windows Internet Information Ser vices (IIS) web application t o A WS. The application curr ently r elies on a ﬁle shar e hosted in the user ' s on-pr emises network-attached st or age (N AS). The solutions ar chitect has pr oposed migr ating the IIS web ser v ers t o A maz on EC2 instances in multiple A v ailability Z ones that ar e connected t o the st or age solution, and conﬁguring an Elastic Load Balancer attached t o the instances. Which r eplacement t o the on-pr emises ﬁle shar e is MOST r esilient and dur able?",
    "options": [
      "Migr ate the ﬁle shar e t o Amaz on RDS.",
      "Migr ate the ﬁle shar e t o Amaz on Elastic File System (Amaz on EFS).",
      "Migr ate the ﬁle shar e t o A WS St or age Gatewa y . D . Migr ate the ﬁle shar e t o Amaz on FSx for Windows File Ser v er . Corr ect answer Ov er all explanation The most r esilient and dur able r eplacement for the on-pr emises ﬁle shar e in this scenario would be Amaz on FSx for Windows File Ser v er . Amaz on FSx is a fully managed Windows ﬁle system ser vice that is built on Windows Ser v er and pr o vides nativ e suppor t for the SMB pr ot ocol. It is designed t o be highly a v ailable and dur able, with built-in backup and r est or e capabilities. It is also fully integr ated with A WS security ser vices, pr o viding encr yption at r est and in tr ansit, and it can be conﬁgur ed t o meet compliance standar ds. PAGE85",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "79",
    "text": "A company has r egister ed its domain name with A maz on Route 53. The company uses A maz on API Gatewa y in the ca-centr al-1 Region as a public inter face for its back end micr oser vice APIs. Thir d-par ty ser vices consume the APIs secur ely . The company wants t o design its API Gatewa y URL with the company ' s domain name and corr esponding cer tiﬁcate so that the thir d-par ty ser vices can use H T TPS. Which solution will meet these r equir ements?",
    "options": [
      "Cr eate Route 53 DNS r ecor ds with the company ' s domain name. P oint the alias r ecor d t o the Regional API Gatewa y stage endpoint. Impor t the public cer tiﬁcate associated with the company ' s domain name int o A WS Cer tiﬁcate Manager (A CM) in the us-east-1 Region.",
      "Cr eate a Regional API Gatewa y endpoint. Associate the API Gatewa y endpoint with the company ' s domain name. Impor t the public cer tiﬁcate associated with the company ' s domain name int o A WS Cer tiﬁcate Manager (A CM) in the same Region. A ttach the cer tiﬁcate t o the API Gatewa y endpoint. Conﬁgur e Route 53 t o r oute tr aﬃc t o the API Gatewa y endpoint. Corr ect answer",
      "Cr eate stage v ariables in API Gatewa y with Name=\"Endpoint-URL \" and V alue=\"Company Domain Name \" t o o v er write the default URL. Impor t the public cer tiﬁcate associated with the company ' s domain name int o A WS Cer tiﬁcate Manager (A CM). D . Cr eate a Regional API Gatewa y endpoint. Associate the API Gatewa y endpoint with the company ' s domain name. Impor t the public cer tiﬁcate associated with the company ' s domain name int o A WS Cer tiﬁcate Manager (A CM) in the us-east-1 Region. A ttach the cer tiﬁcate t o the API Gatewa y APIs. Cr eate Route 53 DNS r ecor ds with the company ' s domain name. P oint an A r ecor d t o the company ' s domain name. Ov er all explanation Cr eate a Regional API Gatewa y endpoint. Associate the API Gatewa y endpoint with the company ' s domain name. Impor t the public cer tiﬁcate associated with the company ' s domain name int o A WS Cer tiﬁcate Manager (A CM) in the same Region. A ttach the cer tiﬁcate t o the API Gatewa y endpoint. Conﬁgur e Route 53 t o r oute tr aﬃc t o the API Gatewa y endpoint. PAGE86",
      ""
    ],
    "correct_answer": null,
    "explanation": "T o set up a secur e API Gatewa y with a cust om domain and an SSL cer tiﬁcate for thir d-par ty ser vices, y ou should follow these steps: Cr eate a Regional API Gatewa y endpoint, as this allows y ou t o associate it with a cust om domain name. Impor t the public cer tiﬁcate associated with y our company ' s domain name int o A WS Cer tiﬁcate Manager (A CM). Mak e sur e the A CM cer tiﬁcate is in the same A WS Region as y our API Gatewa y for easy association. A ttach the A CM cer tiﬁcate t o the API Gatewa y endpoint. Conﬁgur e Route 53 t o r oute tr aﬃc t o the API Gatewa y endpoint, b y setting up the appr opriate DNS r ecor ds. This appr oach ensur es that y our API Gatewa y is associated with y our cust om domain name and secur ed using an SSL cer tiﬁcate, making it accessible via H T TPS for the thir d-par ty ser vices."
  },
  {
    "number": "80",
    "text": "A company has thousands of edge de vices that collectiv ely gener ate 1 TB of status aler ts each da y . Each aler t is appr o ximately 2 KB in siz e. A solutions ar chitect needs t o implement a solution t o ingest and st or e the aler ts for futur e analysis. The company wants a highly a v ailable solution. Howe v er , the company needs t o minimiz e costs and does not want t o manage additional infr astructur e. Additionally , the company wants t o k eep 14 da ys of data a v ailable for immediate analysis and ar chiv e any data older than 14 da ys. What is the MOST oper ationally eﬃcient solution that meets these r equir ements?",
    "options": [
      "Launch Amaz on EC2 instances acr oss two A v ailability Z ones and place them behind an Elastic Load Balancer t o ingest the aler ts. Cr eate a script on the EC2 instances that will st or e the aler ts in an Amaz on S3 buck et. Set up an S3 Lif ecy cle conﬁgur ation t o tr ansition data t o Amaz on S3 Glacier after 14 da ys.",
      "Cr eate an Amaz on Kinesis Data Fir ehose deliv er y str eam t o ingest the aler ts. Conﬁgur e the Kinesis Data Fir ehose str eam t o deliv er the aler ts t o an Amaz on S3 PAGE87 buck et. Set up an S3 Lif ecy cle conﬁgur ation t o tr ansition data t o Amaz on S3 Glacier after 14 da ys. Corr ect answer",
      "Cr eate an Amaz on Kinesis Data Fir ehose deliv er y str eam t o ingest the aler ts. Conﬁgur e the Kinesis Data Fir ehose str eam t o deliv er the aler ts t o an Amaz on Open Sear ch Ser vice (Amaz on Elasticsear ch Ser vice) cluster . Set up the Amaz on Open Sear ch Ser vice (Amaz on Elasticsear ch Ser vice) cluster t o tak e manual snapshots e v er y da y and delete data fr om the cluster that is older than 14 da ys. D . Cr eate an Amaz on Simple Queue Ser vice (Amaz on SQS) standar d queue t o ingest the aler ts, and set the message r etention period t o 14 da ys. Conﬁgur e consumers t o poll the SQS queue, check the age of the message, and analyz e the message data as needed. If the message is 14 da ys old, the consumer should cop y the message t o an Amaz on S3 buck et and delete the message fr om the SQS queue. Ov er all explanation Kinesis Data Fir ehose is a fully managed ser vice that mak es it easy t o ingest, tr ansform, and load data str eams int o v arious A WS ser vices, including Amaz on S3. St oring the data in Amaz on S3 is highly dur able, cost-eff ectiv e, and scalable. Y ou can conﬁgur e S3 t o tr ansition data t o Amaz on S3 Glacier after 14 da ys, which aligns with y our r equir ements for ar chiving data older than 14 da ys. This solution minimiz es oper ational o v erhead because it doesn 't r equir e y ou t o manage additional infr astructur e, such as EC2 instances, Elastic Load Balancers, or Elasticsear ch clusters. Data tr ansition t o S3 Glacier ensur es cost sa vings for long-term data r etention.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "81",
    "text": "A company r ecently migr ated t o A WS and wants t o implement a solution t o pr otect the tr aﬃc that ﬂows in and out of the pr oduction VP",
    "options": [
      "The company had an inspection ser v er in its on-pr emises data center . The inspection ser v er per formed speciﬁc oper ations such as tr aﬃc ﬂow inspection and tr aﬃc ﬁltering. The company wants t o ha v e the same functionalities in the A WS Cloud. Which solution will meet these r equir ements? PAGE88",
      "Use Amaz on Guar d Duty for tr aﬃc inspection and tr aﬃc ﬁltering in the pr oduction VP",
      "B. Use A WS Fir ewall Manager t o cr eate the r equir ed rules for tr aﬃc inspection and tr aﬃc ﬁltering for the pr oduction VP",
      "C. Use T r aﬃc Mirr oring t o mirr or tr aﬃc fr om the pr oduction VPC for tr aﬃc inspection and ﬁltering. D . Use A WS Network Fir ewall t o cr eate the r equir ed rules for tr aﬃc inspection and tr aﬃc ﬁltering for the pr oduction VP",
      "Corr ect answer Ov er all explanation A WS Network Fir ewall: A WS Network Fir ewall is a managed ﬁr ewall ser vice that allows y ou t o cr eate cust om rules for ﬁltering and inspecting network tr aﬃc. It' s designed for pr ecisely this type of tr aﬃc inspection and ﬁltering use case. Cust om Rules: Y ou can deﬁne cust om rules in A WS Network Fir ewall t o per form deep pack et inspection, ﬁltering, and other tr aﬃc management tasks t o meet y our speciﬁc r equir ements."
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "82",
    "text": "A company uses high block st or age capacity t o runs its workloads on pr emises. The company ' s daily peak input and output tr ansactions per second ar e not mor e than 15,000 IOPS. The company wants t o migr ate the workloads t o A maz on EC2 and t o pr o vision disk per formance independent of st or age capacity . Which A maz on Elastic Block St or e (A maz on EBS) v olume type will meet these r equir ements MOST cost-eff ectiv ely?",
    "options": [
      "GP2 v olume type",
      "io1 v olume type",
      "GP3 v olume type Corr ect answer D . io2 v olume type PAGE89 Ov er all explanation GP3 v olume type",
      ""
    ],
    "correct_answer": null,
    "explanation": "Independent P er formance: GP3 v olumes pr o vide independent per formance of IOPS and thr oughput, allowing for high IOPS per formance r egar dless of st or age capacity . Cost-E ff ectiv e: GP3 v olumes ar e cost-eff ectiv e and allow for ﬁne-tuning of per formance based on speciﬁc r equir ements. Pr o visioned IOPS: GP3 allows pr o visioning of IOPS based on application needs, ensuring high IOPS per formance for the giv en workload. Flexible St or age Capacity: GP3 v olumes off er ﬂexibility in st or age capacity , aligning with the r equir ement t o pr o vision disk per formance independent of st or age capacity . Ideal for Bursty W orkloads: GP3 is suitable for bursty workloads, making it cost-eff ectiv e while meeting the daily peak IOPS r equir ements."
  },
  {
    "number": "83",
    "text": "A solutions ar chitect is using A maz on S3 t o design the st or age ar chitectur e of a new digital media application. The media ﬁles must be r esilient t o the loss of an A v ailability Z one. Some ﬁles ar e accessed fr equently while other ﬁles ar e r ar ely accessed in an unpr edictable pattern. The solutions ar chitect must minimiz e the costs of st oring and r etrie ving the media ﬁles. Which st or age option meets these r equir ements?",
    "options": [
      "S3 One Z one-Infr equent Access (S3 One Z one-I A)",
      "S3 Standar d-Infr equent Access (S3 Standar d-I A)",
      "S3 Intelligent-Tiering Corr ect answer D . S3 Standar d PAGE90 Ov er all explanation Resilience: S3 Intelligent-Tiering pr o vides the same dur ability and a v ailability as S3 Standar d. It r eplicates objects acr oss multiple A v ailability Z ones, ensuring r esiliency t o the loss of an A v ailability Z one. Cost-Eﬃciency: S3 Intelligent-Tiering aut omatically mo v es objects between the fr equent and infr equent access tiers based on changing access patterns. This means y ou pa y lower st or age costs for infr equently accessed ﬁles, and it adjusts t o y our unpr edictable access pattern without manual inter v ention. This cost-eff ectiv e appr oach is ideal for ﬁles with v ar ying access fr equencies.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "84",
    "text": "A company uses A maz on EC2 instances and A WS Lambda functions t o run its application. The company has VPCs with public subnets and priv ate subnets in its A WS account. The EC2 instances run in a priv ate subnet in one of the VPCs. The Lambda functions need dir ect network access t o the EC2 instances for the application t o work. The application will run for at least 1 y ear . The company expects the number of Lambda functions that the application uses t o incr ease during that time. The company wants t o maximiz e its sa vings on all application r esour ces and t o k eep network latency between the ser vices low . Which solution will meet these r equir ements?",
    "options": [
      "Pur chase an EC2 Instance Sa vings Plan Optimiz e the Lambda functions' dur ation and memor y usage, the number of inv ocations, and the amount of data that is tr ansf err ed. Connect the Lambda functions t o a public subnet in the same VPC wher e the EC2 instances run.",
      "Pur chase an EC2 Instance Sa vings Plan Optimiz e the Lambda functions’ dur ation and memor y usage and the number of inv ocations. Connect the Lambda functions t o the priv ate subnet that contains the EC2 instances.",
      "Pur chase a Compute Sa vings Plan. Optimiz e the Lambda functions’ dur ation and memor y usage, the number of inv ocations, and the amount of data that is tr ansf err ed. Connect the Lambda functions t o the priv ate subnet that contains the EC2 instances. Corr ect answer PAGE91 D . Pur chase a Compute Sa vings Plan. Optimiz e the Lambda functions’ dur ation and memor y usage, the number of inv ocations, and the amount of data that is tr ansf err ed. K eep the Lambda functions in the Lambda ser vice VP",
      "Ov er all explanation Pur chase a Compute Sa vings Plan. Optimiz e the Lambda functions’ dur ation and memor y usage, the number of inv ocations, and the amount of data that is tr ansf err ed. Connect the Lambda functions t o the priv ate subnet that contains the EC2 instances."
    ],
    "correct_answer": null,
    "explanation": "Compute Sa vings Plan: Pur chasing a Compute Sa vings Plan pr o vides cost sa vings for both EC2 instances and Lambda functions, optimizing expenses. Optimizing Lambda F unctions: Optimizing dur ation, memor y usage, inv ocations, and data tr ansf er helps in maximizing the eﬃciency of Lambda functions. Priv ate Subnet Access: Connecting Lambda functions t o the priv ate subnet ensur es dir ect network access t o EC2 instances, meeting the application ' s r equir ements. Least Privilege: Placing Lambda functions in the priv ate subnet adher es t o the principle of least privilege, enhancing security . Minimizing Latency: Connecting t o r esour ces within the same priv ate subnet minimiz es network latency between Lambda functions and EC2 instances."
  },
  {
    "number": "85",
    "text": "A company has mor e than 5 TB of ﬁle data on Windows ﬁle ser v ers that run on pr emises. Users and applications inter act with the data each da y . The company is mo ving its Windows workloads t o A WS. As the company continues this pr ocess, the company r equir es access t o A WS and on-pr emises ﬁle st or age with minimum latency . The company needs a solution that minimiz es oper ational o v erhead and r equir es no signiﬁcant changes t o the existing ﬁle access patterns. The company uses an A WS Site-t o-Site VPN connection for connectivity t o A WS. What should a solutions ar chitect do t o meet these r equir ements? PAGE92",
    "options": [
      "Deplo y and conﬁgur e an Amaz on S3 File Gatewa y on pr emises. Mo v e the on-pr emises ﬁle data t o the S3 File Gatewa y . Reconﬁgur e the on-pr emises workloads and the cloud workloads t o use the S3 File Gatewa y .",
      "Deplo y and conﬁgur e an Amaz on S3 File Gatewa y on pr emises. Mo v e the on-pr emises ﬁle data t o Amaz on S3. Reconﬁgur e the workloads t o use either Amaz on S3 dir ectly or the S3 File Gatewa y . depending on each workload' s location.",
      "Deplo y and conﬁgur e Amaz on FSx for Windows File Ser v er on A WS. Deplo y and conﬁgur e an Amaz on FSx File Gatewa y on pr emises. Mo v e the on-pr emises ﬁle data t o the FSx File Gatewa y . Conﬁgur e the cloud workloads t o use FSx for Windows File Ser v er on A WS. Conﬁgur e the on-pr emises workloads t o use the FSx File Gatewa y . Corr ect answer D . Deplo y and conﬁgur e Amaz on FSx for Windows File Ser v er on A WS. Mo v e the on-pr emises ﬁle data t o FSx for Windows File Ser v er . Reconﬁgur e the workloads t o use FSx for Windows File Ser v er on A WS. Ov er all explanation The Amaz on FSx File Gatewa y extends Amaz on FSx for Windows File Ser v er t o any site with an internet connection. It pr o vides a scalable local cache, up t o 64 TB, for low latency access t o most r ecently used ﬁles. By deplo ying an Amaz on FSx File Gatewa y within y our data center or r emote and br anch oﬃces, y our Windows clients ar e able t o connect o v er the L AN. As Amaz on FSx File Gatewa y is a local cache of most r ecently accessed data back ed b y an Amaz on FSx ﬁle system, it looks lik e a local ﬁle ser v er t o users and applications.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "86",
    "text": "A solutions ar chitect is designing a two-tier ed ar chitectur e that includes a public subnet and a database subnet. The web ser v ers in the public subnet must be open t o the internet on por t 443. The A maz on RDS for My SQL DB instance in the database subnet must be accessible only t o the web ser v ers on por t 3306. Which combination of steps should the solutions ar chitect tak e t o meet these r equir ements? (Choose two.) PAGE93",
    "options": [
      "Cr eate a security gr oup for the web ser v ers in the public subnet. Add a rule t o allow tr aﬃc fr om 0.0.0.0/0 on por t 443. Corr ect answer",
      "Cr eate a network A CL for the public subnet. Add a rule t o deny outbound tr aﬃc t o 0.0.0.0/0 on por t 3306.",
      "Cr eate a security gr oup for the DB instance. Add a rule t o allow tr aﬃc fr om the web ser v ers’ security gr oup on por t 3306. Corr ect answer D . Cr eate a security gr oup for the DB instance. Add a rule t o allow tr aﬃc fr om the public subnet CIDR block on por t 3306. E. Cr eate a security gr oup for the DB instance. Add a rule t o deny all tr aﬃc ex cept tr aﬃc fr om the web ser v ers’ security gr oup on por t 3306. Ov er all explanation T o allow communication between the web ser v ers and the database secur ely , it' s best t o cr eate a security gr oup for the DB instance and allow tr aﬃc fr om the security gr oup of the web ser v ers on por t 3306. Allowing inbound tr aﬃc on por t 443 fr om 0.0.0.0/0 for the web ser v ers in the public subnet ensur es accessibility t o the application o v er H T TPS fr om anywher e.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "87",
    "text": "A company is deplo ying a new public web application t o A WS. The application will run behind an A pplication Load Balancer (ALB). The application needs t o be encr ypted at the edge with an SSL/TLS cer tiﬁcate that is issued b y an external cer tiﬁcate authority (CA). The cer tiﬁcate must be r otated each y ear befor e the cer tiﬁcate expir es. What should a solutions ar chitect do t o meet these r equir ements?",
    "options": [
      "Use A WS Cer tiﬁcate Manager (A CM) t o issue an SSL/TLS cer tiﬁcate. Apply the cer tiﬁcate t o the AL",
      "Use the managed r enewal f eatur e t o aut omatically r otate the cer tiﬁcate.",
      "Use A WS Cer tiﬁcate Manager (A CM) t o issue an SSL/TLS cer tiﬁcate. Impor t the k e y material fr om the cer tiﬁcate. Apply the cer tiﬁcate t o the AL Use the managed r enewal f eatur e t o aut omatically r otate the cer tiﬁcate. PAGE94",
      "Use A WS Cer tiﬁcate Manager (A CM) t o impor t an SSL/TLS cer tiﬁcate. Apply the cer tiﬁcate t o the AL",
      "Use Amaz on E v ent Bridge (Amaz on Cloud W atch E v ents) t o send a notiﬁcation when the cer tiﬁcate is nearing expir ation. Rotate the cer tiﬁcate manually . Corr ect answer D . Use A WS Cer tiﬁcate Manager (A CM) Priv ate Cer tiﬁcate A uthority t o issue an SSL/TLS cer tiﬁcate fr om the r oot C",
      "Apply the cer tiﬁcate t o the AL",
      "Use the managed r enewal f eatur e t o aut omatically r otate the cer tiﬁcate. Ov er all explanation Use A WS Cer tiﬁcate Manager (A CM) t o impor t an SSL/TLS cer tiﬁcate. Apply the cer tiﬁcate t o the AL",
      "Use Amaz on E v ent Bridge (Amaz on Cloud W atch E v ents) t o send a notiﬁcation when the cer tiﬁcate is nearing expir ation. Rotate the cer tiﬁcate manually . With this appr oach, y ou impor t the thir d-par ty cer tiﬁcate int o A CM, which allows y ou t o centr ally manage and apply it t o the AL",
      "By conﬁguring Cloud W atch E v ents, y ou can r eceiv e notiﬁcations when the cer tiﬁcate is close t o expiring, pr ompting y ou t o manually initiate the r otation pr ocess."
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "88",
    "text": "A company pr o vides a V oice o v er Internet Pr ot ocol ( V o IP) ser vice that uses UDP connections. The ser vice consists of A maz on EC2 instances that run in an A ut o Scaling gr oup. The company has deplo yments acr oss multiple A WS Regions. The company needs t o r oute users t o the Region with the lowest latency . The company also needs aut omated failo v er between Regions. Which solution will meet these r equir ements?",
    "options": [
      "Deplo y a Network Load Balancer (NLB) and an associated tar get gr oup. Associate the tar get gr oup with the A ut o Scaling gr oup. Use the NLB as an A WS Global Acceler at or endpoint in each Region.",
      "Deplo y an Application Load Balancer (ALB) and an associated tar get gr oup. Associate the tar get gr oup with the A ut o Scaling gr oup. Use the ALB as an A WS Global Acceler at or endpoint in each Region. PAGE95",
      "Deplo y a Network Load Balancer (NLB) and an associated tar get gr oup. Associate the tar get gr oup with the A ut o Scaling gr oup. Cr eate an Amaz on Route 53 latency r ecor d that points t o aliases for each NL",
      "Cr eate an Amaz on Cloud F r ont distribution that uses the latency r ecor d as an origin. Corr ect answer D . Deplo y an Application Load Balancer (ALB) and an associated tar get gr oup. Associate the tar get gr oup with the A ut o Scaling gr oup. Cr eate an Amaz on Route 53 weighted r ecor d that points t o aliases for each AL",
      "Deplo y an Amaz on Cloud F r ont distribution that uses the weighted r ecor d as an origin. Ov er all explanation Network Load Balancer (NLB): NLB is designed t o handle T CP/UDP tr aﬃc and is a good ﬁt for V o IP ser vices that use UDP connections. T ar get Gr oup: Associate the NLB with a tar get gr oup, which allows y ou t o connect the NLB t o the A ut o Scaling gr oup. A maz on Route 53 Latency Recor d: Cr eate an Amaz on Route 53 latency-based r ecor d set. This r ecor d will r oute users t o the Region with the lowest latency based on their geogr aphical location. Amaz on Route 53 can r esolv e DNS queries t o the closest A WS Region, helping ensur e the lowest latency r outing. A maz on Cloud F r ont: Utiliz e Amaz on Cloud F r ont with the Amaz on Route 53 latency r ecor d as an origin. Amaz on Cloud F r ont can pr o vide a content deliv er y network (CDN) t o cache and ser v e content closer t o end-users, fur ther r educing latency ."
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "89",
    "text": "A company wants t o use an A maz on RDS for P ostgr e SQL DB cluster t o simplify time-consuming database administr ativ e tasks for pr oduction database workloads. The company wants t o ensur e that its database is highly a v ailable and will pr o vide aut omatic failo v er suppor t in most scenarios in less than 40 seconds. The company wants t o oﬄoad r eads off of the primar y instance and k eep costs as low as possible. Which solution will meet these r equir ements? Use an Amaz on RDS Multi-AZ DB cluster deplo yment P oint the r ead workload t o the r eader endpoint. Corr ect answer PAGE96 Use an Amaz on RDS Multi-AZ DB duster deplo yment Cr eate two r ead r eplicas and point the r ead workload t o the r ead r eplicas. Use an Amaz on RDS Multi-AZ DB instance deplo yment. P oint the r ead workload t o the secondar y instances in the Multi-AZ pair . Use an Amaz on RDS Multi-AZ DB instance deplo yment. Cr eate one r ead r eplica and point the r ead workload t o the r ead r eplica. Ov er all explanation Use an Amaz on RDS Multi-AZ DB cluster deplo yment. P oint the r ead workload t o the r eader endpoint. \nExplanation: Multi-AZ DB Cluster Deplo yment: Amaz on RDS Multi-AZ deplo yment pr o vides high a v ailability and aut omatic failo v er suppor t, meeting the r equir ement for a highly a v ailable database. Read Replicas: Utilizing r ead r eplicas oﬄoads r ead oper ations fr om the primar y instance, enhancing o v er all database per formance. Reader Endpoint: The r eader endpoint aut omatically dir ects r ead tr aﬃc t o the appr opriate r eplica, distributing the workload and minimizing load on the primar y instance. A ut omatic F ailo v er Suppor t: In case of a failur e, Multi-AZ deplo yment ensur es aut omatic failo v er t o a standb y r eplica in less than 40 seconds. Cost-E ff ectiv e: The combination of Multi-AZ deplo yment and r ead r eplicas allows for eﬃcient scaling and cost-eff ectiv e utilization of database r esour ces.",
    "options": [
      "",
      "",
      "",
      ""
    ],
    "correct_answer": null,
    "explanation": "Multi-AZ DB Cluster Deplo yment: Amaz on RDS Multi-AZ deplo yment pr o vides high a v ailability and aut omatic failo v er suppor t, meeting the r equir ement for a highly a v ailable database. Read Replicas: Utilizing r ead r eplicas oﬄoads r ead oper ations fr om the primar y instance, enhancing o v er all database per formance. Reader Endpoint: The r eader endpoint aut omatically dir ects r ead tr aﬃc t o the appr opriate r eplica, distributing the workload and minimizing load on the primar y instance. A ut omatic F ailo v er Suppor t: In case of a failur e, Multi-AZ deplo yment ensur es aut omatic failo v er t o a standb y r eplica in less than 40 seconds. Cost-E ff ectiv e: The combination of Multi-AZ deplo yment and r ead r eplicas allows for eﬃcient scaling and cost-eff ectiv e utilization of database r esour ces."
  },
  {
    "number": "90",
    "text": "A company is running an SMB ﬁle ser v er in its data center . The ﬁle ser v er st or es lar ge ﬁles that ar e accessed fr equently for the ﬁrst f ew da ys after the ﬁles ar e cr eated. After 7 da ys the ﬁles ar e r ar ely accessed. The t otal data siz e is incr easing and is close t o the company ' s t otal st or age capacity . A solutions ar chitect must incr ease the company ' s a v ailable st or age space without PAGE97 losing low-latency access t o the most r ecently accessed ﬁles. The solutions ar chitect must also pr o vide ﬁle lif ecy cle management t o a v oid futur e st or age issues. Which solution will meet these r equir ements?",
    "options": [
      "Install a utility on each user ' s computer t o access Amaz on S3. Cr eate an S3 Lif ecy cle policy t o tr ansition the data t o S3 Glacier Flexible Retrie v al after 7 da ys.",
      "Cr eate an Amaz on S3 File Gatewa y t o extend the company ' s st or age space. Cr eate an S3 Lif ecy cle policy t o tr ansition the data t o S3 Glacier Deep Ar chiv e after 7 da ys. Corr ect answer",
      "Use A WS Data Sync t o cop y data that is older than 7 da ys fr om the SMB ﬁle ser v er t o A WS D . Cr eate an Amaz on FSx for Windows File Ser v er ﬁle system t o extend the company ' s st or age space. Ov er all explanation A maz on S3 File Gatewa y: Amaz on S3 File Gatewa y allows y ou t o extend y our st or age capacity using Amaz on S3 as the back end. It pr o vides low-latency access t o fr equently accessed ﬁles and seamlessly integr ates with y our on-pr emises ﬁle ser v er . S3 Lif ecy cle P olicy: S3 pr o vides a r obust lif ecy cle management f eatur e that can aut omatically tr ansition data t o lower-cost st or age classes such as S3 Glacier Deep Ar chiv e after a speciﬁed number of da ys (in this case, 7 da ys). This ensur es that r ar ely accessed ﬁles ar e ar chiv ed, sa ving st or age costs while still being accessible.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "91",
    "text": "A company ' s application integr ates with multiple softwar e-as-a-ser vice (Saa S) sour ces for data collection. The company runs A maz on EC2 instances t o r eceiv e the data and t o upload the data t o an A maz on S3 buck et for analysis. The same EC2 instance that r eceiv es and uploads the data also sends a notiﬁcation t o the user when an upload is complete. The company has noticed slow application per formance and wants t o impr o v e the per formance as much as possible. Which solution will meet these r equir ements with the LEAST oper ational o v erhead? PAGE98",
    "options": [
      "Cr eate an Amaz on E v ent Bridge (Amaz on Cloud W atch E v ents) rule for each Saa S sour ce t o send output data. Conﬁgur e the S3 buck et as the rule ' s tar get. Cr eate a second E v ent Bridge (Cloud W atch E v ents) rule t o send e v ents when the upload t o the S3 buck et is complete. Conﬁgur e an Amaz on Simple Notiﬁcation Ser vice (Amaz on SNS) t opic as the second rule ' s tar get.",
      "Cr eate an Amaz on App Flow ﬂow t o tr ansf er data between each Saa S sour ce and the S3 buck et. Conﬁgur e an S3 e v ent notiﬁcation t o send e v ents t o an Amaz on Simple Notiﬁcation Ser vice (Amaz on SNS) t opic when the upload t o the S3 buck et is complete. Corr ect answer",
      "Cr eate an A ut o Scaling gr oup so that EC2 instances can scale out. Conﬁgur e an S3 e v ent notiﬁcation t o send e v ents t o an Amaz on Simple Notiﬁcation Ser vice (Amaz on SNS) t opic when the upload t o the S3 buck et is complete. D . Cr eate a Dock er container t o use instead of an EC2 instance. Host the containeriz ed application on Amaz on Elastic Container Ser vice (Amaz on ECS). Conﬁgur e Amaz on Cloud W atch Container Insights t o send e v ents t o an Amaz on Simple Notiﬁcation Ser vice (Amaz on SNS) t opic when the upload t o the S3 buck et is complete. Ov er all explanation Amaz on App Flow simpliﬁes the pr ocess of tr ansf erring data between Saa S sour ces and S3, r educing the oper ational o v erhead r equir ed for handling data ingestion. Conﬁguring S3 e v ent notiﬁcations t o send e v ents t o an SNS t opic when uploads ar e complete ensur es that the notiﬁcation functionality r emains intact without signiﬁcant o v erhead. This solution oﬄoads the data tr ansf er pr ocess t o App Flow , making it mor e eﬃcient and r educing the workload on the EC2 instances.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "92",
    "text": "A ﬁnancial company hosts a web application on A WS. The application uses an A maz on API Gatewa y Regional API endpoint t o giv e users the ability t o r etrie v e curr ent st ock prices. The company ’ s security team has noticed an incr ease in the number of API r equests. The security team is concerned that H T TP ﬂood attacks might tak e the application oﬄine. PAGE99 A solutions ar chitect must design a solution t o pr otect the application fr om this type of attack. Which solution meets these r equir ements with the LEAST oper ational o v erhead?",
    "options": [
      "Cr eate a Regional A WS W AF web A CL with a r ate-based rule. Associate the web A CL with the API Gatewa y stage. Corr ect answer",
      "Cr eate an Amaz on Cloud F r ont distribution with Lambda@E dge in fr ont of the API Gatewa y Regional API endpoint. Cr eate an A WS Lambda function t o block r equests fr om IP addr esses that ex ceed the pr edeﬁned r ate.",
      "Use Amaz on Cloud W atch metrics t o monit or the Count metric and aler t the security team when the pr edeﬁned r ate is r eached. D . Cr eate an Amaz on Cloud F r ont distribution in fr ont of the API Gatewa y Regional API endpoint with a maximum T TL of 24 hours. Ov er all explanation A WS W AF ( W eb Application Fir ewall) pr o vides pr otection against common web exploits. Using a r ate-based rule in a web A CL allows y ou t o set thr esholds for r equest r ates, helping t o mitigate H T TP ﬂood attacks with minimal oper ational o v erhead. Regional A WS W AF web A CL is a managed web application ﬁr ewall that can be used t o pr otect y our API Gatewa y API fr om a v ariety of attacks, including H T TP ﬂood attacks. Rate-based rule is a type of rule that can be used t o limit the number of r equests that can be made fr om a single IP addr ess within a speciﬁed period of time. API Gatewa y stage is a logical gr ouping of API r esour ces that can be used t o contr ol access t o y our API.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "93",
    "text": "A company ' s website uses an A maz on EC2 instance st or e for its catalog of items. The company wants t o mak e sur e that the catalog is highly a v ailable and that the catalog is st or ed in a dur able location. What should a solutions ar chitect do t o meet these r equir ements?",
    "options": [
      "Mo v e the catalog t o Amaz on Elasti Cache for Redis. PAGE100",
      "Mo v e the catalog fr om the instance st or e t o Amaz on S3 Glacier Deep Ar chiv e.",
      "Deplo y a lar ger EC2 instance with a lar ger instance st or e. D . Mo v e the catalog t o an Amaz on Elastic File System (Amaz on EFS) ﬁle system. Corr ect answer Ov er all explanation Amaz on Elastic File System (Amaz on EFS) is a scalable and highly a v ailable ﬁle st or age ser vice. It is designed t o pr o vide ﬁle st or age that can be accessed fr om multiple EC2 instances in diff er ent A v ailability Z ones, ensuring data dur ability and a v ailability . High A v ailability: Amaz on EFS is a highly a v ailable and scalable ﬁle st or age ser vice. It' s designed t o pr o vide a shar ed ﬁle system that can be accessed b y multiple Amaz on EC2 instances in diff er ent A v ailability Z ones within an A WS Region. This means that e v en if one A v ailability Z one experiences issues, y our data r emains accessible fr om other instances in diff er ent z ones, ensuring high a v ailability . Data Dur ability: Amaz on EFS is designed for dur ability . Y our data is aut omatically r eplicated acr oss multiple A v ailability Z ones, which mak es it r esilient t o har dwar e failur es or other issues that could aff ect a single instance. The data is st or ed r edundantly , so ther e ' s a v er y low risk of data loss. Ease of Use: With Amaz on EFS, y ou can easily mount the shar ed ﬁle system on y our EC2 instances. This allows y our website t o access the catalog data lik e it would fr om a r egular ﬁle system. It simpliﬁes data access and management. Scalability: Amaz on EFS can aut omatically gr ow and shrink with y our data st or age needs. Y ou don 't need t o worr y about pr o visioning the right amount of st or age upfr ont, and it' s cost-eff ectiv e.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "94",
    "text": "A company per forms monthly maintenance on its A WS infr astructur e. During these maintenance activities, the company needs t o r otate the cr edentials for its A maz on RDS for My SQL databases acr oss multiple A WS Regions. Which solution will meet these r equir ements with the LEAST oper ational o v erhead? PAGE101",
    "options": [
      "St or e the cr edentials as secr ets in A WS Secr ets Manager . Use multi-Region secr et r eplication for the r equir ed Regions. Conﬁgur e Secr ets Manager t o r otate the secr ets on a schedule. Corr ect answer",
      "St or e the cr edentials in an Amaz on S3 buck et that has ser v er-side encr yption (SSE) enabled. Use Amaz on E v ent Bridge (Amaz on Cloud W atch E v ents) t o inv ok e an A WS Lambda function t o r otate the cr edentials.",
      "St or e the cr edentials as secr ets in A WS Systems Manager b y cr eating a secur e string par ameter . Use multi-Region secr et r eplication for the r equir ed Regions. Conﬁgur e Systems Manager t o r otate the secr ets on a schedule. D . Encr ypt the cr edentials as secr ets b y using A WS K e y Management Ser vice (A WS KMS) multi-Region cust omer managed k e ys. St or e the secr ets in an Amaz on Dynamo DB global table. Use an A WS Lambda function t o r etrie v e the secr ets fr om Dynamo D",
      "Use the RDS API t o r otate the secr ets. Ov er all explanation A WS Secr ets Manager: A WS Secr ets Manager is designed speciﬁcally for secur ely managing and r otating cr edentials. It off ers a built-in capability t o manage and aut omatically r otate secr ets. Multi-Region Secr et Replication: A WS Secr ets Manager allows y ou t o r eplicate secr ets t o multiple A WS Regions, ensuring that the cr edentials ar e a v ailable in the r equir ed Regions. A ut omatic Rotation: A WS Secr ets Manager can be conﬁgur ed t o r otate secr ets aut omatically on a schedule, which r educes oper ational o v erhead and enhances security ."
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "95",
    "text": "A company needs t o st or e data fr om its healthcar e application. The application ’ s data fr equently changes. A new r egulation r equir es audit access at all le v els of the st or ed data. The company hosts the application on an on-pr emises infr astructur e that is running out of st or age capacity . A solutions ar chitect must secur ely migr ate the existing data t o A WS while satisfying the new r egulation. PAGE102 Which solution will meet these r equir ements?",
    "options": [
      "Use A WS St or age Gatewa y t o mo v e the existing data t o Amaz on S3. Use A WS Cloud T r ail t o log management e v ents.",
      "Use A WS Snowcone t o mo v e the existing data t o Amaz on S3. Use A WS Cloud T r ail t o log management e v ents.",
      "Use A WS Data Sync t o mo v e the existing data t o Amaz on S3. Use A WS Cloud T r ail t o log data e v ents. Corr ect answer D . Use Amaz on S3 T r ansf er Acceler ation t o mo v e the existing data t o Amaz on S3. Use A WS Cloud T r ail t o log data e v ents. Ov er all explanation - Data sync is used for migr ate. St or age gw is used t o connect on-pr em t o A WS. - Data E v ents is t o log for access, management e v ents is for conﬁg or management",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "96",
    "text": "A company has deplo y ed a ser v erless application that inv ok es an A WS Lambda function when new documents ar e uploaded t o an A maz on S3 buck et. The application uses the Lambda function t o pr ocess the documents. After a r ecent mark eting campaign, the company noticed that the application did not pr ocess many of the documents. What should a solutions ar chitect do t o impr o v e the ar chitectur e of this application?",
    "options": [
      "Conﬁgur e an S3 buck et r eplication policy . Stage the documents in the S3 buck et for later pr ocessing.",
      "Deplo y an additional Lambda function. Load balance the pr ocessing of the documents acr oss the two Lambda functions.",
      "Cr eate an Amaz on Simple Queue Ser vice (Amaz on SQS) queue. Send the r equests t o the queue. Conﬁgur e the queue as an e v ent sour ce for Lambda. Corr ect answer PAGE103 D . Set the Lambda function ' s runtime timeout v alue t o 15 minutes. Ov er all explanation Cr eate an Amaz on Simple Queue Ser vice (Amaz on SQS) queue. Send the r equests t o the queue. Conﬁgur e the queue as an e v ent sour ce for Lambda.",
      ""
    ],
    "correct_answer": null,
    "explanation": "Intr oducing Amaz on SQS as a buff er between the S3 e v ent and the Lambda function can help decouple the pr ocessing and impr o v e the ar chitectur e ' s r esilience. SQS can act as an e v ent queue, and Lambda can be conﬁgur ed t o pr ocess items fr om the SQS queue. This allows for better management of the workload, handling peaks eﬃciently , and a v oiding the loss of documents during hea vy tr aﬃc."
  },
  {
    "number": "97",
    "text": "A company has an application that runs on A maz on EC2 instances and uses an A maz on A ur or a database. The EC2 instances connect t o the database b y using user names and passwor ds that ar e st or ed locally in a ﬁle. The company wants t o minimiz e the oper ational o v erhead of cr edential management. What should a solutions ar chitect do t o accomplish this goal?",
    "options": [
      "Cr eate an Amaz on S3 buck et t o st or e objects that ar e encr ypted with an A WS K e y Management Ser vice (A WS KMS) encr yption k e y . Migr ate the cr edential ﬁle t o the S3 buck et. P oint the application t o the S3 buck et.",
      "Cr eate an encr ypted Amaz on Elastic Block St or e (Amaz on EBS) v olume for each EC2 instance. A ttach the new EBS v olume t o each EC2 instance. Migr ate the cr edential ﬁle t o the new EBS v olume. P oint the application t o the new EBS v olume.",
      "Use A WS Secr ets Manager . T urn on aut omatic r otation. Corr ect answer D . Use A WS Systems Manager P ar ameter St or e. T urn on aut omatic r otation. PAGE104 Ov er all explanation A WS Secr ets Manager: A WS Secr ets Manager is a ser vice designed for secur e and eﬃcient management of cr edentials, secr ets, and other sensitiv e information. It pr o vides a centr al and secur e r eposit or y for st oring database cr edentials. A ut omatic Rotation: A WS Secr ets Manager allows y ou t o enable aut omatic cr edential r otation. This f eatur e helps enhance security b y aut omatically r otating database cr edentials, r educing the risk associated with long-liv ed cr edentials. It also minimiz es oper ational o v erhead because cr edential r otation is aut omated, r educing manual management tasks.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "98",
    "text": "A company has a business system that gener ates hundr eds of r epor ts each da y . The business system sa v es the r epor ts t o a network shar e in CSV format. The company needs t o st or e this data in the A WS Cloud in near-r eal time for analysis. Which solution will meet these r equir ements with the LEAST administr ativ e o v erhead?",
    "options": [
      "Use A WS Data Sync t o tr ansf er the ﬁles t o Amaz on S3. Cr eate a scheduled task that runs at the end of each da y .",
      "Deplo y an A WS T r ansf er for SF TP endpoint. Cr eate a script that checks for new ﬁles on the network shar e and uploads the new ﬁles b y using SF TP .",
      "Use A WS Data Sync t o tr ansf er the ﬁles t o Amaz on S3. Cr eate an application that uses the Data Sync API in the aut omation workﬂow . D . Cr eate an Amaz on S3 File Gatewa y . Update the business system t o use a new network shar e fr om the S3 File Gatewa y . Corr ect answer Ov er all explanation Cr eate an Amaz on S3 File Gatewa y . Update the business system t o use a new network shar e fr om the S3 File Gatewa y . This option r equir es the least administr ativ e o v erhead because: PAGE105 - It pr esents a simple network ﬁle shar e inter face that the business system can write t o, just lik e a standar d network shar e. This r equir es minimal changes t o the business system. - The S3 File Gatewa y aut omatically uploads all ﬁles written t o the shar e t o an S3 buck et in the back gr ound. This handles the tr ansf er and upload t o S3 without r equiring any scheduled tasks, scripts or aut omation. - All ongoing management lik e monit oring, scaling, patching etc. is handled b y A WS for the S3 File Gatewa y .",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "99",
    "text": "A company is st oring petab ytes of data in A maz on S3 Standar d. The data is st or ed in multiple S3 buck ets and is accessed with v ar ying fr equency . The company does not know access patterns for all the data. The company needs t o implement a solution for each S3 buck et t o optimiz e the cost of S3 usage. Which solution will meet these r equir ements with the MOST oper ational eﬃciency? Cr eate an S3 Lif ecy cle conﬁgur ation with a rule t o tr ansition the objects in the S3 buck et t o S3 One Z one-Infr equent Access (S3 One Z one-I A). Cr eate an S3 Lif ecy cle conﬁgur ation with a rule t o tr ansition the objects in the S3 buck et t o S3 Glacier Instant Retrie v al. Cr eate an S3 Lif ecy cle conﬁgur ation with a rule t o tr ansition the objects in the S3 buck et t o S3 Intelligent-Tiering. Corr ect answer Use the S3 st or age class analysis t ool t o determine the corr ect tier for each object in the S3 buck et. Mo v e each object t o the identiﬁed st or age tier . Ov er all explanation Cr eate an S3 Lif ecy cle conﬁgur ation with a rule t o tr ansition the objects in the S3 buck et t o S3 Intelligent-Tiering. PAGE106 \nExplanation: S3 Lif ecy cle Conﬁgur ation: A ut omating the tr ansition of objects based on access patterns is achie v ed thr ough S3 Lif ecy cle policies. S3 Intelligent-Tiering: It aut omatically mo v es objects between two access tiers (fr equent and infr equent access) based on changing access patterns. Least Oper ational Ov erhead: S3 Intelligent-Tiering r equir es no manual inter v ention for object mo v ement, minimizing oper ational o v erhead. Cost Optimization: A ut omatically mo ving objects t o the most cost-eff ectiv e st or age class based on access patterns helps optimiz e costs. Adaptiv e t o V ar ying Access: S3 Intelligent-Tiering adapts t o v ar ying access patterns without the need for explicit management.",
    "options": [
      "",
      "",
      "",
      ""
    ],
    "correct_answer": null,
    "explanation": "S3 Lif ecy cle Conﬁgur ation: A ut omating the tr ansition of objects based on access patterns is achie v ed thr ough S3 Lif ecy cle policies. S3 Intelligent-Tiering: It aut omatically mo v es objects between two access tiers (fr equent and infr equent access) based on changing access patterns. Least Oper ational Ov erhead: S3 Intelligent-Tiering r equir es no manual inter v ention for object mo v ement, minimizing oper ational o v erhead. Cost Optimization: A ut omatically mo ving objects t o the most cost-eff ectiv e st or age class based on access patterns helps optimiz e costs. Adaptiv e t o V ar ying Access: S3 Intelligent-Tiering adapts t o v ar ying access patterns without the need for explicit management."
  },
  {
    "number": "100",
    "text": "A company is hosting a static website on A maz on S3 and is using A maz on Route 53 for DNS. The website is experiencing incr eased demand fr om ar ound the world. The company must decr ease latency for users who access the website. Which solution meets these r equir ements MOST cost-eff ectiv ely?",
    "options": [
      "Replicate the S3 buck et that contains the website t o all A WS Regions. Add Route 53 geolocation r outing entries.",
      "Enable S3 T r ansf er Acceler ation on the buck et. E dit the Route 53 entries t o point t o the new endpoint.",
      "Pr o vision acceler at ors in A WS Global Acceler at or . Associate the supplied IP addr esses with the S3 buck et. E dit the Route 53 entries t o point t o the IP addr esses of the acceler at ors. D . Add an Amaz on Cloud F r ont distribution in fr ont of the S3 buck et. E dit the Route 53 entries t o point t o the Cloud F r ont distribution. Corr ect answer Ov er all explanation By using Amaz on Cloud F r ont in fr ont of y our S3 buck et, y ou can r educe latency for users accessing the website. PAGE107 Cloud F r ont has a global network of edge locations, which will cache and ser v e content fr om the edge locations closest t o the users. This helps t o impr o v e latency and r educes the load on the S3 buck et, making it a cost-eff ectiv e solution for decr easing latency for a static website.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "101",
    "text": "The following I AM policy is attached t o an I AM gr oup. This is the only policy applied t o the gr oup. What ar e the eff ectiv e I AM permissions of this policy for gr oup members?",
    "options": [
      "Gr oup members ar e permitted any Amaz on EC2 action within the us-east-1 Region. Statements after the Allow permission ar e not applied.",
      "Gr oup members ar e allowed the ec2:St op Instances and ec2:T erminate Instances permissions for all Regions when logged in with multi-fact or authentication (MF A). Gr oup members ar e permitted any other Amaz on EC2 action.",
      "Gr oup members ar e allowed the ec2:St op Instances and ec2:T erminate Instances permissions for the us-east-1 Region only when logged in with multi-fact or authentication (MF A). Gr oup members ar e permitted any other Amaz on EC2 action within the us-east-1 Region. Corr ect answer D . Gr oup members ar e denied any Amaz on EC2 permissions in the us-east-1 Region unless the y ar e logged in with multi-fact or authentication (MF A). Ov er all explanation Gr oup members ar e allowed the ec2:St op Instances and ec2:T erminate Instances permissions for the us-east-1 Region only when logged in with multi-fact or authentication (MF A). Gr oup members ar e permitted any other Amaz on EC2 action within the us-east-1 Region.",
      ""
    ],
    "correct_answer": null,
    "explanation": "PAGE108 I AM P olicy Statements: The policy includes speciﬁc statements allowing ec2:St op Instances and ec2:T erminate Instances actions with conditions. Region-Speciﬁc P ermissions: P ermissions ar e speciﬁed for the us-east-1 Region, limiting the scope of the actions t o a speciﬁc r egion. Multi-F act or A uthentication (MF A): Additional conditions r equir e users t o be logged in with MF A t o per form cer tain actions, enhancing security . Wildcar d P ermission: The policy permits any other EC2 action within the speciﬁed r egion, pr o viding ﬂexibility for other actions. Gr anular Access Contr ol: The policy enfor ces gr anular access contr ol, allowing only speciﬁc actions under speciﬁc conditions within the deﬁned r egion."
  },
  {
    "number": "102",
    "text": "A company r ecently launched a v ariety of new workloads on A maz on EC2 instances in its A WS account. The company needs t o cr eate a str ategy t o access and administer the instances r emotely and secur ely . The company needs t o implement a r epeatable pr ocess that works with nativ e A WS ser vices and follows the A WS W ell-Ar chitected F r amework. Which solution will meet these r equir ements with the LEAST oper ational o v erhead?",
    "options": [
      "A ttach the appr opriate I AM r ole t o each existing instance and new instance. Use A WS Systems Manager Session Manager t o establish a r emote SSH session. Corr ect answer",
      "Establish an A WS Site-t o-Site VPN connection. Instruct administr at ors t o use their local on-pr emises machines t o connect dir ectly t o the instances b y using SSH k e ys acr oss the VPN tunnel.",
      "Cr eate an administr ativ e SSH k e y pair . Load the public k e y int o each EC2 instance. Deplo y a bastion host in a public subnet t o pr o vide a tunnel for administr ation of each instance. D . Use the EC2 serial console t o dir ectly access the terminal inter face of each instance for administr ation. PAGE109 Ov er all explanation A WS Systems Manager Session Manager allows y ou t o secur ely access y our EC2 instances without needing t o use SSH k e ys or open inbound por ts in y our security gr oups. By attaching I AM r oles t o y our EC2 instances and using Session Manager , y ou can achie v e secur e and contr olled r emote access, and it aligns with A WS W ell-Ar chitected best pr actices. This appr oach minimiz es oper ational o v erhead and pr o vides a mor e str eamlined and secur e r emote administr ation pr ocess.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "103",
    "text": "A company wants t o deplo y a new public web application on A WS. The application includes a web ser v er tier that uses A maz on EC2 instances. The application also includes a database tier that uses an A maz on RDS for My SQL DB instance. The application must be secur e and accessible for global cust omers that ha v e dynamic IP addr esses. How should a solutions ar chitect conﬁgur e the security gr oups t o meet these r equir ements?",
    "options": [
      "Conﬁgur e the security gr oup for the web ser v ers t o allow inbound tr aﬃc on por t 443 fr om 0.0.0.0/0. Conﬁgur e the security gr oup for the DB instance t o allow inbound tr aﬃc on por t 3306 fr om the security gr oup of the web ser v ers. Corr ect answer",
      "Conﬁgur e the security gr oup for the web ser v ers t o allow inbound tr aﬃc on por t 443 fr om the IP addr esses of the cust omers. Conﬁgur e the security gr oup for the DB instance t o allow inbound tr aﬃc on por t 3306 fr om the IP addr esses of the cust omers.",
      "Conﬁgur e the security gr oup for the web ser v ers t o allow inbound tr aﬃc on por t 443 fr om 0.0.0.0/0. Conﬁgur e the security gr oup for the DB instance t o allow inbound tr aﬃc on por t 3306 fr om 0.0.0.0/0. PAGE110 D . Conﬁgur e the security gr oup for the web ser v ers t o allow inbound tr aﬃc on por t 443 fr om the IP addr esses of the cust omers. Conﬁgur e the security gr oup for the DB instance t o allow inbound tr aﬃc on por t 3306 fr om the security gr oup of the web ser v ers. Ov er all explanation It allows H T TPS access fr om any public IP addr ess, meeting the r equir ement for global cust omer access. H T TPS pr o vides encr yption for secur e communication. And for the database security gr oup, only allowing inbound por t 3306 fr om the web ser v er security gr oup pr operly r estricts access t o only the r esour ces that need it.",
      ""
    ],
    "correct_answer": null,
    "explanation": ""
  },
  {
    "number": "104",
    "text": "A company runs an application that r eceiv es data fr om thousands of geogr aphically dispersed r emote de vices that use UDP . The application pr ocesses the data immediately and sends a message back t o the de vice if necessar y . No data is st or ed. The company needs a solution that minimiz es latency for the data tr ansmission fr om the de vices. The solution also must pr o vide r apid failo v er t o another A WS Region. Which solution will meet these r equir ements?",
    "options": [
      "Conﬁgur e an Amaz on Route 53 failo v er r outing policy . Cr eate an Application Load Balancer (ALB) in each of the two Regions. Cr eate an Amaz on Elastic Container Ser vice (Amaz on ECS) cluster with the F ar gate launch type. Cr eate an ECS ser vice on the cluster . Set the ECS ser vice as the tar get for the AL",
      "Pr ocess the data in Amaz on ECS.",
      "Use A WS Global Acceler at or . Cr eate an Application Load Balancer (ALB) in each of the two Regions as an endpoint. Cr eate an Amaz on Elastic Container Ser vice (Amaz on ECS) cluster with the F ar gate launch type. Cr eate an ECS ser vice on the cluster . Set the ECS ser vice as the tar get for the AL",
      "Pr ocess the data in Amaz on ECS. PAGE111",
      "Conﬁgur e an Amaz on Route 53 failo v er r outing policy . Cr eate a Network Load Balancer (NLB) in each of the two Regions. Conﬁgur e the NLB t o inv ok e an A WS Lambda function t o pr ocess the data. D . Use A WS Global Acceler at or . Cr eate a Network Load Balancer (NLB) in each of the two Regions as an endpoint. Cr eate an Amaz on Elastic Container Ser vice (Amaz on ECS) cluster with the F ar gate launch type. Cr eate an ECS ser vice on the cluster . Set the ECS ser vice as the tar get for the NLPr ocess the data in Amaz on ECS. Corr ect answer Ov er all explanation Use A WS Global Acceler at or . Cr eate a Network Load Balancer (NLB) in each of the two Regions as an endpoint. Cr eate an Amaz on Elastic Container Ser vice (Amaz on ECS) cluster with the F ar gate launch type. Cr eate an ECS ser vice on the cluster . Set the ECS ser vice as the tar get for the NL",
      "Pr ocess the data in Amaz on ECS."
    ],
    "correct_answer": null,
    "explanation": "A WS Global Acceler at or combined with Network Load Balancers (NLBs) in multiple r egions pr o vides a scalable and r esilient solution. Amaz on ECS with F ar gate launch type allows for ser v erless container management."
  },
  {
    "number": "105",
    "text": "A company runs a highly a v ailable SF TP ser vice. The SF TP ser vice uses two A maz on EC2 Linux instances that run with elastic IP addr esses t o accept tr aﬃc fr om trusted IP sour ces on the internet. The SF TP ser vice is back ed b y shar ed st or age that is attached t o the instances. User accounts ar e cr eated and managed as Linux users in the SF TP ser v ers. The company wants a ser v erless option that pr o vides high IOPS per formance and highly conﬁgur able security . The company also wants t o maintain contr ol o v er user permissions. Which solution will meet these r equir ements?",
    "options": [
      "Cr eate an encr ypted Amaz on Elastic File System (Amaz on EFS) v olume. Cr eate an A WS T r ansf er F amily SF TP ser vice with elastic IP addr esses and a VPC endpoint that has internet-facing access. A ttach a security gr oup t o the endpoint PAGE112 that allows only trusted IP addr esses. A ttach the EFS v olume t o the SF TP ser vice endpoint. Gr ant users access t o the SF TP ser vice. Corr ect answer",
      "Cr eate an Amaz on S3 buck et with default encr yption enabled. Cr eate an A WS T r ansf er F amily SF TP ser vice with a VPC endpoint that has internal access in a priv ate subnet. A ttach a security gr oup that allows only trusted IP addr esses. A ttach the S3 buck et t o the SF TP ser vice endpoint. Gr ant users access t o the SF TP ser vice.",
      "Cr eate an Amaz on S3 buck et with default encr yption enabled. Cr eate an A WS T r ansf er F amily SF TP ser vice with a public endpoint that allows only trusted IP addr esses. A ttach the S3 buck et t o the SF TP ser vice endpoint. Gr ant users access t o the SF TP ser vice. D . Cr eate an encr ypted Amaz on Elastic Block St or e (Amaz on EBS) v olume. Cr eate an A WS T r ansf er F amily SF TP ser vice with a public endpoint that allows only trusted IP addr esses. A ttach the EBS v olume t o the SF TP ser vice endpoint. Gr ant users access t o the SF TP ser vice. Ov er all explanation Cr eate an encr ypted Amaz on Elastic File System (Amaz on EFS) v olume. Cr eate an A WS T r ansf er F amily SF TP ser vice with elastic IP addr esses and a VPC endpoint that has internet-facing access. A ttach a security gr oup t o the endpoint that allows only trusted IP addr esses. A ttach the EFS v olume t o the SF TP ser vice endpoint. Gr ant users access t o the SF TP ser vice.",
      ""
    ],
    "correct_answer": null,
    "explanation": "Elastic File System (A maz on EFS): EFS pr o vides scalable and highly a v ailable ﬁle st or age, suitable for a ser v erless SF TP ser vice. Encr ypted V olume: The r equir ement for encr yption is met b y cr eating an encr ypted EFS v olume, ensuring data security . A WS T r ansf er F amily SF TP Ser vice: A WS T r ansf er F amily allows for the cr eation of a fully managed SF TP ser vice with high conﬁgur ability and security . VPC Endpoint with Elastic IP Addr esses: Using a VPC endpoint with elastic IP addr esses ensur es secur e access t o the SF TP ser vice fr om trusted IP addr esses o v er the internet. PAGE113 Security Gr oup: A ttaching a security gr oup t o the endpoint allows ﬁne-gr ained contr ol o v er inbound tr aﬃc, limiting access t o trusted IP addr esses. Maintaining Contr ol o v er User P ermissions: I AM r oles and policies can be used t o contr ol user permissions and maintain contr ol o v er user access t o the SF TP ser vice."
  }
]