[
    {
      "q_number": "1",
      "q_text": "A company hosts a three-tier web application in the AWS Cloud. A Multi-AZ Amazon RDS for MySQL server forms the database layer Amazon ElastiCache forms the cache layer. The company wants a caching strategy that adds or updates data in the cache when a customer adds an item to the database. The data in the cache must always match the data in the database. Which solution will meet these requirements?",
      "options": [
        {
          "A": "Implement the write-through caching strategy"
        },
        {
          "B": "Implement the lazy loading caching strategy"
        },
        {
          "C": "Implement the adding TTL caching strategy"
        },
        {
          "D": "Implement the AWS App Config caching strategy"
        }
      ],
      "correct_answer": "A",
      "explanation": "The write-through caching strategy is the optimal solution for this scenario. With this approach, data is written simultaneously to both the cache (Amazon ElastiCache) and the database (Amazon RDS for MySQL) whenever a customer adds an item. This ensures perfect synchronization between the cache and database at all times, meeting the requirement that 'data in the cache must always match the data in the database.' Unlike lazy loading, which only updates the cache when data is requested (potentially leading to stale data), or TTL-based strategies that expire cache entries after a set time, write-through provides immediate consistency. While this strategy may introduce slight write latency, it guarantees data integrity across the three-tier web application's cache and database layers."
    },
    {
      "q_number": "2",
      "q_text": "A company hosts a website on Amazon EC2 instances behind an Application Load Balancer (ALB). The website serves static content. Website traffic is increasing, and the company is concerned about a potential increase in cost.",
      "options": [
        {
          "A": "Create an Amazon CloudFront distribution to cache state files at edge locations"
        },
        {
          "B": "Create an AWS WAF web ACL and associate it with the ALB. Add a rule to the web ACL to cache static files"
        },
        {
          "C": "Create a second ALB in an alternative AWS Region. Route user traffic to the closest Region to minimize data transfer costs"
        },
        {
          "D": "Create an Amazon ElastiCache cluster. Connect the ALB to the ElastiCache cluster to serve cached files"
        }
      ],
      "correct_answer": "A",
      "explanation": "Amazon CloudFront is the ideal solution for optimizing cost while serving static content from EC2 instances. As a content delivery network (CDN), CloudFront caches static files at edge locations worldwide, significantly reducing the load on origin servers (EC2 instances) and the Application Load Balancer. This approach provides multiple benefits: reduced latency for global users who access content from nearby edge locations; decreased data transfer costs since content is served from the edge rather than repeatedly from origin servers; lower compute costs as fewer requests reach the EC2 instances; and improved scalability during traffic spikes. Unlike the other."
    },
    {
      "q_number": "3",
      "q_text": "A security team wants to limit access to specific services or actions in all of the team's AWS accounts. All accounts belong to a large organization in AWS Organizations. The solution must be scalable and there must be a single point where permissions can be maintained. What should a solutions architect do to accomplish this?",
      "options": [
        {
          "A": "Create a service control policy in the root organizational unit to deny access to the services or actions"
        },
        {
          "B": "Create cross-account roles in each account to deny access to the services or actions."
        },
        {
          "C": "Create an ACL to provide access to the services or actions."
        },
        {
          "D": "Create a security group to allow accounts and attach it to user groups."
        }
      ],
      "correct_answer": "A",
      "explanation": "Service Control Policies (SCPs) in AWS Organizations provide the ideal solution for centralized access control across multiple accounts. By implementing SCPs at the root organizational unit level, the security team can establish a single point of management for limiting access to specific services or actions across all accounts in the organization. SCPs act as guardrails that define the maximum permissions available, regardless of identity-based or resource-based policies within individual accounts. This approach is highly scalable as it automatically applies to existing and new accounts within the organization, eliminating the need to configure and maintain separate policies for each account. Unlike."
    },
    {
      "q_number": "4",
      "q_text": "A company needs to connect several VPCs in the us-east-1 Region that span hundreds of AWS accounts. The company's networking team has its own AWS account to manage the cloud network. What is the MOST operationally efficient solution to connect the VPCs?",
      "options": [
        {
          "A": "Set up VPC peering connections between each VPC. Update each associated subnet's route table"
        },
        {
          "B": "Deploy VPN gateways in each VPC. Create a transit VPC in the networking team's AWS account to connect to each VPC."
        },
        {
          "C": "Create an AWS Transit Gateway in the networking team's AWS account. Configure static routes from each VPC."
        },
        {
          "D": "Configure a NAT gateway and an internet gateway in each VPC to connect each VPC through the internet"
        },
        {
          "C": "â€¢ AWS Transit Gateway simplifies connectivity between multiple VPCs, making it operationally efficient."
        }
      ],
      "correct_answer": "C",
      "explanation": "The correct answer is C: Create an AWS Transit Gateway in the networking team's AWS account. Configure static routes from each VPC. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "5",
      "q_text": "A company wants to migrate its existing on-premises monolithic application to AWS. The company wants to keep as much of the front-end code and the backend code as possible. However, the company wants to break the application into smaller applications. A different team will manage each application. The company needs a highly scalable solution that minimizes operational overhead. Which solution will meet these requirements?",
      "options": [
        {
          "A": "Host the application on Amazon EC2 instances. Set up an Application Load Balancer with EC2 instances in an Auto Scaling group as targets."
        },
        {
          "B": "Host the application on AWS Lambda. Integrate the application with Amazon API Gateway."
        },
        {
          "C": "Host the application with AWS Amplify. Connect the application to an Amazon API Gateway API that is integrated with AWS Lambda."
        },
        {
          "D": "Host the application on Amazon Elastic Container Service (Amazon ECS). Set up an Application Load Balancer with Amazon ECS as the target."
        }
      ],
      "correct_answer": "D",
      "explanation": "The correct answer is D: Host the application on Amazon Elastic Container Service (Amazon ECS). Set up an Application Load Balancer with Amazon ECS as the target. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "6",
      "q_text": "A company wants to move its application to a serverless solution. The serverless solution needs to analyze existing and new data by using SQL. The company stores the data in an Amazon S3 bucket. The data requires encryption and must be replicated to a different AWS Region. Which solution will meet these requirements with the LEAST operational overhead?",
      "options": [
        {
          "A": "Create a new S3 bucket. Load the data into the new S3 bucket. Use S3 Cross-Region Replication (CRR) to replicate encrypted objects to an S3 bucket in another Region. Use server-side encryption with AWS KMS multi-Region keys (SSE-KMS). Use Amazon Athena to query the data."
        },
        {
          "B": "Load the data into the existing S3 bucket. Use S3 Cross-Region Replication (CRR) to replicate encrypted objects to an S3 bucket in another Region. Use server-side encryption with Amazon S3 managed encryption keys (SSE-S3). Use Amazon Athena to query the data."
        },
        {
          "C": "Load the data into the existing S3 bucket. Use S3 Cross-Region Replication (CRR) to replicate encrypted objects to an S3 bucket in another Region. Use server-side encryption with Amazon S3 managed encryption keys (SSE-S3). Use Amazon RDS to query the data."
        },
        {
          "D": "Create a new S3 bucket. Load the data into the new S3 bucket. Use S3 Cross-Region Replication (CRR) to replicate encrypted objects to an S3 bucket in another Region. Use server-side encryption with AWS KMS multi-Region keys (SSE-KMS). Use Amazon RDS to query the data."
        }
      ],
      "correct_answer": "A",
      "explanation": "The correct answer is A: Create a new S3 bucket. Load the data into the new S3 bucket. Use S3 Cross-Region Replication (CRR) to replicate encrypted objects to an S3 bucket in another Region. Use server-side encryption with AWS KMS multi-Region keys (SSE-KMS). Use Amazon Athena to query the data. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to."
    },
    {
      "q_number": "7",
      "q_text": "A company needs to store contract documents. A contract lasts for 5 years. During the 5-year period, the company must ensure that the documents cannot be overwritten or deleted. The company needs to encrypt the documents at rest and rotate the encryption keys automatically every year. Which combination of steps should a solutions architect take to meet these requirements with the LEAST operational overhead? (Choose two.)",
      "options": [
        {
          "A": "Store the documents in Amazon S3. Use S3 Object Lock in compliance mode."
        },
        {
          "B": "Store the documents in Amazon S3. Use S3 Object Lock in governance mode."
        },
        {
          "C": "Use server-side encryption with AWS Key Management Service (AWS KMS) customer provided (imported) keys. Configure key rotation."
        },
        {
          "D": "Use server-side encryption with AWS Key Management Service (AWS KMS) customer managed keys. Configure key rotation."
        },
        {
          "E": "Use server-side encryption with Amazon S3 managed encryption keys (SSE-S3). Configure key rotation."
        }
      ],
      "correct_answer": "A, D",
      "explanation": "The correct answers are A and D. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "8",
      "q_text": "A company recently started using Amazon Aurora as the datastore for its global ecommerce application. When large reports are run, developers report that the ecommerce application is performing poorly. After reviewing metrics in Amazon Cloud Watch, a solutions architect finds that the Read IOPS and CPU Utilization metrics are spiking when monthly reports run. What is the MOST cost-effective solution?",
      "options": [
        {
          "A": "Increase the Provisioned IOPS on the Aurorainstance."
        },
        {
          "B": "Migrate the monthly reporting to Amazon Redshift."
        },
        {
          "C": "Migrate the Auroradatabase to a larger instance class."
        },
        {
          "D": "Migrate the monthly reporting to an Aurora Replica."
        }
      ],
      "correct_answer": "D",
      "explanation": "The correct answer is D: Migrate the monthly reporting to an Aurora Replica. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "9",
      "q_text": "A company is migrating an application from on-premisesserversto Amazon EC2 instances. As part of the migration design requirements, a solutions architect must implement infrastructure metrical arms. The company does not need to take action if CPU utilization increases to more than 50% for a short burst to time. However, if the CPU utilization increases to more than 50% and read IOPS on the disk are high at the same time, the company needs to act as soon as possible. The solutions architect also must reduce false alarms. What should the solutions architect do to meet these requirements?",
      "options": [
        {
          "A": "Create Amazon Cloud Watch Synthetic scanariestomonitortheapplicationand raise an alarm."
        },
        {
          "B": "Createsingle Amazon Cloud Watch metrical arms with multiple metric thresholds where possible."
        },
        {
          "C": "Create Amazon Cloud Watch dashboardstovisualizethemetricsandreactto issues quickly."
        },
        {
          "D": "Create Amazon Cloud Watch composite alarms where possible."
        }
      ],
      "correct_answer": "D",
      "explanation": "The correct answer is D: Create Amazon Cloud Watch composite alarms where possible. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "10",
      "q_text": "A company has migrated multiple Microsoft Windows Server workloads to Amazon EC2 instances that run in the us-west-1 Region. The company manually backs up the workloads to create an image as needed. In the event of a natural disaster in the us-west-1 Region, the company wants to recover workloads quickly in the us-west-2 Region. The company wants no more than 24 hours of data loss on the EC2 instances. The company also wants to automate any backups of the EC2 instances. Which solutions will meet these requirements with the LEAST administrative effort? (Choose two.)",
      "options": [
        {
          "A": "Create backup vaults in us-west-1 and inus-west-2 by using AWS Backup. Create a backup plan for the EC2 instances based on tag values. Create an AWS Lambda function to run as a scheduled job to copy the backup data to us-west-2."
        },
        {
          "B": "Create an Amazon EC2-backed Amazon Machine Image (AMI) lifecycle policy to create a backup based on tags. Schedule the backup to run twice daily. Configure the copy to the us-west-2 Region. Correct selection"
        },
        {
          "C": "Create a backup vault by using AWS Backup. Use AWS Backup to create a backup plan for the EC2 instances based on tag values. Define the destination for the copy as us-west-2. Specify the backup schedule to run twice daily. Correct selection"
        },
        {
          "D": "Create an Amazon EC2-backed Amazon Machine Image (AMI) lifecycle policy to create a backup based on tags. Schedule the backup to run twice daily. Copy the image on demand."
        },
        {
          "E": "Create a backup vault by using AWS Backup. Use AWS Backup to create a backup plan for the EC2 instances based on tag values. Specify the backup schedule to run twice daily. Copy on demand to us-west-2."
        }
      ],
      "correct_answer": "B, C",
      "explanation": "The correct answers are B and C. These solutions address the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approaches provide optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. By automating backups and ensuring data replication across regions, the company can ensure business continuity in the event of a disaster. The selected solutions also meet the requirement of minimizing administrative effort by leveraging AWS services designed for automation and scalability. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answers."
    },
    {
      "q_number": "11",
      "q_text": "A company provides an API to its users that automates inquiries for tax computations based on item prices. The company experiences a large number of inquiries during the holiday season only that causes lower response times. A solutions architect needs to design a solution that is scalable and elastic. What should the solutions architect do to accomplish this?",
      "options": [
        {
          "A": "Design a REST API using Amazon API Gateway that connects with an API hosted on an Amazon EC2 instance. API Gateway accepts and passes the item names to the EC2 instance for tax computations."
        },
        {
          "B": "Design a REST API using Amazon API Gateway that accepts the item names. API Gateway passes item names to AWS Lambda for tax computations. Correct answer"
        },
        {
          "C": "Create an Application Load Balancer that has two Amazon EC2 instances behind it. The EC2 instances will compute the tax on the received item names."
        },
        {
          "D": "Provide an API hosted on an Amazon EC2 instance. The EC2 instance performs the required computations when the API request is made."
        }
      ],
      "correct_answer": "A",
      "explanation": "The correct answer is : . This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "12",
      "q_text": "A company has a service that reads and writes large amounts of data from an Amazon S3 bucket in the same AWS Region. The service is deployed on Amazon EC2 instances within the private subnet of a VPC. The service communicates with Amazon S3 over a NAT gateway in the public subnet. However, the company wants a solution that will reduce the data output costs. Which solution will meet theserequirements MOST cost-effectively?",
      "options": [
        {
          "A": "Provision a dedicated EC2 NAT instance in the private subnet. Configure the route table for the public subnet to use the elastic network interface of this instance as the destination for all S3 traffic."
        },
        {
          "B": "Provision a VPC gateway endpoint. Configure the route table for the private subnet to use the gateway endpoint as the route for all S3 traffic."
        },
        {
          "C": "Provision a second NAT gateway. Configure the route table for the private subnet to use this NAT gateway as the destination for all S3 traffic."
        },
        {
          "D": "Provision a dedicated EC2 NAT instance in the public subnet. Configure the route table for the private subnet to use the elastic network interface of this instance as the destination for all S3 traffic."
        }
      ],
      "correct_answer": "B",
      "explanation": "The correct answer is B: Provision a VPC gateway endpoint. Configure the routetable for the private subnettousethegatewayendpointastherouteforall S 3 traffic. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "13",
      "q_text": "A solutions architect needs to securely store a database username and password that an application uses to access an Amazon RDS DB instance. The application that accesses the database runs on an Amazon EC2 instance. The solutions architect want to create a secure parameter in AWS Systems Manager Parameter Store. What should the solutions architect do to meet this requirement?",
      "options": [
        {
          "A": "Create an IAM role that has read access to the Parameter Store parameter. Allow Decrypt access to an AWS Key Management Service (AWS KMS) key that is used to encrypt the parameter. Assign this IAM role to the EC2 instance. Correct answer"
        },
        {
          "B": "Create an IAM trust relationship between the Parameter Store parameter and the EC2 instance. Specify Amazon RDS as a principal in the trust policy."
        },
        {
          "C": "Create an IAM trust relationship between the DB instance and the EC2 instance. Specify Systems Manager as a principal in the trust policy."
        },
        {
          "D": "Create an IAM policy that allows read access to the Parameter Store parameter. Allow Decrypt access to an AWS Key Management Service (AWS KMS) key that is used to encrypt the parameter. Assign this IAM policy to the EC2 instance."
        }
      ],
      "correct_answer": "A",
      "explanation": "The correct answer is : . This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "14",
      "q_text": "A solutions architect is creating a new Amazon CloudFront distribution for an application. Some of the information submitted by users is sensitive. The application uses HTTPS but needs another layer of security. The sensitive information should be protected throughout the entire application stack, and access to the information should be restricted to certain applications. Which action should the solutions architect take?",
      "options": [
        {
          "A": "Configure a CloudFront field-level encryption profile."
        },
        {
          "B": "Configure CloudFront and set the Origin Protocol Policy setting to HTTPS Only for the Viewer Protocol Policy."
        },
        {
          "C": "Configure a CloudFront signed cookie."
        },
        {
          "D": "Configure a CloudFront signed URL."
        }
      ],
      "correct_answer": "A",
      "explanation": "The correct answer is A: Configure a CloudFront field-level encryption profile. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "15",
      "q_text": "A company has a legacy data processing application that runs on Amazon EC2 instances. Data is processed sequentially, but the order of results does not matter. The application uses a monolithic architecture. The only way that the company can scale the application to meet increased demand is to increase the size of the instances. The company's developers have decided to rewrite the application to use a microservices architecture on Amazon Elastic Container Service (Amazon ECS). What should a solutions architect recommend for communication between the microservices?",
      "options": [
        {
          "A": "Create an Amazon Simple Notification Service (Amazon SNS) topic. Add code to the data producers, and publish notifications to the topic. Add code to the data consumers to subscribe to the topic."
        },
        {
          "B": "Create an Amazon Dynamo DB table. Enable Dynamo DB Streams. Add code to the data producers to insert data into the table. Add code to the data consumers to use the Dynamo DB Streams API to detect new table entries and retrieve the data."
        },
        {
          "C": "Create an Amazon Simple Queue Service (Amazon SQS) queue. Add code to the data producers, and send data to the queue. Add code to the data consumers to process data from the queue."
        },
        {
          "D": "Create an AWS Lambda function to pass messages. Add code to the data producers to call the Lambda function with a data object. Add code to the data consumers to receive a data object that is passed from the Lambda function."
        }
      ],
      "correct_answer": "C",
      "explanation": "The correct answer is C: Create an Amazon Simple Queue Service (Amazon SQS) queue. Add code to the data producers, and send data to the queue. Add code to the data consumers to process data from the queue. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "16",
      "q_text": "A company seeks a storage solution for its application. The solution must be highly available and scalable. The solution also must function as a file system, be mountable by multiple Linux instances in AWS and on-premises through native protocols, and have minimum size requirements. The company has set up a Site-to-Site VPN for access from its on-premises network to its VPC. Which storage solution meets these requirements?",
      "options": [
        {
          "C": "Which storage solution meets these requirements?"
        },
        {
          "A": "Amazon FSx Multi-AZ deployments"
        },
        {
          "B": "Amazon Elastic Block Store (Amazon EBS) Multi-Attach volumes"
        },
        {
          "C": "Amazon Elastic File System (Amazon EFS) with a single mount target and multiple access points"
        },
        {
          "D": "Amazon Elastic File System (Amazon EFS) with multiple mount targets Correct answer"
        }
      ],
      "correct_answer": "A",
      "explanation": "The correct answer is : . This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "17",
      "q_text": "A company is developing an e-commerce application that will consist of a load-balanced frontend, a container-based application, and a relational database. A solutions architect needs to create a highly available solution that operates with as little manual intervention as possible. Which solutions meet these requirements? (Choosetwo.)",
      "options": [
        {
          "A": "Create an Amazon RDS DB instance in Multi-AZ mode. Correct selection"
        },
        {
          "B": "Create an Amazon Elastic Container Service (Amazon ECS) cluster with a Fargate launch type to handle the dynamic application load. Correct selection"
        },
        {
          "C": "Create an Amazon Elastic Container Service (Amazon ECS) cluster with an Amazon EC2 launch type to handle the dynamic application load."
        },
        {
          "D": "Create an Amazon RDS DB instance and one or more replicas in another Availability Zone."
        },
        {
          "E": "Create an Amazon EC2 instance-based Docker cluster to handle the dynamic application load."
        }
      ],
      "correct_answer": "A",
      "explanation": "The correct answer is : . This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "18",
      "q_text": "A company has an ordering application that stores customer information in Amazon RDS for MySQL. During regular business hours, employees run one-time queries for reporting purposes. Timeouts are occurring during order processing because the reporting queries are taking a long time to run. The company needs to solve the timeouts without preventing employees from performing queries. What should a solutions architect do to meet these requirements?",
      "options": [
        {
          "A": "Create a read replica. Distribute the ordering application to the primary DB instance and the read replica."
        },
        {
          "B": "Schedule the reporting queries for non-peak hours."
        },
        {
          "C": "Create a read replica. Move reporting queries to the read replica."
        },
        {
          "D": "Migrate the ordering application to Amazon Dynamo DB with on-demand capacity."
        }
      ],
      "correct_answer": "C",
      "explanation": "The correct answer is C: Create a read replica. Move reporting queries to the read replica.. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "19",
      "q_text": "A company has a service that reads and writes large amounts of data from an Amazon S3 bucket in the same AWS Region. The service is deployed on Amazon EC2 instances within the private subnet of a VPC. The service communicates with Amazon S3 over a NAT gateway in the public subnet. However, the company wants a solution that will reduce the data output costs. Which solution will meet theserequirements MOST cost-effectively?",
      "options": [
        {
          "A": "Provision a dedicated EC2 NAT instance in the private subnet. Configure the route table for the public subnet to use the elastic network interface of this instance as the destination for all S3 traffic."
        },
        {
          "B": "Provision a VPC gateway endpoint. Configure the route table for the private subnet to use the gateway endpoint as the route for all S3 traffic."
        },
        {
          "C": "Provision a second NAT gateway. Configure the route table for the private subnet to use this NAT gateway as the destination for all S3 traffic."
        },
        {
          "D": "Provision a dedicated EC2 NAT instance in the public subnet. Configure the route table for the private subnet to use the elastic network interface of this instance as the destination for all S3 traffic."
        }
      ],
      "correct_answer": "B",
      "explanation": "The correct answer is B: Provision a VPC gateway endpoint. Configure the routetable for the private subnettousethegatewayendpointastherouteforall S 3 traffic.. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "20",
      "q_text": "A company has Amazon EC2 instances that run nightly batch jobs to process data. The EC2 instances run in an Auto Scaling group that uses On-Demand billing. If a job fails on one instance, another instance will reprocess the job. The batch jobs run between 12:00 AM and 06:00 AM local time every day. Which solution will provide EC2 instances to meet these requirements MOST cost-effectively?",
      "options": [
        {
          "A": "Purchase a 1-year Reserved Instance for the specific instance type and operating system of the instances in the Auto Scaling group that the batch job uses."
        },
        {
          "B": "Purchase a 1-year Savings Plan for Amazon EC2 that covers the instance family of the Auto Scaling group that the batch job uses."
        },
        {
          "C": "Create a new launch template for the Auto Scaling group. Set the instances to Spot Instances. Set a policy to scale out based on CPU usage."
        },
        {
          "D": "Create a new launch template for the Auto Scaling group. Increase the instance size. Set a policy to scale out based on CPU usage."
        }
      ],
      "correct_answer": "C",
      "explanation": "The correct answer is C: Create a new launch template for the Auto Scaling group. Set the instances to Spot Instances. Set a policy to scale out based on CPU usage. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "21",
      "q_text": "A company's web application is running on Amazon EC2 instances behind an Application Load Balancer. The company recently changed its policy, which now requires the application to be accessed from one specific country only. Which configuration will meet this requirement?",
      "options": [
        {
          "A": "Configure the security group for the EC2 instances."
        },
        {
          "B": "Configure AWS WAF on the Application Load Balancer in a VPC."
        },
        {
          "C": "Configure the network ACL for the subnet that contains the EC2 instances."
        },
        {
          "D": "Configure the security group on the Application Load Balancer."
        },
        {
          "C": "Explanation: \u2022 AWS WAF allows you to create a web access control list (web ACL) that defines rules for allowing or blocking web requests based on various conditions, including the country or region from which the request is originating. \u2022 You can associate this AWS WAF web ACL with your Application Load Balancer (ALB) in your VPC. This will enable AWS WAF to inspect incoming web requests and block any requests that do not meet the defined criteria, such as requests originating from outside the specific country. \u2022 This approach provides a more targeted and flexible way to restrict access to your application based on geographic location while allowing legitimate traffic to reach your EC2 instances behind the ALB."
        }
      ],
      "correct_answer": "B",
      "explanation": "The correct answer is B: Configure AWS WAF on the Application Load Balancer in a VPC.. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "24",
      "q_text": "A company runs an infrastructure monitoring service. The company is building a new feature that will enable the service to monitor data in customer AWS accounts. The new feature will call AWS APIs in customer accounts to describe Amazon EC2 instances and read Amazon Cloud Watch metrics. What should the company do to obtain access to customer accounts in the MOST secure way?",
      "options": [
        {
          "A": "Ensure that the customers create an Amazon Cognito user in their account to use an IAM role with read-only EC2 and Cloud Watch permissions. Encrypt and store the Amazon Cognito user and password in a secrets management system."
        },
        {
          "B": "Ensure that the customers create an IAM user in their account with read-only EC2 and Cloud Watch permissions. Encrypt and store customer access and secret keys in a secrets management system."
        },
        {
          "C": "Create a serverless API that implements a token vending machine to provide temporary AWS credentials for a role with read-only EC2 and Cloud Watch permissions."
        },
        {
          "D": "Ensure that the customers create an IAM role in their account with read-only EC2 and Cloud Watch permissions and a trust policy to the company's account."
        }
      ],
      "correct_answer": "A",
      "explanation": "The correct answer is : . This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "25",
      "q_text": "A company runs a web-based portal that provides users with global breaking news, local alerts, and weather updates. The portal delivers each user a personalized view by using a mixture of static and dynamic content. Content is served over HTTPS through an API server running on an Amazon EC2 instance behind an Application Load Balancer (ALB). The company wants the portal to provide this content to its users across the world as quickly as possible. How should a solutions architect design the application to ensure the LEAST amount of latency for all users?",
      "options": [
        {
          "A": "Deploy the application stack in two AWS Regions. Use an Amazon Route 53 geolocation routing policy to serve all content from the ALB in the closest Region."
        },
        {
          "B": "Deploy the application stack in a single AWS Region. Use Amazon CloudFront to serve all static and dynamic content by specifying the ALB as an origin. Correct answer"
        },
        {
          "C": "Deploy the application stack in a single AWS Region. Use Amazon CloudFront to serve static content. Serve the dynamic content directly from the ALB."
        },
        {
          "D": "Deploy the application stack in two AWS Regions. Use an Amazon Route 53 latency routing policy to serve all content from the ALB in the closest Region."
        }
      ],
      "correct_answer": "A",
      "explanation": "The correct answer is : . This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "26",
      "q_text": "Organizers for a global event want to put daily reports online as static HTML pages. The pages are expected to generate millions of views from users around the world. The files are stored in an Amazon S3 bucket. Asolutionsarchitect has been asked to design an efficient and effective solution. Which action should the solutions architect take to accomplish this?",
      "options": [
        {
          "A": "Use Amazon CloudFront with the S3 bucket as its origin."
        },
        {
          "B": "Generate presigned URLs for the files."
        },
        {
          "C": "Use the geoproximity feature of Amazon Route 53."
        },
        {
          "D": "Use cross-Region replication to all Regions."
        }
      ],
      "correct_answer": "A",
      "explanation": "The correct answer is A: Use Amazon CloudFront with the S3 bucket as its origin. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "27",
      "q_text": "A business application is hosted on Amazon EC2 and uses Amazon S3 for encrypted object storage. The chief information security officer has directed that no application traffic between the two services should traverse the public internet. Which capability should the solutions architect use to meet the compliance requirements?",
      "options": [
        {
          "A": "VPC endpoint"
        },
        {
          "B": "AWS Key Management Service (AWS KMS)"
        },
        {
          "C": "Private subnet"
        },
        {
          "D": "Virtual private gateway"
        }
      ],
      "correct_answer": "A",
      "explanation": "The correct answer is A: VPC endpoint. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "28",
      "q_text": "An application runs on Amazon EC2 instances in private subnets. The application needs to access an Amazon Dynamo DB table. What is the MOST secure way to access the table while ensuring that the traffic does not leave the AWS network?",
      "options": [
        {
          "A": "Use a VPC endpoint for Dynamo DB."
        },
        {
          "B": "Use a NAT gateway in a public subnet."
        },
        {
          "C": "Use the internet gateway attached to the VPC."
        },
        {
          "D": "Use a NAT instance in a private subnet."
        },
        {
          "B": "Explanation: The most secure way to access an Amazon Dynamo DB table from Amazon EC2 instances in private subnets while ensuring that the traffic does not leave the AWS network is to use a VPC endpoint for Dynamo DB. Here's why: 1. VPC Endpoints: A VPC endpoint allows you to privately connect your VPC to supported AWS services like Dynamo DB without the need for an internet gateway, NAT gateway, or NAT instance. It keeps the traffic within the AWS network and does not traverse the public internet. 2. Security: Using a VPC endpoint provides a more secure connection as it doesn't rely on public internet access. It also eliminates the need to configure complex network address translation (NAT) gateways or instances. 3. Simplicity: It is a simpler and more direct method of accessing Dynamo DB without exposing your resources to the internet. This reduces the attack surface and ensures that the traffic remains within your VPC."
        }
      ],
      "correct_answer": "A",
      "explanation": "The correct answer is A: Use a VPC endpoint for Dynamo DB. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "29",
      "q_text": "A company uses a three-tier web application to provide training to new employees. The application is accessed for only 12 hours every day. The company is using an Amazon RDS for MySQL DB instance to store information and wants to minimize costs. What should a solutions architect do to meet these requirements?",
      "options": [
        {
          "A": "Create AWS Lambda functions to start and stop the DB instance. Create Amazon Event Bridge (Amazon Cloud Watch Events) scheduled rules to invoke the Lambda functions. Configure the Lambda functions as event targets for the rules. Correct answer"
        },
        {
          "B": "Launch an Amazon EC2 instance. Create an IAM role that grants access to Amazon RDS. Attach the role to the EC2 instance. Configure a cron job to start and stop the EC2 instance on the desired schedule."
        },
        {
          "C": "Configure an IAM policy for AWSSystems Manager Session Manager. Create an IAM role for the policy. Update the trust relationship of the role. Set up automatic start and stop for the DB instance."
        },
        {
          "D": "Create an Amazon ElastiCache for Rediscache cluster that gives users the ability to access the data from the cache when the DB instance is stopped. Invalidate the cache after the DB instance is started."
        }
      ],
      "correct_answer": "A",
      "explanation": "The correct answer is : . This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "30",
      "q_text": "A company needs to run a critical application on AWS. The company needs to use Amazon EC2 for the application's database. The database must be highly available and must fail over automatically if a disruptive event occurs. Which solution will meet these requirements?",
      "options": [
        {
          "A": "Launch an EC2 instance in an Availability Zone. Install the database on the EC2 instance. Use an Amazon Machine Image (AMI) to backup the data. Use EC2 automatic recovery to recover the instance if a disruptive event occurs."
        },
        {
          "B": "Launch an EC2 instance in an Availability Zone. Install the database on the EC2 instance. Use an Amazon Machine Image (AMI) to backup the data. Use AWS Cloud Formation to automate provisioning of the EC2 instance if a disruptive event occurs."
        },
        {
          "C": "Launch two EC2 instances, each in a different Availability Zone in the same AWS Region. Install the database on both EC2 instances. Configure the EC2 instances as a cluster. Set up database replication."
        },
        {
          "D": "Launch two EC2 instances, each in a different AWS Region. Install the database on both EC2 instances. Set up database replication. Failover the database to a second Region."
        }
      ],
      "correct_answer": "C",
      "explanation": "The correct answer is C: Launch two EC2 instances, each in a different Availability Zone in the same AWS Region. Install the database on both EC2 instances. Configure the EC2 instances as a cluster. Set up database replication. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "31",
      "q_text": "A company uses Amazon S3 to store high-resolution pictures in an S3 bucket. To minimize application changes, the company stores the pictures as the latest version of an S3 object. The company needs to retain only the two most recent versions of the pictures. The company wants to reduce costs. The company has identified the S3 bucket as a large expense. Which solution will reduce the S3 costs with the LEAST operational overhead?",
      "options": [
        {
          "A": "Use S3 Lifecycle to delete expired object versions and retain the two most recent versions."
        },
        {
          "B": "Deactivate versioning on the S3 bucket and retain the two most recent versions."
        },
        {
          "C": "Use an AWS Lambda function to check for older versions and delete all but the two most recent versions."
        },
        {
          "D": "Use S3 Batch Operations to delete non-current object versions and retain only the two most recent versions."
        }
      ],
      "correct_answer": "A",
      "explanation": "The correct answer is A: Use S3 Lifecycle to delete expired object versions and retain the two most recent versions. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "32",
      "q_text": "A company wants to migrate 100 GB of historical data from an on-premises location to an Amazon S3 bucket. The company has a 100 megabits per second (Mbps) internet connection on premises. The company needs to encrypt the data in transit to the S3 bucket. The company will store new data directly in Amazon S3. Which solution will meet these requirements with the LEAST operational overhead?",
      "options": [
        {
          "A": "Set up an IPsec VPN from the on-premises location to AWS. Use the s3 cp command in the AWS CLI to move the data directly to an S3 bucket"
        },
        {
          "B": "Use AWS Data Sync to migrate the data from the on-premises location to an S3 bucket"
        },
        {
          "C": "Use the s3 sync command in the AWS CLI to move the data directly to an S3 bucket"
        },
        {
          "D": "Use AWS Snowball to move the data to an S3 bucket"
        }
      ],
      "correct_answer": "B",
      "explanation": "The correct answer is B: Use AWS Data Sync to migrate the data from the on-premises location to an S3 bucket. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "34",
      "q_text": "A company has a small Python application that processes JSON documents and outputs the results to a non-premises SQL database. The application runs thousands of times each day. The company wants to move the application to the AWS Cloud. The company needs a highly available solution that maximizes scalability and minimizes operational overhead. Which solution will meet these requirements?",
      "options": [
        {
          "A": "Place the JSON documents in an Amazon S3 bucket. Run the Python code on multiple Amazon EC2 instances to process the documents. Store the results in an Amazon Aurora DB cluster."
        },
        {
          "B": "Place the JSON documents in an Amazon Simple Queue Service (Amazon SQS) queue as messages. Deploy the Python code as a container on an Amazon Elastic Container Service (Amazon ECS) cluster that is configured with the Amazon EC2 launch type. Use the container to process the SQS messages. Store the results on an Amazon RDS DB instance."
        },
        {
          "C": "Place the JSON documents in an Amazon S3 bucket. Create an AWS Lambda function that runs the Python code to process the documents as they arrive in the S3 bucket. Store the results in an Amazon Aurora DB cluster."
        },
        {
          "D": "Place the JSON documents in an Amazon Elastic Block Store (Amazon EBS) volume. Use the EBS Multi-Attach feature to attach the volume to multiple Amazon EC2 instances. Run the Python code on the EC2 instances to process the documents. Store the results on an Amazon RDS DB instance."
        }
      ],
      "correct_answer": "C",
      "explanation": "The correct answer is C: Place the JSON documents in an Amazon S3 bucket. Create an AWS Lambda function that runs the Python code to process the documents as they arrive in the S3 bucket. Store the results in an Amazon Aurora DB cluster. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "35",
      "q_text": "A reporting team receives files each day in an Amazon S3 bucket. The reporting team manually reviews and copies the files from this initial S3 bucket to an analysis S3 bucket each day at the same time to use with Amazon Quick Sight. Additional teams are starting to send more files in larger sizes to the initial S3 bucket. The reporting team wants to move the files automatically analysis S3 bucket as the files enter the initial S3 bucket. The reporting team also wants to use AWS Lambda functions to run pattern-matching code on the copied data. In addition, the reporting team wants to send the data files to a pipeline in Amazon Sage Maker Pipelines. What should a solutions architect do to meet these requirements with the LEAST operational overhead?",
      "options": [
        {
          "A": "Configure S3 replication between the S3 buckets. Configure the analysis S3 bucket to send event notificationsto Amazon Event Bridge (Amazon Cloud Watch Events). Configure an Object Created rule in Event Bridge (Cloud Watch Events). Configure Lambda and Sage Maker Pipelines as targets for the rule."
        },
        {
          "B": "Create a Lambda function to copy the files to the analysis S3 bucket. Create an S3 event notification for the analysis S3 bucket. Configure Lambda and Sage Maker Pipelines as destinations of the event notification. Configure s3:Object Created:Put as the event type."
        },
        {
          "C": "Create a Lambda function to copy the files to the analysis S3 bucket. Configure the analysis S3 bucket to send event notifications to Amazon Event Bridge (Amazon Cloud Watch Events). Configure an Object Created rule in Event Bridge (Cloud Watch Events). Configure Lambda and Sage Maker Pipelines as targets for the rule."
        },
        {
          "D": "Configure S3 replication between the S3 buckets. Create an S3 event notification for the analysis S3 bucket. Configure Lambda and Sage Maker Pipelines as destinations of the event notification. Configures 3:Object Created:Put as the event type."
        }
      ],
      "correct_answer": "C",
      "explanation": "The correct answer is C: Create a Lambda function to copy the files to the analysis S3 bucket. Configure the analysis S3 bucket to send event notifications to Amazon Event Bridge (Amazon Cloud Watch Events). Configure an Object Created rule in Event Bridge (Cloud Watch Events). Configure Lambda and Sage Maker Pipelines as targets for the rule. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "36",
      "q_text": "A company's ordersystems sends requests from clients to Amazon EC2 instances. The EC2 instances process the orders and then store the orders in a database on Amazon RDS. Users report that they must reprocess orders when the system fails. The company wants a resilient solution that can process orders automatically if a system outage occurs. What should a solutions architect do to meet these requirements?",
      "options": [
        {
          "A": "Move the EC2 instances into an Auto Scaling group behind an Application Load Balancer (ALB). Update the ordersystem to send messages to the ALB endpoint."
        },
        {
          "B": "Create an Amazon Simple Notification Service (Amazon SNS) topic. Create an AWS Lambda function, and subscribe the function to the SNStopic. Configure the ordersystem to send messages to the SNStopic. Send a command to the EC2 instances to process the messages by using AWSSystems Manager Run Command."
        },
        {
          "C": "Move the EC2 instances into an Auto Scaling group. Create an Amazon Event Bridge (Amazon Cloud Watch Events) rule to target an Amazon Elastic Container Service (Amazon ECS) task."
        },
        {
          "D": "Move the EC2 instances into an Auto Scaling group. Configure the ordersystem to send messages to an Amazon Simple Queue Service (Amazon SQS) queue. Configure the EC2 instances to consume messages from the queue. Correct answer"
        }
      ],
      "correct_answer": "A",
      "explanation": "The correct answer is : . This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "37",
      "q_text": "A company wants to migrate its MySQL database from on-premises to AWS. The company recently experienced a database outage that significantly impacted the business. To ensure this doesn't happen again, the company wants a reliable database solution on AWS that minimizes data loss and stores every transaction on at least two nodes. Which solution meets these requirements?",
      "options": [
        {
          "A": "Create an Amazon EC2 instance with a MySQL engine installed that triggers an AWS Lambda function to asynchronously replicate the data to an Amazon RDS MySQL DB instance."
        },
        {
          "B": "Create an Amazon RDS DB instance with synchronous replication to three nodes in three Availability Zones."
        },
        {
          "C": "Create an Amazon RDS MySQL DB instance with Multi-AZ functionality enabled to synchronously replicate the data."
        },
        {
          "D": "Create an Amazon RDS MySQL DB instance and then create a read replica in a separate AWS Region that asynchronously replicates the data."
        }
      ],
      "correct_answer": "C",
      "explanation": "The correct answer is C: Create an Amazon RDS MySQL DB instance with Multi-AZ functionality enabled to synchronously replicate the data. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "38",
      "q_text": "A company's infrastructure consists of Amazon EC2 instances and an Amazon RDS DB instance in a single AWS Region. The company wants to back up its data in a separate Region. Which solution will meet these requirements with the LEAST operational overhead?",
      "options": [
        {
          "A": "Use AWS Backup to copy EC2 backups and RDS backups to the separate Region."
        },
        {
          "B": "Create Amazon Machine Images (AMIs) of the EC2 instances. Copy the AMIs to theseparate Region. Create a read replica for the RDS DB instance in the separate Region."
        },
        {
          "C": "Use Amazon Data Lifecycle Manager (Amazon DLM) to copy EC2 backups and RDS backups to the separate Region."
        },
        {
          "D": "Create Amazon Elastic Block Store (Amazon EBS) snapshots. Copy the EBS snapshots to the separate Region. Create RDS snapshots. Export the RDS snapshots to Amazon S3. Configure S3 Cross-Region Replication (CRR) to the separate Region."
        }
      ],
      "correct_answer": "A",
      "explanation": "The correct answer is : . This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "39",
      "q_text": "A company is expecting rapid growth in the near future. Asolutions architect needs to configure existing users and grant permissions to new users on AWS. The solutions architect has decided to create IAM groups. The solutions architect will add the new users to IAM groups based on department. Which additional action is the MOST secure way to grant permissions to the new users?",
      "options": [
        {
          "A": "Create IAM roles. Associate the roles with a permissions boundary that defines the maximum permissions"
        },
        {
          "B": "Create IAM roles that have least privilege permission. Attach the roles to IAM groups"
        },
        {
          "C": "Apply service control policies (SCPs) to manage access permissions"
        },
        {
          "D": "Create an IAM policy that grants least privilege permission. Attach the policy to the IAM groups"
        }
      ],
      "correct_answer": "D",
      "explanation": "The correct answer is D: Create an IAM policy that grants least privilege permission. Attach the policy to the IAM groups. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "40",
      "q_text": "A company is concerned about the security of its public web application due to recent web attacks. The application uses an Application Load Balancer (ALB). Asolutions architect must reduce the risk of DDoS attacks against the application. What should the solutions architect do to meet this requirement?",
      "options": [
        {
          "A": "Enable AWSShield Advanced to prevent attacks."
        },
        {
          "B": "Configure Amazon Macie to prevent attacks."
        },
        {
          "C": "Configure Amazon Guard Duty to monitor the ALB."
        },
        {
          "D": "Add an Amazon Inspector agent to the ALB."
        }
      ],
      "correct_answer": "A",
      "explanation": "The correct answer is A: Enable AWSShield Advanced to prevent attacks. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "41",
      "q_text": "A company has a mobile chat application with a datastore based in Amazon Dynamo DB. Users would like new messages to be read with as little latency as possible. Asolutions architect needs to design an optimal solution that requires minimal application changes. Which method should the solutions architect select?",
      "options": [
        {
          "A": "Add an Amazon ElastiCache for Rediscache to the application stack. Update the application to point to the Rediscache endpoint instead of Dynamo DB."
        },
        {
          "B": "Configure Amazon Dynamo DB Accelerator (DAX) for the new messages table. Update the code to use the DAX endpoint."
        },
        {
          "C": "Add Dynamo DB read replicas to handle the increased read load. Update the application to point to the read endpoint for the read replicas."
        },
        {
          "D": "Double the number of read capacity units for the new messages table in Dynamo DB. Continue to use the existing Dynamo DB endpoint."
        }
      ],
      "correct_answer": "B",
      "explanation": "The correct answer is B: Configure Amazon Dynamo DB Accelerator (DAX) for the new messages table. Update the code to use the DAX endpoint. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "42",
      "q_text": "A company has a service that produces event data. The company wants to use AWS to process the event data as it is received. The data is written in a specific order that must be maintained throughout processing. The company wants to implement a solution that minimizes operational overhead. How should a solutions architect accomplish this?",
      "options": [
        {
          "A": "Create an Amazon Simple Notification Service (Amazon SNS) topic to deliver notifications containing payloads to process. Configure an AWS Lambda function as a subscriber."
        },
        {
          "B": "Create an Amazon Simple Queue Service (Amazon SQS) standard queue to hold messages. Set up an AWS Lambda function to process messages from the queue independently."
        },
        {
          "C": "Create an Amazon Simple Notification Service (Amazon SNS) topic to deliver notifications containing payloads to process. Configure an Amazon Simple Queue Service (Amazon SQS) queue as a subscriber."
        },
        {
          "D": "Create an Amazon Simple Queue Service (Amazon SQS) FIFO queue to hold messages. Set up an AWS Lambda function to process messages from the queue."
        }
      ],
      "correct_answer": "D",
      "explanation": "The correct answer is D: Create an Amazon Simple Queue Service (Amazon SQS) FIFO queue to hold messages. Set up an AWS Lambda function to process messages from the queue. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "43",
      "q_text": "A solutionsarchitect needsto help a company optimize the cost of running an application on AWS. The application will use Amazon EC2 instances, AWS Fargate, and AWS Lambda for compute within the architecture. The EC2 instances will run the data ingestion layer of the application. EC2 usage will be sporadic and unpredictable. Workloads that run on EC2 instances can be interrupted at any time. The application frontend will run on Fargate, and Lambda will serve the API layer. The front-end utilization and API layer utilization will be predictable over the course of the next year. Which combination of purchasing options will provide the MOST cost-effective solution for hosting this application? (Choosetwo.)",
      "options": [
        {
          "A": "Purchase 1-year All Upfront Reserved instances for the data ingestion layer."
        },
        {
          "B": "Purchase a 1-year EC2 instance Savings Plan for the frontend and API layer."
        },
        {
          "C": "Purchase a 1-year Compute Savings Plan for the frontend and API layer. Correct selection"
        },
        {
          "D": "Use Spot Instances for the data ingestion layer. Correct selection"
        },
        {
          "E": "Use On-Demand Instances for the data ingestion layer"
        }
      ],
      "correct_answer": "A",
      "explanation": "The correct answer is : . This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "44",
      "q_text": "A company needs to minimize the cost of its 1 Gbps AWS Direct Connect connection. The company's average connection utilization is less than 10%. Asolutions architect must recommend a solution that will reduce the cost without compromising security. Which solution will meet these requirements?",
      "options": [
        {
          "A": "Contact an AWS Direct Connect Partner to order a 1 Gbps connection. Share the connection with another AWS account."
        },
        {
          "B": "Contact an AWS Direct Connect Partner to order a 200 Mbps hosted connection for an existing AWS account."
        },
        {
          "C": "Set up a new 1 Gbps Direct Connect connection. Share the connection with another AWS account."
        },
        {
          "D": "Set up a new 200 Mbps Direct Connect connection in the AWS Management Console."
        }
      ],
      "correct_answer": "D",
      "explanation": "The correct answer is D: Set up a new 200 Mbps Direct Connect connection in the AWS Management Console. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "45",
      "q_text": "A company needs to save the results from a medical trial to an Amazon S3 repository. Therepository must allow a few scientists to add new files and must restrict all other users to read-only access. No users can have the ability to modify or delete any files in the repository. The company must keep every file in the repository for a minimum of 1 year after its creation date. Which solution will meet these requirements?",
      "options": [
        {
          "A": "Use S3 Object Locking in governance mode with a legal hold of 1 year."
        },
        {
          "B": "Configure the S3 bucket to invoke an AWS Lambda function every time an object is added. Configure the function to track the hash of the saved objects so that modified objects can be marked accordingly."
        },
        {
          "C": "Use S3 Object Lock in compliance mode with a retention period of 365 days."
        },
        {
          "D": "Use an IAM role to restrict all users from deleting or changing objects in the S3 bucket. Use an S3 bucket policy to only allow the IAM role."
        }
      ],
      "correct_answer": "A",
      "explanation": "The correct answer is e: . This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "46",
      "q_text": "A company operates atwo-tier application for image processing. The application uses two Availability Zones, each with one public subnet and one private subnet. An Application Load Balancer (ALB) for the web tier uses the public subnets. Amazon EC2 instances for the application tier use the private subnets. Users report that the application is running more slowly than expected. A security auditor of the web server log files shows that the application is receiving millions of illegitimate requests from a small number of IP addresses. Asolutions architect needs to resolve the immediate performance problem while the company investigates a more permanent solution. What should the solutions architect recommend to meet this requirement?",
      "options": [
        {
          "A": "Modify the network ACL for the web tier subnets. Add an inbound deny rule for the IP addresses that are consuming resources."
        },
        {
          "B": "Modify the network ACL for the application tier subnets. Add an inbound deny rule for the IP addresses that are consuming resources."
        },
        {
          "C": "Modify the inbound security group for the application tier. Add a deny rule for the IP addresses that are consuming resources."
        },
        {
          "D": "Modify the inbound security group for the web tier. Add a deny rule for the IP address that is consuming resources."
        }
      ],
      "correct_answer": "A",
      "explanation": "The correct answer is A: Modify the network ACL for the web tier subnets. Add an inbound deny rule for the IP addresses that are consuming resources. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "47",
      "q_text": "A company has a web application that is based on Java and PHP. The company plans to move the application from on-premises to AWS. The company needs the ability to test new site features frequently. The company also needs a highly available and managed solution that requires minimum operational overhead. Which solution will meet these requirements?",
      "options": [
        {
          "A": "Containerize the web application. Deploy the web application to Amazon EC2 instances. Use the AWS Load Balancer Controller to dynamically route traffic between containersthat contain the new site features for testing."
        },
        {
          "B": "Create an Amazon S3 bucket. Enable static web hosting on the S3 bucket. Upload the static content to the S3 bucket. Use AWS Lambda to process all dynamic content."
        },
        {
          "C": "Deploy the web application to Amazon EC2 instancesthat are configured with Java and PHP. Use Auto Scaling groups and an Application Load Balancer to manage the website's availability."
        },
        {
          "D": "Deploy the web application to an AWS Elastic Beanstalk environment. Use URL swapping to switch between multiple Elastic Beanstalk environments for feature testing."
        }
      ],
      "correct_answer": "D",
      "explanation": "The correct answer is D: Deploy the web application to an AWS Elastic Beanstalk environment. Use URL swapping to switch between multiple Elastic Beanstalk environments for feature testing. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "48",
      "q_text": "An entertainment company is using Amazon Dynamo DB to store media metadata. The application is read intensive and experiencing delays. The company does not have staff to handle additional operational overhead and needs to improve the performance efficiency of Dynamo DB without reconfiguring the application. What should a solutions architect recommend to meet this requirement?",
      "options": [
        {
          "A": "Use Amazon ElastiCache for Memcached with Auto Discovery enabled."
        },
        {
          "B": "Use Amazon ElastiCache for Redis."
        },
        {
          "C": "Replicated at by using Dynamo DB global tables."
        },
        {
          "D": "Use Amazon Dynamo DB Accelerator (DAX)."
        }
      ],
      "correct_answer": "D",
      "explanation": "The correct answer is D: Use Amazon Dynamo DB Accelerator (DAX). This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "51",
      "q_text": "A company wants to ingest customer payment data into the company's data lake in Amazon S3. The company receives payment data every minute on average. The company wants to analyze the payment data in real time. Then the company wants to ingest the data into the data lake. Which solution will meet these requirements with the MOST operationally efficient?",
      "options": [
        {
          "A": "Use Amazon Kinesis Data Firehose to ingest data. Use Amazon Kinesis Data Analytics to analyze the data in real time."
        },
        {
          "B": "Use AWS Glue to ingest data. Use Amazon Kinesis Data Analytics to analyze the data in real time."
        },
        {
          "C": "Use Amazon API Gateway to ingest data. Use AWS Lambda to analyze the data in real time."
        },
        {
          "D": "Use Amazon Kinesis Data Streams to ingest data. Use AWS Lambda to analyze the data in real time."
        }
      ],
      "correct_answer": "A",
      "explanation": "The correct answer is A: Use Amazon Kinesis Data Firehose to ingest data. Use Amazon Kinesis Data Analytics to analyze the data in real time. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "52",
      "q_text": "A company is creating an application that runs on containers in a VPC. The application stores and accesses data in an Amazon S3 bucket. During the development phase, the application will store and access 1 TB of data in Amazon S3 each day. The company wants to minimize costs and wants to prevent traffic from traversing the internet whenever possible. Which solution will meet these requirements?",
      "options": [
        {
          "A": "Enable S3 Transfer Acceleration for the S3 bucket"
        },
        {
          "B": "Create an interface endpoint for Amazon S3 in the VPC. Associate this endpoint with all route tables in the VPC"
        },
        {
          "C": "Create a gateway VPC endpoint for Amazon S3. Associate this endpoint with all route tables in the VPC. Correct answer"
        },
        {
          "D": "Enable S3 Intelligent-Tiering for the S3 bucket"
        }
      ],
      "correct_answer": "C",
      "explanation": "The correct answer is C: Create a gateway VPC endpoint for Amazon S3. Associate this endpoint with all route tables in the VPC. Correct answer. This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    },
    {
      "q_number": "53",
      "q_text": "An ecommerce company hostsits analytics application in the AWS Cloud. The application generates about 300 MB of data each month. The data is stored in JSON format. The company is evaluating a disaster recovery solution to backup the data. The data must be accessible in milliseconds if it is needed, and the data must be kept for 30 days. Which solution meets these requirements MOST cost-effectively?",
      "options": [
        {
          "A": "Amazon RDS for Postgre SQL"
        },
        {
          "B": "Amazon Open Search Service (Amazon Elasticsearch Service)"
        },
        {
          "C": "Amazon S3 Glacier"
        },
        {
          "D": "Amazon S3 Standard Correct answer"
        }
      ],
      "correct_answer": "A",
      "explanation": "The correct answer is d: . This solution addresses the key requirements outlined in the scenario by leveraging AWS best practices for cloud architecture. The chosen approach provides optimal performance, cost-efficiency, and reliability while maintaining security and compliance standards. Alternative options would either introduce unnecessary complexity, increase operational overhead, or fail to meet specific requirements mentioned in the question. AWS services are designed to work together seamlessly, and this solution demonstrates effective integration of services to solve business challenges. When implementing AWS solutions, it's important to consider factors such as scalability, availability, security, and cost optimization, all of which are addressed by the correct answer."
    }
    
  ]